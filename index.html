<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="爱自己是终身浪漫的开始">
<meta property="og:type" content="website">
<meta property="og:title" content="Pearl 的个人小站">
<meta property="og:url" content="https://pearlzju.github.io/index.html">
<meta property="og:site_name" content="Pearl 的个人小站">
<meta property="og:description" content="爱自己是终身浪漫的开始">
<meta property="article:author" content="Pearl">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://pearlzju.github.io/"/>





  <title>Pearl 的个人小站</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?e99d362e55bda406e16937db2b48aebc";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Pearl 的个人小站</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">终身学习者</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://pearlzju.github.io/2021/06/19/%E6%B5%85%E6%9E%90Golang%E7%9A%84%E8%B0%83%E5%BA%A6%E5%99%A8(%E4%B8%80)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pearl">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/face.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pearl 的个人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/19/%E6%B5%85%E6%9E%90Golang%E7%9A%84%E8%B0%83%E5%BA%A6%E5%99%A8(%E4%B8%80)/" itemprop="url">浅析Golang的调度器(一)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-06-19T18:33:38+08:00">
                2021-06-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" itemprop="url" rel="index">
                    <span itemprop="name">计算机</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/06/19/%E6%B5%85%E6%9E%90Golang%E7%9A%84%E8%B0%83%E5%BA%A6%E5%99%A8(%E4%B8%80)/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2021/06/19/%E6%B5%85%E6%9E%90Golang%E7%9A%84%E8%B0%83%E5%BA%A6%E5%99%A8(%E4%B8%80)/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2021/06/19/%E6%B5%85%E6%9E%90Golang%E7%9A%84%E8%B0%83%E5%BA%A6%E5%99%A8(%E4%B8%80)/" class="leancloud_visitors" data-flag-title="浅析Golang的调度器(一)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1 id="进程-线程-协程-Goroutine"><a href="#进程-线程-协程-Goroutine" class="headerlink" title="进程/线程/协程/Goroutine"></a>进程/线程/协程/Goroutine</h1><h2 id="进程-Process"><a href="#进程-Process" class="headerlink" title="进程(Process)"></a>进程(Process)</h2><p>在说进程是什么之前，先考虑一下为什么需要进程？<br>早期批处理系统只能一次处理一个任务，多道程序设计的引入，内存中可以同时存放多个程序，在操作系统的管理下，可以并发(同一时间间隔)处理多个任务。所以需要引入进程，合理地隔离资源、运行环境，提升资源利用率。</p>
<p>所以，进程是操作系统进行资源分配和调度的基本单位，作为程序独立运行的载体保障程序正常执行，使得资源利用率大幅提升。</p>
<p>程序最初只是一个文本文件，被编译或解释成二进制，载入到内存后成为一个或多个正在运行的进程，它不仅需要告诉CPU应该执行什么二进制指令，还需要内存和各种操作系统资源才能运行。所以进程也可以理解为：加载到内存中的程序 + 程序运行所需的所有资源（操作系统分配和管理这些资源）。</p>
<p>进程作为运行中的程序在操作系统中的一个具象化的表现，在内存中的典型存储空间布局如图所示。每个进程都拥有如图的存储空间，独立不共享。所以从一个进程切换到另一个进程需要一些时间来保存和加载寄存器、内存映射和其他资源。</p>
<img width="400" src="/images/浅析Golang的调度器/1.png">

<ul>
<li>text: 代码区。程序代码编译后的能被CPU执行的机器指令。一旦加载后只读，大小不会再变化。</li>
<li>initialized data: 程序初始化的变量，全局变量和静态变量。一旦加载后只读，大小不会再变化。</li>
<li>uninitialized data(bss): 程序没有初始化的变量，会被初始化为0或空指针。</li>
<li>stack: 函数调用栈。保存函数的局部变量、向被调用函数传递参数、返回函数的返回值、函数的返回地址。</li>
<li>heap: 堆。程序运行时动态分配的内存(例如调用malloc)，大小随程序的运行而变化。从堆上分配的内存用完后必须归还给堆，否则内存分配器可能会反复向操作系统申请扩展堆的大小，最后内存不足导致内存泄露。</li>
</ul>
<blockquote>
<p>c/c++必须小心处理堆的分配和释放。但是go的runtime有垃圾处理器进行垃圾回收。<br>c/c++绝对不要返回函数局部变量的地址，因为同一地址的栈内存会被其它函数重用。但是go的编译器发现程序返回了某个局部变量的地址，编译器会把这个变量放到堆上去。</p>
</blockquote>
<h2 id="线程-Thread"><a href="#线程-Thread" class="headerlink" title="线程(Thread)"></a>线程(Thread)</h2><p>线程是进程中的执行单元。简单地说，线程是由内核负责调度且拥有自己私有的一组寄存器值和栈的执行流。</p>
<p>如图所示，例如一个程序要输出2次print，可以用一个执行流依次执行；也可以创建2个执行流，每个执行流执行一次print。如果有2个cpu，就可以实现单进程中利用2个执行流并行执行print。所以线程是操作系统独立调度的最小单位。操作系统对线程的调度可以简单地理解为内核对不同线程所使用的寄存器和栈的切换。</p>
<img width="400" src="/images/浅析Golang的调度器/2.png">

<p>每个线程都有自己的stack，但是进程中的所有线程都将共享heap和其它资源。所以同一进程的线程之间的通信成本相对较低，但同时增加了解决临界资源的锁问题。</p>
<p>相比于进程，线程最大的好处是同一进程的线程之间切换上下文开销较小。</p>
<h2 id="协程-Coroutine"><a href="#协程-Coroutine" class="headerlink" title="协程(Coroutine)"></a>协程(Coroutine)</h2><p>一些现代编程语言中，引入了协程的概念。为什么引入协程？</p>
<p>虽然多线程/多进程解决了阻塞带来的CPU浪费，可以并发执行多个任务。但是引入新的问题，一是进程/线程数量越多，CPU在执行程序和切换进程/线程中来回，切换成本越大；二是多线程需要解决同步和竞争(锁、资源竞争冲突等)问题；三是进程/线程都是高内存(虚拟内存)占用，进程的量级在GB，线程的量级在MB。</p>
<p>所以协程的产生是为了追求更好地利用CPU和内存。把线程一分为二：内核空间的线程+用户空间的协程。具体语言会做相应的绑定和调度策略，比如本文要讲的go语言的GMP模型的协程调度器。</p>
<p>所以，协程是用户态的概念。线程是由操作系统在内核态调度的，协程则是由应用程序在用户态调度的。</p>
<p>多个协程可以运行在一个线程中。相比于线程，有两个优势：</p>
<ul>
<li>一个协程只需要量级KB的栈内存，而线程的量级是MB。</li>
<li>由于协程之间的切换发生在用户态，没有系统调用，切换效率远高于线程（我理解是在子程序之间来回切换）。</li>
</ul>
<blockquote>
<p>只有内核对线程的调度才能利用多核CPU让程序并行执行，所以一个线程中的多个协程是无法并行执行的。<br>协程非常适合用于并发执行IO密集型任务，但不适合计算密集任务。因为计算密集型任务需要连续执行指令，切换会损失CPU资源；IO密集型任务，任务阻塞在IO等待，切换不会损失CPU资源。</p>
</blockquote>
<h2 id="Goroutine"><a href="#Goroutine" class="headerlink" title="Goroutine"></a>Goroutine</h2><p>不能简单地将go语言中的goroutine理解为协程。因为多个goroutine在运行时创建多个线程来执行并发任务。goroutine在运行时可以被分派到其它线程执行。goroutine更像是线程和协程的结合，可以最大限度利用多核CPU。</p>
<p>相比于线程，goroutine的优势在于轻量，体现在两个方面：</p>
<ul>
<li>goroutine的创建和切换在用户态就能完成，无需进入内核态。开销远小于需要进入内核态创建和切换的线程。</li>
<li>线程的栈内存空间一旦创建和初始化完成后其大小就不能再变化，而且这个栈内存空间较大；而goroutine启动时默认栈大小只有2KB，而且可以由<code>runtime</code>自动伸缩，既没有栈溢出风险，也不会造成栈内存空间浪费。</li>
</ul>
<blockquote>
<p>线程的调度是抢占式的，由内核决定。但是goroutine的调度是用户态决定的，在go1.14之前是非抢占式的，在go1.14开始是抢占式的。</p>
</blockquote>
<p>用一个example可以看出go1.14前后版本的区别。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">"fmt"</span></span><br><span class="line">	<span class="string">"runtime"</span></span><br><span class="line">	<span class="string">"time"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	runtime.GOMAXPROCS(<span class="number">1</span>) <span class="comment">// 限制CPU使用1核，否则无法区分结果</span></span><br><span class="line">	<span class="keyword">var</span> a [<span class="number">10</span>]<span class="keyword">int</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(i <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">			<span class="keyword">for</span> &#123;</span><br><span class="line">				a[i]++</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;(i)</span><br><span class="line">	&#125;</span><br><span class="line">	time.Sleep(time.Second)</span><br><span class="line">	fmt.Println(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>用go1.13编译器，该程序会死循环，永远无法退出。如图所示，可以看到CPU占用率持续在接近100%。<br>因为在go1.13中，goroutine调度器还是非抢占式的，除非遇到IO阻塞等情况，否则goroutine不会主动交出CPU的使用权。我们的示例是个计算密集型程序，main goroutine永远拿不到CPU的使用权，所以程序永远无法结束。</p>
<img width="400" src="/images/浅析Golang的调度器/6.png">

<p>用go1.14编译器，可以得到类似<code>[66722775 68857017 71320685 63615563 60855132 52515950 51764765 53227266 57977851 61729335]</code>的输出。<br>因为在go1.14中，goroutine调度器是抢占式的，goroutine占用CPU的时间是被限制的，只要main函数中的goroutine拿到CPU的使用权，就能结束程序。</p>
<h1 id="GMP模型"><a href="#GMP模型" class="headerlink" title="GMP模型"></a>GMP模型</h1><h2 id="GM模型的问题"><a href="#GM模型的问题" class="headerlink" title="GM模型的问题"></a>GM模型的问题</h2><p>在2012年go1.0版本之前，goroutine调度器是<code>GM</code>模型。G代表goroutine，M(thread)代表线程。如图所示，goroutine维护在全局队列，M想要执行、放回G都必须访问全局队列。因为M有多个，访问临界资源全局队列需要加锁保证互斥/同步。</p>
<p><code>GM</code>模型有几个缺点：</p>
<ol>
<li>创建、销毁、调度G都需要M获取锁，锁竞争导致性能低下。</li>
<li>当G需要创建子协程G’，为了继续执行G，需要把G’交给M’执行，导致程序的局部性很差(因为G和G’相关的)。</li>
<li>CPU在M之间的频繁切换导致较大的系统调用开销。</li>
</ol>
<img width="400" src="/images/浅析Golang的调度器/5.png">

<h2 id="GMP模型的引入"><a href="#GMP模型的引入" class="headerlink" title="GMP模型的引入"></a>GMP模型的引入</h2><p>针对<code>GM</code>模型的弊端，引入了<code>GMP</code>模型，它增加了<code>P</code>(processor)。<code>M</code>和<code>P</code>绑定，<code>P</code>中包含<code>G</code>的局部运行队列。</p>
<p>如图所示，可以看出，每个<code>M</code>都绑定了一个<code>P</code>，每个<code>P</code>都有一个私有的goroutine本地运行队列，<code>M</code>从本地和全局goroutine队列中获取goroutine并运行之。</p>
<img width="400" src="/images/浅析Golang的调度器/4.png">

<ul>
<li>全局队列：存放等待运行的G。</li>
<li>P的本地队列：也是存放等待运行的G。不超过256个。G新建子协程G’时，G’优先加到本地队列。如果队列满，则把本地队列的一半G移动到全局队列。</li>
<li>P：所有P都在程序启动时创建，最多<code>GOMAXPROCS</code>(可配置) 个。</li>
<li>M：M和P绑定，M通过P间接从本地队列获取G，P队列为空时候，M也会尝试从全局队列拿一批G放到P的本地队列，或者从其他P的本地队列偷取G放到自己的本地队列。M运行G，G执行完成后，M会从P获取下一个G，不断重复，直到主进程退出。</li>
</ul>
<blockquote>
<p>P的数量由<code>GOMAXPROCS</code>决定，运行时候系统会根据这个数量创建P，这意味着同一时刻，只有<code>GOMAXPROCS</code>个goroutine在并行。<br>M的最大数量由<code>runtime</code>的 <code>SetMaxThreads</code>函数设置。当一个M阻塞，P会创建新的M或切到另一个空闲的M。所以P和M的数量没有绝对关系。</p>
</blockquote>
<h2 id="为什么是M-N"><a href="#为什么是M-N" class="headerlink" title="为什么是M:N"></a>为什么是M:N</h2><p>go的调度器是基于GMP模型的。先说结论，GMP模型中，线程和协程的绑定是M:N关系。M个goroutine运行在N个线程之上，内核负责对这N个线程进行调度，这N个线程又负责对这M个goroutine进行调度。</p>
<img width="400" src="/images/浅析Golang的调度器/3.png">

<p>再说为什么是M:N关系？</p>
<ul>
<li><p>如果绑定是N:1关系，N个协程绑定在一个1个线程上。优点是可以在用户态快速切换协程。缺点是1个进程的所有协程都绑定在1个线程上，无法利用多核CPU。一旦某个协程阻塞，线程也会阻塞，其它协程都无法执行。</p>
</li>
<li><p>如果绑定是1:1关系，1个协程绑定在1个线程上。可以利用多核，不存在N:1关系的缺点。但反而多了协程的创建和删除开销，且切换上下文慢。</p>
</li>
<li><p>绑定是M:N关系，M个协程绑定在N个线程上。解决了上面两种模型的缺点，能利用多核，也能快速切换协程。但瓶颈在于协程调度器的优化和调度算法。</p>
</li>
</ul>
<p>所以，即使某个工作线程遇到goroutine阻塞，该线程的其它goroutine也能被<code>runtime</code>调度，转移到其它工作线程执行。</p>
<h2 id="GMP模型的数据结构"><a href="#GMP模型的数据结构" class="headerlink" title="GMP模型的数据结构"></a>GMP模型的数据结构</h2><p>以下列举的结构体的定义位于Go源代码的<code>src/runtime/runtime2.go</code>。</p>
<h3 id="g"><a href="#g" class="headerlink" title="g"></a>g</h3><p>线程对goroutine的调度和内核对线程的调度，其原理是类似的，都是通过保存和修改CPU寄存器的值来实现切换线程/goroutine。</p>
<p>所以，为了实现对goroutine的调度，goroutine调度器引入<code>g</code>结构体来保存CPU寄存器的值和goroutine的所有信息。<code>g</code>的每一个实例对象代表一个goroutine。当goroutine被调离CPU时，调度器负责把CPU寄存器值保存在<code>g</code>对象的成员变量中；当goroutine被调度在CPU运行时，调度器负责把<code>g</code>对象的成员变量保存的寄存器值恢复到CPU寄存器中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">type g struct &#123;</span><br><span class="line">    stack       stack &#x2F;&#x2F; 记录该goroutine使用的栈</span><br><span class="line">    &#x2F;&#x2F; 下面两个成员用于栈溢出检查，实现栈的自动伸缩，抢占调度也会用到stackguard0</span><br><span class="line">    stackguard0 uintptr &#x2F;&#x2F; offset known to liblink</span><br><span class="line">    stackguard1 uintptr &#x2F;&#x2F; offset known to liblink</span><br><span class="line">    ......    </span><br><span class="line">    m              *m &#x2F;&#x2F; 此goroutine正在被哪个工作线程执行</span><br><span class="line">    sched          gobuf &#x2F;&#x2F; 保存调度信息，主要是几个寄存器的值</span><br><span class="line">    ......</span><br><span class="line">    schedlink      guintptr &#x2F;&#x2F; 指向全局运行队列中的下一个g，所有位于全局运行队列中的g形成一个链表</span><br><span class="line">    ......</span><br><span class="line">    preempt        bool &#x2F;&#x2F; 抢占调度标志，如果需要抢占调度，设置preempt为true</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="schedt"><a href="#schedt" class="headerlink" title="schedt"></a>schedt</h3><p>可运行的<code>g</code>对象需要有存放在一个容器里，便于被工作线程调度并运行。调度器引入<code>schedt</code>结构体，用来保存<code>g</code>对象的运行队列(称之为goroutine全局运行队列)，也用来保存调度器自身的状态信息。</p>
<p>每个go程序中，只有一个<code>schedt</code>的实例对象，被定义成一个共享的全局变量。这样每个线程都可以访问<code>schedt</code>对象，以及获取<code>schedt</code>的goroutine全局运行队列。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">type schedt struct &#123;</span><br><span class="line">    &#x2F;&#x2F; accessed atomically. keep at top to ensure alignment on 32-bit systems.</span><br><span class="line">    goidgen  uint64</span><br><span class="line">    lastpoll uint64</span><br><span class="line">    lock mutex</span><br><span class="line">    &#x2F;&#x2F; 由空闲的工作线程组成链表</span><br><span class="line">    midle        muintptr &#x2F;&#x2F; idle m&#39;s waiting for work</span><br><span class="line">    &#x2F;&#x2F; 空闲的工作线程的数量</span><br><span class="line">    nmidle       int32    &#x2F;&#x2F; number of idle m&#39;s waiting for work</span><br><span class="line">    nmidlelocked int32    &#x2F;&#x2F; number of locked m&#39;s waiting for work</span><br><span class="line">    mnext        int64    &#x2F;&#x2F; number of m&#39;s that have been created and next M ID</span><br><span class="line">    &#x2F;&#x2F; 最多只能创建maxmcount个工作线程</span><br><span class="line">    maxmcount    int32    &#x2F;&#x2F; maximum number of m&#39;s allowed (or die)</span><br><span class="line">    nmsys        int32    &#x2F;&#x2F; number of system m&#39;s not counted for deadlock</span><br><span class="line">    nmfreed      int64    &#x2F;&#x2F; cumulative number of freed m&#39;s</span><br><span class="line">    ngsys uint32 &#x2F;&#x2F; number of system goroutines; updated atomically</span><br><span class="line">    &#x2F;&#x2F; 由空闲的p结构体对象组成的链表</span><br><span class="line">    pidle      puintptr &#x2F;&#x2F; idle p&#39;s</span><br><span class="line">    &#x2F;&#x2F; 空闲的p结构体对象的数量</span><br><span class="line">    npidle     uint32</span><br><span class="line">    nmspinning uint32 &#x2F;&#x2F; See &quot;Worker thread parking&#x2F;unparking&quot; comment in proc.go.</span><br><span class="line">    &#x2F;&#x2F; goroutine全局运行队列</span><br><span class="line">    runq     gQueue</span><br><span class="line">    runqsize int32</span><br><span class="line">    ......</span><br><span class="line">    &#x2F;&#x2F; gFree是所有已经退出的goroutine对应的g结构体对象组成的链表</span><br><span class="line">    &#x2F;&#x2F; 用于缓存g结构体对象，避免每次创建goroutine时都重新分配内存</span><br><span class="line">    gFree struct &#123;</span><br><span class="line">        lock          mutex</span><br><span class="line">        stack        gList &#x2F;&#x2F; Gs with stacks</span><br><span class="line">        noStack   gList &#x2F;&#x2F; Gs without stacks</span><br><span class="line">        n              int32</span><br><span class="line">    &#125;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="p"><a href="#p" class="headerlink" title="p"></a>p</h3><p>因为全局运行队列是临界资源，每个工作线程都可读，访问它需要加锁，影响调度器性能。所以调度器为每个工作线程引入<code>p</code>结构体来保存一个私有的goroutine局部运行队列，工作线程优先用局部运行队列获取goroutine进行调度，提高工作线程的并行性。</p>
<p>所以，每个工作线程都会和一个<code>p</code>对象关联。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">type p struct &#123;</span><br><span class="line">    lock mutex</span><br><span class="line">    status       uint32 &#x2F;&#x2F; one of pidle&#x2F;prunning&#x2F;...</span><br><span class="line">    link            puintptr</span><br><span class="line">    schedtick   uint32     &#x2F;&#x2F; incremented on every scheduler call</span><br><span class="line">    syscalltick  uint32     &#x2F;&#x2F; incremented on every system call</span><br><span class="line">    sysmontick  sysmontick &#x2F;&#x2F; last tick observed by sysmon</span><br><span class="line">    m                muintptr   &#x2F;&#x2F; back-link to associated m (nil if idle)</span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 本地goroutine运行队列</span><br><span class="line">    runqhead uint32 &#x2F;&#x2F; 队列头</span><br><span class="line">    runqtail uint32 &#x2F;&#x2F; 队列尾</span><br><span class="line">    runq     [256]guintptr &#x2F;&#x2F; 使用数组实现的循环队列</span><br><span class="line">    runnext guintptr</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Available G&#39;s (status &#x3D;&#x3D; Gdead)</span><br><span class="line">    gFree struct &#123;</span><br><span class="line">        gList</span><br><span class="line">        n int32</span><br><span class="line">    &#125;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="m"><a href="#m" class="headerlink" title="m"></a>m</h3><p>调度器用<code>m</code>结构体保存工作线程的状态，包括工作线程的栈起始位置、当前正在运行的goroutine、是否空闲等，还通过指针维持<code>p</code>对象的绑定关系。每个工作线程和一个<code>m</code>对象对应。</p>
<p>所以，通过<code>m</code>对象，可以找到它正在运行的goroutine，也可以间接通过<code>p</code>对象找到局部运行队列。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">type m struct &#123;</span><br><span class="line">    g0      *g &#x2F;&#x2F; 用来记录工作线程使用的栈信息，在执行调度代码时需要使用这个栈。执行用户goroutine代码时，使用用户goroutine自己的栈，调度时会发生栈的切换</span><br><span class="line">    tls           [6]uintptr &#x2F;&#x2F; 通过TLS实现m结构体对象与工作线程之间的绑定</span><br><span class="line">    mstartfn      func()</span><br><span class="line">    curg          *g &#x2F;&#x2F; 指向工作线程正在运行的goroutine的g结构体对象</span><br><span class="line"></span><br><span class="line">    p             puintptr &#x2F;&#x2F; 记录与当前工作线程绑定的p结构体对象</span><br><span class="line">    nextp         puintptr</span><br><span class="line">    oldp          puintptr</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; spinning状态：表示当前工作线程正在试图从其它工作线程的本地运行队列偷取goroutine</span><br><span class="line">    spinning      bool &#x2F;&#x2F; m is out of work and is actively looking for work</span><br><span class="line">    blocked       bool &#x2F;&#x2F; m is blocked on a note</span><br><span class="line"></span><br><span class="line">    park          note &#x2F;&#x2F; 没有goroutine需要运行时，工作线程睡眠在这个park成员上，其它线程通过这个park唤醒该工作线程</span><br><span class="line">    alllink       *m &#x2F;&#x2F; 记录所有工作线程的一个链表</span><br><span class="line">    schedlink     muintptr</span><br><span class="line"></span><br><span class="line">    thread        uintptr &#x2F;&#x2F; 线程ID</span><br><span class="line">    freelink      *m      &#x2F;&#x2F; on sched.freem</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>工作线程执行的代码是如何找到属于自己的<code>m</code>对象的呢？答案是通过线程本地存储。每个工作线程拥有各自私有的<code>m</code>对象，在不同的工作线程中，使用相同的全局变量名来访问不同的<code>m</code>对象。</p>
<blockquote>
<p>在gcc中，在定义全局变量时增加__thread，这样该变量就变成线程私有变量了。</p>
</blockquote>
<p>在goroutine调度器中，每个工作线程在被创建后，线程本地存储机制就为该线程实现一个指向<code>m</code>对象的私有全局变量。这个工作线程的代码就可以使用该全局变量访问自己的<code>m</code>对象以及和<code>m</code>对象关联的<code>p</code>对象和<code>g</code>对象。</p>
<h3 id="stack"><a href="#stack" class="headerlink" title="stack"></a>stack</h3><p><code>stack</code>结构体用于记录goroutine使用的栈的起始和结束位置。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">type stack struct &#123;  </span><br><span class="line">    lo uintptr    &#x2F;&#x2F; 栈顶，指向内存低地址</span><br><span class="line">    hi uintptr    &#x2F;&#x2F; 栈底，指向内存高地址</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="gobuf"><a href="#gobuf" class="headerlink" title="gobuf"></a>gobuf</h3><p><code>gobuf</code>结构体用于保存goroutine的调度信息，包括CPU的几个寄存器的值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">type gobuf struct &#123;</span><br><span class="line">    sp   uintptr  &#x2F;&#x2F; 保存rsp寄存器的值</span><br><span class="line">    pc   uintptr  &#x2F;&#x2F; 保存rip寄存器的值</span><br><span class="line">    g    guintptr &#x2F;&#x2F; 记录当前这个gobuf对象属于哪个goroutine</span><br><span class="line">    ctxt unsafe.Pointer</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 保存系统调用的返回值，因为从系统调用返回之后如果p被其它工作线程抢占，</span><br><span class="line">    &#x2F;&#x2F; 则这个goroutine会被放入全局运行队列被其它工作线程调度，其它线程需要知道系统调用的返回值。</span><br><span class="line">    ret  sys.Uintreg  </span><br><span class="line">    lr   uintptr</span><br><span class="line"></span><br><span class="line">    bp   uintptr &#x2F;&#x2F; 保存rip寄存器的值</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="全局变量"><a href="#全局变量" class="headerlink" title="全局变量"></a>全局变量</h3><p>一些重要的全局变量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">allgs     []*g &#x2F;&#x2F; 保存所有的g</span><br><span class="line">allm       *m &#x2F;&#x2F; 所有的m构成的一个链表，包括下面的m0</span><br><span class="line">allp       []*p &#x2F;&#x2F; 保存所有的p，len(allp) &#x3D;&#x3D; gomaxprocs</span><br><span class="line">ncpu             int32 &#x2F;&#x2F; 系统中cpu核的数量，程序启动时由runtime代码初始化</span><br><span class="line">gomaxprocs int32  &#x2F;&#x2F; p的最大值，默认等于ncpu，但可以通过GOMAXPROCS修改</span><br><span class="line">sched      schedt &#x2F;&#x2F; 调度器结构体对象，记录了调度器的工作状态</span><br><span class="line">m0  m  &#x2F;&#x2F; 代表进程的主线程</span><br><span class="line">g0   g &#x2F;&#x2F; m0的g0，也就是m0.g0 &#x3D; &amp;g0</span><br></pre></td></tr></table></figure>

<p>这些全局变量会被初始化为0值(指针会被初始化为nil指针，切片初始化为nil切片，int被初始化为数字0，结构体的所有成员变量按其本类型初始化为其类型的0值)。所以程序刚启动时allgs，allm和allp都不包含任何g、m、p。</p>
<h1 id="goroutine调度器"><a href="#goroutine调度器" class="headerlink" title="goroutine调度器"></a>goroutine调度器</h1><h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><p>goroutine调度器本质是按照一定的算法把大量的goroutine分配到少量的线程上利用CPU去运行，充分利用多核CPU并行。</p>
<p>工作流程简易地可以用下面伪代码描述。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">for i :&#x3D; 0; i &lt; N; i++ &#123; &#x2F;&#x2F; 创建N个线程执行schedule函数</span><br><span class="line">     create_os_thread(schedule) &#x2F;&#x2F; 创建一个线程执行schedule函数</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 定义一个线程私有全局变量，它是一个指向m对象的指针</span><br><span class="line">&#x2F;&#x2F; 真实的调度器中，不光是schedule函数需要访问m，其它很多地方也需要访问m，所以将其定义成私有全局变量。</span><br><span class="line">ThreadLocal self *m</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; schedule函数实现调度逻辑</span><br><span class="line">func schedule() &#123;</span><br><span class="line">    &#x2F;&#x2F; 创建和初始化m结构体对象，并赋值给私有全局变量self</span><br><span class="line">    self &#x3D; initm()  </span><br><span class="line">    for &#123; &#x2F;&#x2F; 调度循环</span><br><span class="line">          if (self.p.runqueue is empty) &#123;</span><br><span class="line">                 &#x2F;&#x2F; 根据某种算法从全局运行队列中找出一个需要运行的goroutine</span><br><span class="line">                 g :&#x3D; find_a_runnable_goroutine_from_global_runqueue()</span><br><span class="line">           &#125; else &#123;</span><br><span class="line">                 &#x2F;&#x2F; 根据某种算法从私有的局部运行队列中找出一个需要运行的goroutine</span><br><span class="line">                 g :&#x3D; find_a_runnable_goroutine_from_local_runqueue()</span><br><span class="line">           &#125;</span><br><span class="line">          run_g(g) &#x2F;&#x2F; CPU运行该goroutine，直到需要调度其它goroutine才返回</span><br><span class="line">          save_status_of_g(g) &#x2F;&#x2F; 保存goroutine的状态，主要是寄存器的值</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="调度器的设计策略"><a href="#调度器的设计策略" class="headerlink" title="调度器的设计策略"></a>调度器的设计策略</h2><ol>
<li>复用线程：避免频繁地创建、销毁线程。</li>
</ol>
<ul>
<li>work stealing：当某个M无可运行的G时，从其他M绑定的P偷取G，而不是销毁线程。</li>
<li>hand off：当某个M因为G进行系统调用阻塞时，M释放绑定的P，将P由其他空闲的M绑定并运行。</li>
</ul>
<ol start="2">
<li>利用并行：<code>GOMAXPROCS</code>设置P的数量，最多有<code>GOMAXPROCS</code>个线程分布在CPU上并行。</li>
<li>抢占：不同于coroutine的非抢占式，从go1.14开始，goroutine的调度器是抢占式的，一个goroutine占用CPU的时间是被限制的。</li>
<li>全局G队列：依然有全局G队列。但是只有在M执行work stealing从其他P偷不到G时，才从全局G队列获取。</li>
</ol>
<blockquote>
<p>下一篇会简单分析下Golang调度器的源码。</p>
</blockquote>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1].UNIX环境高级编程（第3版）<a href="https://book.douban.com/subject/25900403/" target="_blank" rel="noopener">https://book.douban.com/subject/25900403/</a><br>[2].<a href="https://www.backblaze.com/blog/whats-the-diff-programs-processes-and-threads/" target="_blank" rel="noopener">https://www.backblaze.com/blog/whats-the-diff-programs-processes-and-threads/</a><br>[3].<a href="https://learnku.com/articles/41728" target="_blank" rel="noopener">https://learnku.com/articles/41728</a><br>[4].<a href="https://mp.weixin.qq.com/mp/homepage?__biz=MzU1OTg5NDkzOA==&amp;hid=1&amp;sn=8fc2b63f53559bc0cee292ce629c4788&amp;scene=1&amp;devicetype=android-29&amp;version=2800015d&amp;lang=zh_CN&amp;nettype=3gnet&amp;ascene=7&amp;session_us=gh_8b5b60477260&amp;wx_header=1" target="_blank" rel="noopener">https://mp.weixin.qq.com/mp/homepage?__biz=MzU1OTg5NDkzOA==&amp;hid=1&amp;sn=8fc2b63f53559bc0cee292ce629c4788&amp;scene=1&amp;devicetype=android-29&amp;version=2800015d&amp;lang=zh_CN&amp;nettype=3gnet&amp;ascene=7&amp;session_us=gh_8b5b60477260&amp;wx_header=1</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://pearlzju.github.io/2021/06/16/%E3%80%8AKubernetes%20In%20Action%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(%E4%BA%8C)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pearl">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/face.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pearl 的个人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/16/%E3%80%8AKubernetes%20In%20Action%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(%E4%BA%8C)/" itemprop="url">《Kubernetes In Action》阅读笔记(二)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-06-16T11:06:05+08:00">
                2021-06-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" itemprop="url" rel="index">
                    <span itemprop="name">计算机</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/06/16/%E3%80%8AKubernetes%20In%20Action%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(%E4%BA%8C)/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2021/06/16/%E3%80%8AKubernetes%20In%20Action%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(%E4%BA%8C)/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2021/06/16/%E3%80%8AKubernetes%20In%20Action%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(%E4%BA%8C)/" class="leancloud_visitors" data-flag-title="《Kubernetes In Action》阅读笔记(二)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<blockquote>
<p>本文是把《Kubernetes In Action》读薄的摘抄或转述，仅供参考。系统学习请阅读原书。<br>k8s的命令繁多，熟练使用它们提高工作效率和理解k8s设计思想同等重要，每章最后总结了该章涉及的命令。</p>
</blockquote>
<img width="300" src="/images/Kubernetes In Action阅读笔记/0.png">

<h1 id="7-ConfigMap-和-Secret-：配置应用程序-195"><a href="#7-ConfigMap-和-Secret-：配置应用程序-195" class="headerlink" title="7 ConfigMap 和 Secret ：配置应用程序 195"></a>7 ConfigMap 和 Secret ：配置应用程序 195</h1><h2 id="7-1-配置容器化应用程序-195"><a href="#7-1-配置容器化应用程序-195" class="headerlink" title="7.1 配置容器化应用程序 195"></a>7.1 配置容器化应用程序 195</h2><p>因为pod的设计理念是无状态的，所以需要提供一种方式让pod中的应用可以读取到相应的配置文件。configMap就提供了一个集群级别的服务，让pod根据需求读取相应的配置（配置信息本质上是KV，不过可以以多种方式挂载）。</p>
<p>或者，pod的启动需要拉取registry的镜像，而registry可能会有授权认证，这时候就需要pod有认证信息，但是又不能直接将认证信息写进pod的配置（不然就所有的人都能看到了），所以最好能有一种等pod启动后再加载的相对安全的方式，这就是secret了。</p>
<p>使用configMap和secret的优点在于，配置可以动态的变化，而且容器完全不会感知到configMap和secret的存在，而是通过文件挂载等方式直接读取，不需要和configMap等直接交互。</p>
<h2 id="7-2-向容器传递命令行参数-196"><a href="#7-2-向容器传递命令行参数-196" class="headerlink" title="7.2 向容器传递命令行参数 196"></a>7.2 向容器传递命令行参数 196</h2><h3 id="7-2-1-在-Docker-中定义命令与参数-196"><a href="#7-2-1-在-Docker-中定义命令与参数-196" class="headerlink" title="7.2.1 在 Docker 中定义命令与参数 196"></a>7.2.1 在 Docker 中定义命令与参数 196</h3><p>容器中运行的完整指令由两部分组成：命令与参数。</p>
<p>Dockerfile中的两种指令分别定义命令与参数这两个部分：</p>
<ul>
<li>ENTRYPOINT 定义容器启动时被调用的可执行程序。</li>
<li>CMD 指定传递给 ENTRYPOINT 的参数。</li>
</ul>
<p>尽管可以直接使用CMD指令指定镜像运行时想要执行的命令，正确的做法依旧是借助ENTRYPOINT指令，仅仅用 CMD 指定所需的默认参数。镜像中定义的CMD可以被覆盖，而ENTRYPOINT无法被覆盖。</p>
<p>上述两条指令均支持以下两种形式：</p>
<ul>
<li>shell 形式：如 ENTRYPOINT node app . js。</li>
<li>exec 形式：如 ENTRYPOINT [＂node＂,＂app . js＂]。</li>
</ul>
<p>两者的区别在于指定的命令是否是在shell中被调用。<br>采用shell形式，PID 1是shell进程而非node进程，node进程于shell中启动。shell进程往往是多余的。所以通常可以直接采用exec形式的ENTRYPOINT指令。</p>
<h3 id="7-2-2-在-Kubernetes-中覆盖命令和参数-199"><a href="#7-2-2-在-Kubernetes-中覆盖命令和参数-199" class="headerlink" title="7.2.2 在 Kubernetes 中覆盖命令和参数 199"></a>7.2.2 在 Kubernetes 中覆盖命令和参数 199</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kind: pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: some&#x2F;image</span><br><span class="line">    command: [&quot;bin&#x2F;command&quot;]</span><br><span class="line">    args: [&quot;arg1&quot;, &quot;arg2&quot;, &quot;arg3&quot;]</span><br></pre></td></tr></table></figure>

<p>Docker的ENTRYPOINT对应k8s的command，描述容器中运行的可执行文件。<br>Docker的CMD对应k8s的args，描述传给可执行文件的参数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: fortune2s</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa&#x2F;fortune:args</span><br><span class="line">    args: [&quot;2&quot;] # 该参数覆盖dockerfile中的CMD</span><br><span class="line">    name: html-generator</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: html</span><br><span class="line">      mountPath: &#x2F;var&#x2F;htdocs</span><br><span class="line">  volumes:</span><br><span class="line">  - name: html</span><br><span class="line">    emptyDir: &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>少量参数值的设置可以使用数组表示。多参数值情况下可以采用如下标记：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">args:</span><br><span class="line">- foo # 字符串不需要引号标记</span><br><span class="line">- bar</span><br><span class="line">- &quot;15&quot; # 数值需要引号标记</span><br></pre></td></tr></table></figure>

<h2 id="7-3-为容器设置环境变量-200"><a href="#7-3-为容器设置环境变量-200" class="headerlink" title="7.3 为容器设置环境变量 200"></a>7.3 为容器设置环境变量 200</h2><h3 id="7-3-1-在容器定义中指定环境变量-201"><a href="#7-3-1-在容器定义中指定环境变量-201" class="headerlink" title="7.3.1 在容器定义中指定环境变量 201"></a>7.3.1 在容器定义中指定环境变量 201</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa&#x2F;fortune:env</span><br><span class="line">    env:</span><br><span class="line">    - name: INTERVAL # 在环境变量列表中添加一个新变量</span><br><span class="line">      value: &quot;30&quot;</span><br><span class="line">    name: html-generator</span><br></pre></td></tr></table></figure>

<h3 id="7-3-2-在环境变量值中引用其他环境变量-201"><a href="#7-3-2-在环境变量值中引用其他环境变量-201" class="headerlink" title="7.3.2 在环境变量值中引用其他环境变量 201"></a>7.3.2 在环境变量值中引用其他环境变量 201</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">env:</span><br><span class="line">- name: FIRST_VAR</span><br><span class="line">  value: &quot;foo&quot;</span><br><span class="line">- name: SECOND_VAR</span><br><span class="line">  value: &quot;$(FIRST_VAR)bar&quot;</span><br></pre></td></tr></table></figure>

<h3 id="7-3-3-了解硬编码环境变量的不足之处-202"><a href="#7-3-3-了解硬编码环境变量的不足之处-202" class="headerlink" title="7.3.3 了解硬编码环境变量的不足之处 202"></a>7.3.3 了解硬编码环境变量的不足之处 202</h3><p>pod定义硬编码意味着需要有效区分生产和开发环境的pod定义。如果想在多个环境中能复用pod的定义，需要将配置从pod定义中解耦出来。——可以通过ConfigMap的资源对象完成解耦。</p>
<h2 id="7-4-利用-ConfigMap-解耦配置-202"><a href="#7-4-利用-ConfigMap-解耦配置-202" class="headerlink" title="7.4 利用 ConfigMap 解耦配置 202"></a>7.4 利用 ConfigMap 解耦配置 202</h2><p><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configMap/" target="_blank" rel="noopener">configMap的官方文档</a></p>
<h3 id="7-4-1-ConfigMap-介绍-202"><a href="#7-4-1-ConfigMap-介绍-202" class="headerlink" title="7.4.1 ConfigMap 介绍 202"></a>7.4.1 ConfigMap 介绍 202</h3><p>k8s允许将配置选项分离到单独的资源对象ConfigMap中，本质上就是一个键/值对映射。</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/29.png">

<img width="500" src="/images/Kubernetes In Action阅读笔记/30.png">

<h3 id="7-4-2-创建-ConfigMap-203"><a href="#7-4-2-创建-ConfigMap-203" class="headerlink" title="7.4.2 创建 ConfigMap 203"></a>7.4.2 创建 ConfigMap 203</h3><p>configMap创建自多种选项：完整文件夹、单独文件、自定义键名的条目下的文件（替代文件名作键名）以及字面量。</p>
<p>多种形式创建 configMap：</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/31.png">

<h3 id="7-4-3-给容器传递-ConfigMap-条目作为环境变量-206"><a href="#7-4-3-给容器传递-ConfigMap-条目作为环境变量-206" class="headerlink" title="7.4.3 给容器传递 ConfigMap 条目作为环境变量 206"></a>7.4.3 给容器传递 ConfigMap 条目作为环境变量 206</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa&#x2F;fortune:env</span><br><span class="line">    env:</span><br><span class="line">    - name: INTERVAL # 设置环境变量INTERVAL</span><br><span class="line">      valueFrom: </span><br><span class="line">        configMapKeyRef: # 用ConfigMap初始化，不设定固定值</span><br><span class="line">          name: fortune-config # 引用的ConfigMap名称</span><br><span class="line">          key: sleep-interval # 环境变量值被设置为ConfigMap下对应键的值</span><br></pre></td></tr></table></figure>

<p>如果pod中引用了不存在的configMap会导致pod启动失败。如果稍后创建了该configMap后，pod就会自动启动。</p>
<h3 id="7-4-4-一次性传递-ConfigMap-的所有条目作为环境变量-208"><a href="#7-4-4-一次性传递-ConfigMap-的所有条目作为环境变量-208" class="headerlink" title="7.4.4 一次性传递 ConfigMap 的所有条目作为环境变量 208"></a>7.4.4 一次性传递 ConfigMap 的所有条目作为环境变量 208</h3><p>可以通过<code>envFrom</code>属性字段将所有条目暴露作为环境变量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - image: some-image</span><br><span class="line">      envFrom:</span><br><span class="line">        prefix: CONFIG_ # 环境变量名为&#96;CONFIG_&#123;name&#125;&#96;</span><br><span class="line">        configMapRef:</span><br><span class="line">          name: my-config-map # configMap name</span><br></pre></td></tr></table></figure>

<p>configMap里的名字必须符合环境变量格式才能被转为环境变量。k8s不会主动转换键名（例如不会将破折号转换为下画线）。如果configMap的某键名格式不正确，创建环境变量时会忽略对应的条目（忽略时不会发出事件通知）。</p>
<h3 id="7-4-5-传递-ConfigMap-条目作为命令行参数-209"><a href="#7-4-5-传递-ConfigMap-条目作为命令行参数-209" class="headerlink" title="7.4.5 传递 ConfigMap 条目作为命令行参数 209"></a>7.4.5 传递 ConfigMap 条目作为命令行参数 209</h3><p>在字段<code>pod.spec.containers.args</code>中无法直接引用configMap的条目，但是可以利用configMap条目初始化某个环境变量，然后再在参数字段中引用该环境变量，形如 “$ENV_VAR”。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa&#x2F;fortune:args</span><br><span class="line">    env:</span><br><span class="line">    - name: INTERVAL</span><br><span class="line">      valueFrom: </span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: fortune-config</span><br><span class="line">          key: sleep-interval</span><br><span class="line">    args: [&quot;$(INTERVAL)&quot;] # 在参数设置中引用环境变量</span><br></pre></td></tr></table></figure>

<h3 id="7-4-6-使用-configMap-卷将条目暴露为文件-210"><a href="#7-4-6-使用-configMap-卷将条目暴露为文件-210" class="headerlink" title="7.4.6 使用 configMap 卷将条目暴露为文件 210"></a>7.4.6 使用 configMap 卷将条目暴露为文件 210</h3><p>configMap卷会将configMap中的每个条目均暴露成一个文件。key 为文件名，value 为文件内容。运行在容器中的进程可通过读取文件内容获得对应的条目值，所以可以用configMap来保存配置文件。</p>
<p>volume声明可以直接声明configMap，将configMap条目作为容器卷中的文件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx:alpine</span><br><span class="line">    name: web-server</span><br><span class="line">    volumeMounts: # 通过volume挂载configMap volume</span><br><span class="line">		...</span><br><span class="line">    - name: config</span><br><span class="line">      mountPath: &#x2F;etc&#x2F;nginx&#x2F;conf.d # 挂载configMap卷至这个位置</span><br><span class="line">      readOnly: true</span><br><span class="line">		...</span><br><span class="line">  volumes:</span><br><span class="line">  - name: config</span><br><span class="line">    configMap:</span><br><span class="line">      name: fortune-config # 卷定义引用fortune-config configMap</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<img width="500" src="/images/Kubernetes In Action阅读笔记/32.png">

<p>挂载任意一种卷时均可以使用<code>subPath</code>属性。可以选择挂载部分卷而不是挂载完整的卷。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: some&#x2F;image</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: myvolume</span><br><span class="line">      mountPath: &#x2F;etc&#x2F;someconfig.conf # 挂载至某一文件，而不是文件夹</span><br><span class="line">      subPath: myconfig.conf # 仅挂载指定的条目的myconfig.conf，并非完整的卷</span><br></pre></td></tr></table></figure>

<p>configMap卷中所有文件的权限默认被设置为644，可以通过卷规则定义中的<code>defaultMode</code>属性改变默认权限。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">volume:</span><br><span class="line">- name: config</span><br><span class="line">  configMap:</span><br><span class="line">    name: fortune-config</span><br><span class="line">    defaultMode: &quot;6600&quot;</span><br></pre></td></tr></table></figure>

<h3 id="7-4-7-更新应用配置且不重启应用程序-216"><a href="#7-4-7-更新应用配置且不重启应用程序-216" class="headerlink" title="7.4.7 更新应用配置且不重启应用程序 216"></a>7.4.7 更新应用配置且不重启应用程序 216</h3><p>将configMap暴露为卷可以达到配置热更新的效果，无须重新创建pod或者重启容器。</p>
<p>如果挂载的是容器中的单个文件而不是完整的卷，configMap更新之后对应的文件不会被更新。 热更新只能运用于挂载整个文件夹。</p>
<h2 id="7-5-使用-Secret-给容器传递敏感数据-218"><a href="#7-5-使用-Secret-给容器传递敏感数据-218" class="headerlink" title="7.5 使用 Secret 给容器传递敏感数据 218"></a>7.5 使用 Secret 给容器传递敏感数据 218</h2><p><a href="https://kubernetes.io/docs/concepts/configuration/secret/" target="_blank" rel="noopener">secret的官方文档</a></p>
<h3 id="7-5-1-介绍-Secret-218"><a href="#7-5-1-介绍-Secret-218" class="headerlink" title="7.5.1 介绍 Secret 218"></a>7.5.1 介绍 Secret 218</h3><p>secret和configMap最大的区别在于，secrets用于保存敏感的数据。<br>secret的数据都不会被写入磁盘，而是挂载在内存盘中。</p>
<h3 id="7-5-2-默认令牌-Secret-介绍-218"><a href="#7-5-2-默认令牌-Secret-介绍-218" class="headerlink" title="7.5.2 默认令牌 Secret 介绍 218"></a>7.5.2 默认令牌 Secret 介绍 218</h3><p><code>default-tokenSecret</code>会被自动创建且对应的卷被自动挂载到每个pod上。</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/33.png">

<h3 id="7-5-3-创建-Secret-220"><a href="#7-5-3-创建-Secret-220" class="headerlink" title="7.5.3 创建 Secret 220"></a>7.5.3 创建 Secret 220</h3><p>与创建ConfigMap的过程类似。用<code>kubectl create secret</code>创建secret。</p>
<h3 id="7-5-4-对比-ConfigMap-与-Secret-221"><a href="#7-5-4-对比-ConfigMap-与-Secret-221" class="headerlink" title="7.5.4 对比 ConfigMap 与 Secret 221"></a>7.5.4 对比 ConfigMap 与 Secret 221</h3><p>Secret条目的内容会被以Base64格式编码，而configMap直接以纯文本展示。采用Base64的原因在于，secret的条目可以涵盖二进制数据。</p>
<blockquote>
<p>Secret的大小限于1MB。</p>
</blockquote>
<p>k8s允许通过Secret的stringData字段设置条目的纯文本值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kind: Secret</span><br><span class="line">apiVersion: v1</span><br><span class="line">stringData: # 可以被用来设置非二进制数据</span><br><span class="line">  foo: plain text # 可以看出值未被Base64编码</span><br><span class="line">data:</span><br><span class="line">  https.cert: xxx</span><br><span class="line">  https.key: xxx</span><br></pre></td></tr></table></figure>

<h3 id="7-5-5-在-pod-中使用-Secret-222"><a href="#7-5-5-在-pod-中使用-Secret-222" class="headerlink" title="7.5.5 在 pod 中使用 Secret 222"></a>7.5.5 在 pod 中使用 Secret 222</h3><p>挂载fortune-secret至pod。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: fortune-https</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa&#x2F;fortune:env</span><br><span class="line">    name: html-generator</span><br><span class="line">    env:</span><br><span class="line">    - name: INTERVAL</span><br><span class="line">      valueFrom: </span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: fortune-config</span><br><span class="line">          key: sleep-interval</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: html</span><br><span class="line">      mountPath: &#x2F;var&#x2F;htdocs</span><br><span class="line">  - image: nginx:alpine</span><br><span class="line">    name: web-server</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: html</span><br><span class="line">      mountPath: &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html</span><br><span class="line">      readOnly: true</span><br><span class="line">    - name: config</span><br><span class="line">      mountPath: &#x2F;etc&#x2F;nginx&#x2F;conf.d</span><br><span class="line">      readOnly: true</span><br><span class="line">    - name: certs</span><br><span class="line">      mountPath: &#x2F;etc&#x2F;nginx&#x2F;certs&#x2F; # 配置Nginx从&#x2F;etc&#x2F;nginx&#x2F;certs中读取证书和密钥文件，需将secret卷挂载于此</span><br><span class="line">      readOnly: true</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 80</span><br><span class="line">    - containerPort: 443</span><br><span class="line">  volumes:</span><br><span class="line">  - name: html</span><br><span class="line">    emptyDir: &#123;&#125;</span><br><span class="line">  - name: config</span><br><span class="line">    configMap:</span><br><span class="line">      name: fortune-config</span><br><span class="line">      items:</span><br><span class="line">      - key: my-nginx-config.conf</span><br><span class="line">        path: https.conf</span><br><span class="line">  - name: certs</span><br><span class="line">    secret: # 这里引用fortune-https secret来定义secret卷</span><br><span class="line">      secretName: fortune-https</span><br></pre></td></tr></table></figure>

<img width="600" src="/images/Kubernetes In Action阅读笔记/34.png">

<p>由于挂载时使用的是tmpfs，存储在Secret中的数据不会写入磁盘。</p>
<p>k8s允许通过环境变量暴露Secret，然而此特性的使用往往不是一个好主意。应用程序通常会在错误报告时转储环境变量，或者是启动时打印在应用日志中，无意中暴露了Secret信息。另外，子进程会继承父进程的所有环境变量，如果是通过第三方二进制程序启动应用，你并不知道它使用敏感数据做了什么。提示由于敏感数据可能在无意中被暴露，通过环境变量暴露Secret给容器之前请再三思考。为了确保安全性，请始终采用secret卷的方式暴露Secret。</p>
<h2 id="7-6-本章的k8s命令-228"><a href="#7-6-本章的k8s命令-228" class="headerlink" title="7.6 本章的k8s命令 228"></a>7.6 本章的k8s命令 228</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">########## ConfigMap ##########  </span><br><span class="line"></span><br><span class="line"># 创建一个ConfigMap，指定字面量</span><br><span class="line">$ kubectl create configmap fortune-config --from-literal&#x3D;sleep-interval&#x3D;25</span><br><span class="line"></span><br><span class="line"># 创建一个ConfigMap，从文件内容创建</span><br><span class="line">$ kubectl create configmap my-config --from-file&#x3D;customkey&#x3D;config-file.conf</span><br><span class="line"></span><br><span class="line"># 创建一个ConfigMap，从文件夹创建</span><br><span class="line">$ kubectl create configmap my-config --from-file&#x3D;&#x2F;path&#x2F;to&#x2F;dir</span><br><span class="line"></span><br><span class="line"># 修改ConfigMap</span><br><span class="line">$ kubectl edit configmap fortune-config</span><br><span class="line"></span><br><span class="line"># 重启nginx</span><br><span class="line">$ kubectl exec fortune-configmap-volume -c web-server -- nginx -s reload</span><br><span class="line"></span><br><span class="line">########## Secret ##########  </span><br><span class="line"></span><br><span class="line"># 创建一个Secret</span><br><span class="line">$ kubectl create secret generic fortune-https --from-file&#x3D;https.key --from-file&#x3D;https.cert --from-file&#x3D;foo</span><br><span class="line"></span><br><span class="line"># 列出容器的挂载点</span><br><span class="line">$ kubectl exec fortune-https -c web-server -- mount | grep certs</span><br></pre></td></tr></table></figure>

<h1 id="8-从应用访问-pod-元数据以及其他资源-229"><a href="#8-从应用访问-pod-元数据以及其他资源-229" class="headerlink" title="8 从应用访问 pod 元数据以及其他资源 229"></a>8 从应用访问 pod 元数据以及其他资源 229</h1><h2 id="8-1-通过-Downward-API-传递元数据-229"><a href="#8-1-通过-Downward-API-传递元数据-229" class="headerlink" title="8.1 通过 Downward API 传递元数据 229"></a>8.1 通过 Downward API 传递元数据 229</h2><p><a href="https://kubernetes.io/zh/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#downward-api" target="_blank" rel="noopener">downward-api的官方文档</a></p>
<p>有时候，容器里的应用会需要获取到pod的metadata，或者node的一些信息，举几个例子来说:</p>
<ul>
<li>应用希望获取到podmetadata中设置的labels。</li>
<li>应用需要调用主机上的一些端口（如daemonset），所以需要获取到主机的IP。</li>
</ul>
<p>DownwardAPI允许我们通过环境变量或者文件（在downwardAPI卷中）的传递pod和node的元数据。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/35.png">

<p>和configMap和secret类似，downwardAPI也是以volume的形式挂载。</p>
<h3 id="8-1-1-了解可用的元数据-230"><a href="#8-1-1-了解可用的元数据-230" class="headerlink" title="8.1.1 了解可用的元数据 230"></a>8.1.1 了解可用的元数据 230</h3><p>Downward API 可以给在pod 中运行的进程暴露pod的元数据。目前我们可以给容器传递以下数据：</p>
<ul>
<li>pod 的名称</li>
<li>pod 的IP</li>
<li>pod 所在的命名空间</li>
<li>pod 运行节点的名称</li>
<li>pod 运行所归属的服务账户的名称</li>
<li>每个容器请求的 CPU 和内存的使用量</li>
<li>每个容器可以使用的 CPU 和内存的限制</li>
<li>pod 的标签</li>
<li>pod 的注解</li>
</ul>
<h3 id="8-1-2-通过环境变量暴露元数据-231"><a href="#8-1-2-通过环境变量暴露元数据-231" class="headerlink" title="8.1.2 通过环境变量暴露元数据 231"></a>8.1.2 通过环境变量暴露元数据 231</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: main</span><br><span class="line">      ...</span><br><span class="line">      env:</span><br><span class="line">      - name: POD_NAME</span><br><span class="line">        valueFrom:</span><br><span class="line">          fieldRef: # 引用pod manifest中的元数据名称字段，而不是设定一个具体的值</span><br><span class="line">            fieldPath: metadata.name</span><br><span class="line">      - name: CONTAINER_CPU_REQUEST_MILLICORES</span><br><span class="line">        valueFrom:</span><br><span class="line">          resourceFieldRef:  # 容器请求的CPU和内存使用量是引用resourceFieldRef字段而不是filedRef字段</span><br><span class="line">            resource: requests.cpu</span><br><span class="line">            divisor: 1m  # 设定基数，从而生成每一部分的值</span><br><span class="line">      - name: CONTAINER_MEMORY_LIMIT_KIBIBYTES</span><br><span class="line">        valueFrom:</span><br><span class="line">          resourceFieldRef:</span><br><span class="line">            resource: limits.memory</span><br><span class="line">            divisor: 1Ki</span><br></pre></td></tr></table></figure>

<p>获取资源用量的字段是<code>resourceFieldRef</code>。</p>
<p>对于暴露资源请求和使用限制的环境变量，我们会设定一个基数单位(divisor)。 实际的资源请求值和限制值除以这个基数单位，所得的结果通过环境变量暴露出去。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/36.png">

<h3 id="8-1-3-通过-downwardAPI-卷来传递元数据-234"><a href="#8-1-3-通过-downwardAPI-卷来传递元数据-234" class="headerlink" title="8.1.3 通过 downwardAPI 卷来传递元数据 234"></a>8.1.3 通过 downwardAPI 卷来传递元数据 234</h3><p>如果更倾向于使用文件的方式而不是环境变量的方式暴露元数据，可以定义一个downwardAPI卷并挂载到容器中。</p>
<p>可以在pod运行时修改标签和注解。当标签和注解被修改后，k8s会更新存有相关信息的文件， 从而使pod可以获取最新的数据。这也解释了为什么不要通过环境变量的方式暴露标签和注解，在环境变量方式下，一旦标签和注解被修改，环境变量不会被动态更新。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: downward # 通过downwardAPI卷来暴露这些标签和注解</span><br><span class="line">  labels:</span><br><span class="line">    foo: bar</span><br><span class="line">  annotations:</span><br><span class="line">    key1: value1</span><br><span class="line">    key2: |</span><br><span class="line">      multi</span><br><span class="line">      line</span><br><span class="line">      value</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">		...</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: downward</span><br><span class="line">      mountPath: &#x2F;etc&#x2F;downward # 在&#x2F;etc&#x2F;downward目录下挂载这个downward卷</span><br><span class="line">  volumes:</span><br><span class="line">  - name: downward # 通过将卷的名字设定为downward来定义一个downwardAPI卷</span><br><span class="line">    downwardAPI:</span><br><span class="line">      items:</span><br><span class="line">      - path: &quot;podName&quot; # pod的名称(来自manifest文件中的manifest.name字段)将被写入podName文件中</span><br><span class="line">        fieldRef:</span><br><span class="line">          fieldPath: metadata.name</span><br><span class="line">      - path: &quot;podNamespace&quot;</span><br><span class="line">        fieldRef:</span><br><span class="line">          fieldPath: metadata.namespace</span><br><span class="line">      - path: &quot;labels&quot;</span><br><span class="line">        fieldRef: # pod的标签将被保存到&#x2F;etc&#x2F;downward&#x2F;labels文件中</span><br><span class="line">          fieldPath: metadata.labels</span><br><span class="line">      - path: &quot;annotations&quot; # pod的注解将被保存到&#x2F;etc&#x2F;downward&#x2F;annotations文件中</span><br></pre></td></tr></table></figure>

<img width="600" src="/images/Kubernetes In Action阅读笔记/37.png">

<h2 id="8-2-与-Kubernetes-API-服务器交互-237"><a href="#8-2-与-Kubernetes-API-服务器交互-237" class="headerlink" title="8.2 与 Kubernetes API 服务器交互 237"></a>8.2 与 Kubernetes API 服务器交互 237</h2><p>downwardAPI的问题在于，只能暴露当前pod和当前节点的信息，如果我们需要获取集群中的其他信息，就需要去和APIServer交互了。</p>
<h3 id="8-2-1-探究-Kubernetes-REST-API-238"><a href="#8-2-1-探究-Kubernetes-REST-API-238" class="headerlink" title="8.2.1 探究 Kubernetes REST API 238"></a>8.2.1 探究 Kubernetes REST API 238</h3><p>在本地运行<code>kubectl proxy</code>，就会在<code>127.0.0.1:8001</code>开启一个代理端口。通过该代理就可以直接和APIServer交互（已经做好了所有的认证凭证等）。</p>
<h3 id="8-2-2-从-pod-内部与-API-服务器进行交互-242"><a href="#8-2-2-从-pod-内部与-API-服务器进行交互-242" class="headerlink" title="8.2.2 从 pod 内部与 API 服务器进行交互 242"></a>8.2.2 从 pod 内部与 API 服务器进行交互 242</h3><p>集群内的apiserver地址：<code>https://kubernetes</code>。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/38.png">

<p>一个名为<code>defalut-token-xyz</code>的Secret被自动创建，并挂载到每个容器的<code>/var/run/secrets/kubernetes.io/serviceaccount</code>目录下，包含apiserver的ca和token。</p>
<h3 id="8-2-3-通过-ambassador-容器简化与-API-服务器的交互-248"><a href="#8-2-3-通过-ambassador-容器简化与-API-服务器的交互-248" class="headerlink" title="8.2.3 通过 ambassador 容器简化与 API 服务器的交互 248"></a>8.2.3 通过 ambassador 容器简化与 API 服务器的交互 248</h3><p>上述方法中，与APIServer交互需要手动处理ca和token。</p>
<p>有一个更简单的方式，在pod里启动一个sidecar容器，这个容器就负责运行<code>kubectl proxy</code>，然后主容器通过proxy端口和APIServer交互。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/39.png">

<h3 id="8-2-4-使用客户端库与-API-服务器交互-251"><a href="#8-2-4-使用客户端库与-API-服务器交互-251" class="headerlink" title="8.2.4 使用客户端库与 API 服务器交互 251"></a>8.2.4 使用客户端库与 API 服务器交互 251</h3><p>k8s API客户端库</p>
<ul>
<li>golang client - <a href="https://github.com/kubernetes/client-go" target="_blank" rel="noopener">https://github.com/kubernetes/client-go</a></li>
<li>python client - <a href="https://github.com/kubernetes-incubator/client-python" target="_blank" rel="noopener">https://github.com/kubernetes-incubator/client-python</a></li>
</ul>
<h2 id="8-3-本章的k8s命令-253"><a href="#8-3-本章的k8s命令-253" class="headerlink" title="8.3 本章的k8s命令 253"></a>8.3 本章的k8s命令 253</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">########## downwardAPI ##########  </span><br><span class="line"></span><br><span class="line"># 展示downwardAPI卷中的标签（path labels是定义的）</span><br><span class="line">$ kubectl exec downward cat &#x2F;etc&#x2F;downward&#x2F;labels</span><br><span class="line"></span><br><span class="line"># 展示downwardAPI卷中的注解（path annotations是定义的）</span><br><span class="line">$ kubectl exec downward cat &#x2F;etc&#x2F;downward&#x2F;annotations</span><br></pre></td></tr></table></figure>

<h1 id="9-Deployment-声明式地升级应用-255"><a href="#9-Deployment-声明式地升级应用-255" class="headerlink" title="9 Deployment: 声明式地升级应用 255"></a>9 Deployment: 声明式地升级应用 255</h1><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">deployment的官方文档</a></p>
<h2 id="9-1-更新运行在-pod-内的应用程序-256"><a href="#9-1-更新运行在-pod-内的应用程序-256" class="headerlink" title="9.1 更新运行在 pod 内的应用程序 256"></a>9.1 更新运行在 pod 内的应用程序 256</h2><h3 id="9-1-1-删除旧版本-pod，使用新版本-pod-替换-257"><a href="#9-1-1-删除旧版本-pod，使用新版本-pod-替换-257" class="headerlink" title="9.1.1 删除旧版本 pod，使用新版本 pod 替换 257"></a>9.1.1 删除旧版本 pod，使用新版本 pod 替换 257</h3><p>Deployment是用户需要关心的负责管理pod的最小单位，在deployment的配置文件里可以直接一次性地配置pod和replicaset。使用deployment不但可以简单的迅速启动容器，还提供了非常方便的滚动升级的方法。</p>
<h3 id="9-1-2-先创建新-pod-再删除旧版本-pod-257"><a href="#9-1-2-先创建新-pod-再删除旧版本-pod-257" class="headerlink" title="9.1.2 先创建新 pod 再删除旧版本 pod 257"></a>9.1.2 先创建新 pod 再删除旧版本 pod 257</h3><p>手动执行滚动升级的方法繁琐，不建议。</p>
<h2 id="9-2-使用-ReplicationController-实现自动的滚动升级-259"><a href="#9-2-使用-ReplicationController-实现自动的滚动升级-259" class="headerlink" title="9.2 使用 ReplicationController 实现自动的滚动升级 259"></a>9.2 使用 ReplicationController 实现自动的滚动升级 259</h2><h3 id="9-2-1-运行第一个版本的应用-259"><a href="#9-2-1-运行第一个版本的应用-259" class="headerlink" title="9.2.1 运行第一个版本的应用 259"></a>9.2.1 运行第一个版本的应用 259</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ReplicationController</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia-v1</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3 # 创建3个pod</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: kubia</span><br><span class="line">      labels:</span><br><span class="line">        app: kubia</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: luksa&#x2F;kubia:v1 # 使用ReplicationController来创建pod</span><br><span class="line">        name: nodejs</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service # service指向所有由ReplicationController创建的pod</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  selector:</span><br><span class="line">    app: kubia</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8080</span><br></pre></td></tr></table></figure>

<h3 id="9-2-2-使用-kubectl-来执行滚动式升级-261"><a href="#9-2-2-使用-kubectl-来执行滚动式升级-261" class="headerlink" title="9.2.2 使用 kubectl 来执行滚动式升级 261"></a>9.2.2 使用 kubectl 来执行滚动式升级 261</h3><blockquote>
<p>如果使用同样的tag推送更新镜像，需要将容器的<code>imagePullPolicy</code>属性设置为Always。当然最好使用一个新的tag来更新镜像。</p>
</blockquote>
<p>可以用<code>kubectl rolling-update</code>来滚动升级rc，不过因为有deployment，所以rc已经不再使用了。在升级过程中，service将请求同时切换到新旧版本的pod。</p>
<h3 id="9-2-3-为什么-kubectl-rolling-update-已经过时-265"><a href="#9-2-3-为什么-kubectl-rolling-update-已经过时-265" class="headerlink" title="9.2.3 为什么 kubectl rolling-update 已经过时 265"></a>9.2.3 为什么 kubectl rolling-update 已经过时 265</h3><ol>
<li>如果kubectl这个客户端在执行升级时失去了网络连接，升级进程将会中断。pod和rc最终会处于中间状态。</li>
<li>k8s的理念是通过不断地收敛达到期望的系统状态。直接使用期望副本数来伸缩pod而不是手动地删除一个pod或者添加一个pod。只要在pod定义中更改所期望的镜像tag，并让k8s用运行新镜像的pod替换旧的pod。正是这一点推动了Deployment的新资源的引入。目前k8s中部署应用程序首选这种方式。</li>
</ol>
<h2 id="9-3-使用-Deployment-声明式地升级应用-266"><a href="#9-3-使用-Deployment-声明式地升级应用-266" class="headerlink" title="9.3 使用 Deployment 声明式地升级应用 266"></a>9.3 使用 Deployment 声明式地升级应用 266</h2><p>rc和rs已经能保证一组pod实例的正常云进行了，为什么要在rc或rs之上再引入另一个对象？<br>在升级应用程序时，需要引入一个额外的rc，并协调两个controller，使它们再根据彼此不断地修改，而不会造成干扰。所以需要Deployment资源来协调。</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/40.png">

<h3 id="9-3-1-创建一个-Deployment-267"><a href="#9-3-1-创建一个-Deployment-267" class="headerlink" title="9.3.1 创建一个 Deployment 267"></a>9.3.1 创建一个 Deployment 267</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment # 需要将原有kind从ReplicationController修改为Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia # Deployment的名称中不再需要包含版本号</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: kubia</span><br><span class="line">      labels:</span><br><span class="line">        app: kubia</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: luksa&#x2F;kubia:v1</span><br><span class="line">        name: nodejs</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: kubia</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Deployment可以同时管理多个版本的pod，所以在命名时不需要指定应用的版本号。</p>
</blockquote>
<p>通过<code>kubectl create -f xxxx-deployment.yml --record</code>创建一个Deployment。在创建时使用了<code>--record</code>选项，这个选项会记录历史版本号。</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/41.png">

<p>现在由Deployment创建的三个pod名称中均包含一个额外的数字。这个数字对应Deployment和ReplicaSet中的pod模板的哈希值。</p>
<p>ReplicaSet的名称中也包含了其pod模板的哈希值。之后的篇幅也会介绍，Deployment会创建多个ReplicaSet，用来对应和管理一个版本的pod模板。像这样使用pod模板的哈希值，可以让Deployment始终对给定版本的pod模板创建相同的（或使用已有的）ReplicaSet。</p>
<h3 id="9-3-2-升级-Deployment-269"><a href="#9-3-2-升级-Deployment-269" class="headerlink" title="9.3.2 升级 Deployment 269"></a>9.3.2 升级 Deployment 269</h3><p>只需修改Deployment资源中定义的pod模板，Kubernetes 会自动将实际的系统状态收敛为资源中定义的状态。</p>
<p>如何达到新的系统状态的过程是由Deployment的升级策略决定的，默认策略是执行滚动更新（策略名为 RollingUpdate）。 另一种策略为Recreate，它会一次性删除所有旧版本的pod，然后创建新的pod。</p>
<p>升级过程是由运行在k8s上的一个控制器处理和完成的（而不再是手动执行kubectl rolling-update）， 只有通过修改deployment内的pod信息才会触发升级。</p>
<p>如果Deployment中的pod模板引用了一个configMap（或 Secret），那么更改configMap资源本身将不会触发升级操作。 如果真的需要修改应用程序的配置并想触发更新的话，可以通过创建一个新的configMap并修改pod模板引用新的configMap。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/42.png">

<p>与rc类型，所有新的pod现在由心的rs管理。但是不同的是，旧的rs会被保留，而旧的rc会在滚动升级过程后被删除。</p>
<h3 id="9-3-3-回滚-Deployment-273"><a href="#9-3-3-回滚-Deployment-273" class="headerlink" title="9.3.3 回滚 Deployment 273"></a>9.3.3 回滚 Deployment 273</h3><p>滚动升级成功后，老版本的 ReplicaSet 也不会被删掉，回滚操作可以回滚到任何一个历史版本。</p>
<p>旧版本的ReplicaSet过多会导致ReplicaSet列表过于混乱，可以通过指定Deployment的<code>revisionHistoryLimit</code>属性来限制历史版本数量。默认值是2，所以正常情况下在版本列表里只有当前版本和上一个版本（以及只保留了当前和上一个ReplicaSet），所有再早之前的ReplicaSet都会被删除。注意<code>extensions/v1beta1</code>版本的Deployment的<code>revisionHistoryLimit</code>没有值，在<code>apps/v1beta2</code>版本中，这个默认值是10。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/43.png">

<h3 id="9-3-4-控制滚动升级速率-276"><a href="#9-3-4-控制滚动升级速率-276" class="headerlink" title="9.3.4 控制滚动升级速率 276"></a>9.3.4 控制滚动升级速率 276</h3><p>在Deployment的滚动升级期间，有两个属性会决定一次替换多少个pod: <code>maxSurge</code>和<code>maxUnavailable</code>。默认都是25%。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 1</span><br><span class="line">      maxUnavailable: 0</span><br><span class="line">    type: RollingUpdate</span><br></pre></td></tr></table></figure>

<h3 id="9-3-5-暂停滚动升级-278"><a href="#9-3-5-暂停滚动升级-278" class="headerlink" title="9.3.5 暂停滚动升级 278"></a>9.3.5 暂停滚动升级 278</h3><p>通过<code>kubectl rollout pause/resume</code>来手动控制滚动步骤。通过暂停滚动升级过程，只有一小部分客户端请求会切换到v4 pod，而大多数请求依然仍只会切换到v3 pod。 一旦确认新版本能够正常工作，就可以恢复滚动升级。</p>
<p>在滚动升级过程中，想要在一个确切的位置暂停滚动升级目前还无法做到，以后可能会有一种新的升级策略来自动完成上面的需求。但目前想要进行金丝雀发布的正确方式是， 使用两个不同的Deployment并同时调整它们对应的pod数量。</p>
<h3 id="9-3-6-阻止出错版本的滚动升级-279"><a href="#9-3-6-阻止出错版本的滚动升级-279" class="headerlink" title="9.3.6 阻止出错版本的滚动升级 279"></a>9.3.6 阻止出错版本的滚动升级 279</h3><p>k8s可以设置多种就绪探针，来探测pod是否已经ready，可以接收svc的流量。</p>
<p><code>minReadySeconds</code>属性指定新创建的pod至少要成功运行多久之后，才能将其视为可用。在pod可用之前，滚动升级的过程不会继续。</p>
<p>默认情况下，在10分钟内不能完成滚动升级的话，将被视为失败。如果运行<code>kubectl describe deployment</code>命令， 将会显示一条 <code>ProgressDeadlineExceeded</code>的记录。</p>
<p>如果只定义就绪探针没有正确设置<code>minReadySeconds</code>，一旦有一次就绪探针调用成功，便会认为新的pod已经处于可用状态。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  minReadySeconds: 10 # 至少就绪运行10s才可用</span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 1</span><br><span class="line">      maxUnavailable: 0 # 确保升级过程中pod被挨个替换</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: kubia</span><br><span class="line">      labels:</span><br><span class="line">        app: kubia</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: luksa&#x2F;kubia:v3</span><br><span class="line">        name: nodejs</span><br><span class="line">        readinessProbe:</span><br><span class="line">          periodSeconds: 1 # 定义一个就绪探针并每隔1s执行一次</span><br><span class="line">          httpGet:</span><br><span class="line">            path: &#x2F; # 就绪探针会执行发送HTTP GET请求到容器</span><br><span class="line">            port: 8080</span><br></pre></td></tr></table></figure>

<img width="600" src="/images/Kubernetes In Action阅读笔记/44.png">

<h2 id="9-4-本章的k8s命令-284"><a href="#9-4-本章的k8s命令-284" class="headerlink" title="9.4 本章的k8s命令 284"></a>9.4 本章的k8s命令 284</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">########## deployment ##########  </span><br><span class="line"></span><br><span class="line"># 开始rc的滚动升级， --v 6 是用于提高日志级别</span><br><span class="line">$ kubectl rolling-update kubia-v1 kubia-v2 --image&#x3D;luksa&#x2F;kubia:v2 --v 6</span><br><span class="line"></span><br><span class="line"># 创建一个Deployment</span><br><span class="line">$ kubectl create -f kubia-deployment-v1.yaml --record</span><br><span class="line"></span><br><span class="line"># 列举Deployment</span><br><span class="line">$ kubectl get deployment</span><br><span class="line"></span><br><span class="line"># 查看Deployment详细信息</span><br><span class="line">$ kubectl describe deployment</span><br><span class="line"></span><br><span class="line"># 查看部署状态</span><br><span class="line">$ kubectl rollout status deployment kubia</span><br><span class="line"></span><br><span class="line"># 设置minReadySeconds属性</span><br><span class="line">$ kubectl patch deployment kubia -p &#39;&#123;&quot;spec&quot;: &#123;&quot;minReadySeconds&quot;: 10&#125;&#125;&#39;</span><br><span class="line"></span><br><span class="line"># 更改任何包含容器资源的镜像</span><br><span class="line">$ kubectl set image deployment kubia nodejs&#x3D;luksa&#x2F;kubia:v2</span><br><span class="line"></span><br><span class="line"># 观察整个升级过程</span><br><span class="line">$ kubectl rollout status deployment kubia</span><br><span class="line"></span><br><span class="line"># 回滚到上一版本</span><br><span class="line">$ kubectl rollout undo deployment kubia</span><br><span class="line"></span><br><span class="line"># 显示升级的版本</span><br><span class="line">$ kubectl rollout history deployment kubia</span><br><span class="line"></span><br><span class="line"># 回滚到一个特定的版本</span><br><span class="line">$ kubectl rollout undo deployment kubia --to-revision&#x3D;1</span><br><span class="line"></span><br><span class="line"># 暂停滚动更新</span><br><span class="line">$ kubectl rollout pause deployment kubia</span><br><span class="line"></span><br><span class="line"># 恢复滚动升级</span><br><span class="line">$ kubectl rollout resume deployment kubia</span><br><span class="line"></span><br><span class="line"># 取消滚动升级</span><br><span class="line">$ kubectl rollout undo deployment kubia</span><br></pre></td></tr></table></figure>

<h1 id="10-StatefulSet-：部署有状态的多副本应用-285"><a href="#10-StatefulSet-：部署有状态的多副本应用-285" class="headerlink" title="10 StatefulSet ：部署有状态的多副本应用 285"></a>10 StatefulSet ：部署有状态的多副本应用 285</h1><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/" target="_blank" rel="noopener">statefulset的官方文档</a></p>
<h2 id="10-1-复制有状态-pod-285"><a href="#10-1-复制有状态-pod-285" class="headerlink" title="10.1 复制有状态 pod 285"></a>10.1 复制有状态 pod 285</h2><p>ReplicaSet通过一个pod模板创建多个pod副本。这些副本除了它们的名字和IP地址不同外，没有别的差异。</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/45.png">

<h3 id="10-1-1-运行每个实例都有单独存储的多副本-286"><a href="#10-1-1-运行每个实例都有单独存储的多副本-286" class="headerlink" title="10.1.1 运行每个实例都有单独存储的多副本 286"></a>10.1.1 运行每个实例都有单独存储的多副本 286</h3><p>一个比较取巧的做法是：所有pod共享同一数据卷，但是每个pod在数据卷中使用不同的数据目录。实现方法是让每个实例自动选择或创建一个别的实例还没有使用的数据目录。但是这种方法，需要实例之间互相协作，增加难度。</p>
<h3 id="10-1-2-每个-pod-都提供稳定的标识-287"><a href="#10-1-2-每个-pod-都提供稳定的标识-287" class="headerlink" title="10.1.2 每个 pod 都提供稳定的标识 287"></a>10.1.2 每个 pod 都提供稳定的标识 287</h3><p>针对集群中的每个成员实例，都创建一个独立的service来提供稳定的网络地址。因为服务IP是固定的，可以在配置文件中指定集群成员对应的服务IP(而不是pod IP)。但这不是好的解决办法，因为pod无法知道它对应的service，不能在别的pod里通过服务IP自行注册。</p>
<h2 id="10-2-了解-Statefulset-289"><a href="#10-2-了解-Statefulset-289" class="headerlink" title="10.2 了解 Statefulset 289"></a>10.2 了解 Statefulset 289</h2><h3 id="10-2-1-对比-Statefulset-和-ReplicaSet-289"><a href="#10-2-1-对比-Statefulset-和-ReplicaSet-289" class="headerlink" title="10.2.1 对比 Statefulset 和 ReplicaSet 289"></a>10.2.1 对比 Statefulset 和 ReplicaSet 289</h3><p>与ReplicaSet不同的是，Statefulset创建的pod副本并不是完全一样的。每个pod都可以拥有一组独立的数据卷（持久化状态）而有所区别。</p>
<h3 id="10-2-2-提供稳定的网络标识-290"><a href="#10-2-2-提供稳定的网络标识-290" class="headerlink" title="10.2.2 提供稳定的网络标识 290"></a>10.2.2 提供稳定的网络标识 290</h3><p>一个Statefulset创建的每个pod都有一个从零开始的顺序索引，这个会体现在pod的名称和主机名上，同样还会体现在pod对应的固定存储上。这些pod的名称则是可预知的，因为它是由Statefulset的名称加该实例的顺序索引值组成的。</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/46.png">

<p>一个StatefulSet通常要求你创建一个用来记录每个pod网络标记的headless Service。通过这个Service，每个pod将拥有独立的DNS记录，这样集群里它的伙伴或者客户端可以通过主机名方便地找到它。比如说，一个属于default命名空间，名为foo的控制服务，它的一个pod名称为A-0，那么可以通过下面的完整域名来访问它<code>a-0.foo.default.svc.cluster.local</code>。而在ReplicaSet中这样是行不通的。</p>
<p>另外，也可以通过 DNS 服务，查找域名<code>foo.default.svc.cluster.local</code>对应的所有SRV记录， 获取一个Statefulset中所有pod的名称。</p>
<p>调度时，Statefulset使用标识完全一致的新的pod替换，ReplicaSet则是使用一个不相干的新的pod替换。缩容一个Statefulset将会最先删除最高索引值的实例。</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/47.png">

<h3 id="10-2-3-为每个有状态实例提供稳定的专属存储-292"><a href="#10-2-3-为每个有状态实例提供稳定的专属存储-292" class="headerlink" title="10.2.3 为每个有状态实例提供稳定的专属存储 292"></a>10.2.3 为每个有状态实例提供稳定的专属存储 292</h3><p>Statefulset在有实例不健康的情况下是不允许做缩容操作的。statefulset会为每一个pod绑定一个不同的固定的pvc，而且该pvc会在pod删除后依然保留，pvc只能手动删除。</p>
<p>因为缩容Statefulset时会保留持久卷声明，所以在随后的扩容操作中，新的pod实例会使用绑定在持久卷上的相同声明和其上的数据。当你因为误操作而缩容一个Statefulset后，可以做一次扩容来弥补自己的过失，新的pod实例会运行到与之前完全一致的状态（名字也是一样的）。</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/48.png">

<h3 id="10-2-4-Statefulset-的保障-294"><a href="#10-2-4-Statefulset-的保障-294" class="headerlink" title="10.2.4 Statefulset 的保障 294"></a>10.2.4 Statefulset 的保障 294</h3><p>Statefulset拥有稳定的标记和独立的存储。通常来说，无状态的pod是可以替代的，有状态的pod则不行。k8s必须保证两个拥有相同标记和绑定相同持久卷声明的有状态的pod实例不能同时运行。一个Statefulset必须保证有状态的pod实例的at-most-one语义。一个Statefulset必须在准确确认一个pod不再运行后，才会去创建它的替换pod。</p>
<h2 id="10-3-使用-Statefulset-295"><a href="#10-3-使用-Statefulset-295" class="headerlink" title="10.3 使用 Statefulset 295"></a>10.3 使用 Statefulset 295</h2><h3 id="10-3-1-创建应用和容器镜像-295"><a href="#10-3-1-创建应用和容器镜像-295" class="headerlink" title="10.3.1 创建应用和容器镜像 295"></a>10.3.1 创建应用和容器镜像 295</h3><p>使用kubia应用作为基础镜像，让每个pod实例都能用来存储和接收一个数据项。</p>
<h3 id="10-3-2-通过-Statefulset-部署应用-296"><a href="#10-3-2-通过-Statefulset-部署应用-296" class="headerlink" title="10.3.2 通过 Statefulset 部署应用 296"></a>10.3.2 通过 Statefulset 部署应用 296</h3><p>为了部署应用，需要创建两个（或三个）不同类型的对象：</p>
<ul>
<li>存储你数据文件的持久卷（当集群不支持持久卷的动态供应时，需要手动创建）</li>
<li>Statefulset必需的一个控制Service</li>
<li>Statefulset本身</li>
</ul>
<p>在部署statefulSet前，需要先创建一个用于在有状态的pod之间提供网络标识的headless service。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None # Statefulset的控制service必须是headless模式</span><br><span class="line">  selector: # 所有标签为app&#x3D;kubia的pod都属于这个service</span><br><span class="line">    app: kubia</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br></pre></td></tr></table></figure>

<p>第二个pod会在第一个pod运行并且处于就绪状态后创建。Statefulset这样的行为是因为：状态明确的集群应用对同时有两个集群成员启动引起的竞争情况是非常敏感的。所以依次启动每个成员是比较安全可靠的。</p>
<h3 id="10-3-3-使用你的-pod-301"><a href="#10-3-3-使用你的-pod-301" class="headerlink" title="10.3.3 使用你的 pod 301"></a>10.3.3 使用你的 pod 301</h3><p>API服务器的一个很有用的功能就是通过代理直接连接到指定的pod。如果想请求当前的 kubia-0 pod，可以通过如下 URL：<code>&lt;apiServerHost&gt;:&lt;port&gt;/api/v1/namespaces/default/pods/kubia-0/proxy/&lt;path&gt;</code>。</p>
<p>通过 kubectl proxy 访问服务，都会经过两个代理的两次跳转。</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/49.png">

<p>statefulSet的pod在重启后也有可能会被调度到不同的节点上，但是会保留它的存储卷和主机名。</p>
<h2 id="10-4-在-Statefulset-中发现伙伴节点-305"><a href="#10-4-在-Statefulset-中发现伙伴节点-305" class="headerlink" title="10.4 在 Statefulset 中发现伙伴节点 305"></a>10.4 在 Statefulset 中发现伙伴节点 305</h2><h3 id="10-4-1-通过-DNS-实现伙伴间彼此发现-306"><a href="#10-4-1-通过-DNS-实现伙伴间彼此发现-306" class="headerlink" title="10.4.1 通过 DNS 实现伙伴间彼此发现 306"></a>10.4.1 通过 DNS 实现伙伴间彼此发现 306</h3><p>k8s通过一个headless service创建SRV记录来指向pod的主机名。创建svc的目的就是在dns中生成srv记录，这一记录会返回与该svc关联的所有的pods。</p>
<h3 id="10-4-2-更新-Statefulset-308"><a href="#10-4-2-更新-Statefulset-308" class="headerlink" title="10.4.2 更新 Statefulset 308"></a>10.4.2 更新 Statefulset 308</h3><p>可以使用<code>kubectl edit statefulset</code>来更新stateful的配置。</p>
<p>Statefulset更像ReplicaSet，而不是Deployment，所以在模板被修改后，它们不会重启更新。 需要手动删除这些副本，然后Statefulset会依据新的模板重新调度启动它们。不会主动删除旧pod，等手动删除后，才会自动创建新pod。</p>
<h3 id="10-4-3-尝试集群数据存储-309"><a href="#10-4-3-尝试集群数据存储-309" class="headerlink" title="10.4.3 尝试集群数据存储 309"></a>10.4.3 尝试集群数据存储 309</h3><p>当一个客户端请求到达集群中的任意一个节点后，它会发现它的所有伙伴节点，然后通过它们收集数据，然后把收集到的所有数据返回给客户端。</p>
<h2 id="10-5-了解-Statefulset-如何处理节点失效-310"><a href="#10-5-了解-Statefulset-如何处理节点失效-310" class="headerlink" title="10.5 了解 Statefulset 如何处理节点失效 310"></a>10.5 了解 Statefulset 如何处理节点失效 310</h2><h3 id="10-5-1-模拟一个节点的网络断开-310"><a href="#10-5-1-模拟一个节点的网络断开-310" class="headerlink" title="10.5.1 模拟一个节点的网络断开 310"></a>10.5.1 模拟一个节点的网络断开 310</h3><p>Statefulset要保证不会有两个拥有相同标记和存储的pod同时运行，当一个节点似乎失效时，Statefulset在明确知道一个pod不再运行之前，它不能或者不应该创建一个替换pod， 保证at-most-one。</p>
<p>只有当集群的管理者告诉它这些信息的时候，它才能明确知道。为了做到这一点，管理者需要删除这个pod，或者删除整个节点。</p>
<p>若该节点过段时间正常连通，并且重新汇报它上面的pod状态，那这个pod就会重新被标记为 Runing。 但如果这个pod的未知状态持续几分钟后（这个时间是可以配置的），这个pod就会自动从节点上驱逐。 不过所谓的”驱逐”也只是k8s会试图删除该 pod，但是由于节点不可达，所以节点状态会停留在Terminating。</p>
<h3 id="10-5-2-手动删除-pod-312"><a href="#10-5-2-手动删除-pod-312" class="headerlink" title="10.5.2 手动删除 pod 312"></a>10.5.2 手动删除 pod 312</h3><p>除非确认节点不再运行或者不会再可以访问，否则不要强制删除有状态的pod。</p>
<h2 id="10-6-本章的k8s命令-313"><a href="#10-6-本章的k8s命令-313" class="headerlink" title="10.6 本章的k8s命令 313"></a>10.6 本章的k8s命令 313</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">########## Statefulset ##########  </span><br><span class="line"></span><br><span class="line"># 修改Statefulset</span><br><span class="line">$ kubectl edit statefulset kubia</span><br><span class="line"></span><br><span class="line"># 删除pod，发出警告信息</span><br><span class="line">$ kubectl delete pod kubia-0 --force --grace-period 0</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://pearlzju.github.io/2021/06/13/%E3%80%8AKubernetes%20In%20Action%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(%E4%B8%80)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pearl">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/face.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pearl 的个人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/13/%E3%80%8AKubernetes%20In%20Action%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(%E4%B8%80)/" itemprop="url">《Kubernetes In Action》阅读笔记(一)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-06-13T10:17:28+08:00">
                2021-06-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" itemprop="url" rel="index">
                    <span itemprop="name">计算机</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/06/13/%E3%80%8AKubernetes%20In%20Action%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(%E4%B8%80)/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2021/06/13/%E3%80%8AKubernetes%20In%20Action%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(%E4%B8%80)/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2021/06/13/%E3%80%8AKubernetes%20In%20Action%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(%E4%B8%80)/" class="leancloud_visitors" data-flag-title="《Kubernetes In Action》阅读笔记(一)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<blockquote>
<p>本文是把《Kubernetes In Action》读薄的摘抄或转述，仅供参考。系统学习请阅读原书。<br>k8s的命令繁多，熟练使用它们提高工作效率和理解k8s设计思想同等重要，每章最后总结了该章涉及的命令。</p>
</blockquote>
<img width="300" src="/images/Kubernetes In Action阅读笔记/0.png">

<p>2019~2020年期间，在工作上使用过Kubernetes(k8s)+Istio治理微服务。我们的业务是做一个Iass+Paas平台，我们把计算、网络、存储、安全、数据库、负载均衡和监控等模块拆分成微服务，每个服务在一组相同的pod运行，每个pod中运行两个容器，业务容器和sidecar。Istio Ingress作为k8s的Ingress Controller，用于对外暴露服务，并且管理南北向流量。Istio的sidecar注入pod，用于管理集群内服务之间的东西向流量。</p>
<p>当时我只是在项目中应用了istio+k8s，没有系统学习过k8s，包括它的设计思想。最近因为工作再次接触k8s，于是挑选了《Kubernetes In Action》进行系统学习和温故而知新，这确实是一本不多见的涵盖广阔提纲挈领的好书。</p>
<p>微服务架构，它从管理上获取对服务的抽象，方便服务的管理和规划服务的边界。但它因为引入了很多新的机制，比如服务注册中心等，其实对硬件而言是一种牺牲。但舍弃一定的性能，换来的是服务的治理、团队协作开发的方便，这就是微服务架构的价值。</p>
<p>程序的本质从不同角度观察，会有不同的见解，就像光的波粒二象性。我的观点是不浪费硬件是对提升性能最大的帮助。会有听到微服务解决了高并发问题的说法，但微服务和高并发其实没有必然关系。而是因为通常微服务会使用分布式方式部署，硬件资源包括CPU、网络、磁盘等成倍增加，所以分布式对高并发问题有积极作用。</p>
<p>Istio，它其实不局限于微服务治理范畴，任何服务，只要服务间有访问，需要对服务间的流量进行管理、服务间认证等，都可以使用Istio来管理。</p>
<p>k8s不是一个专为Docker设计的容器编排系统。k8s的核心也不止是编排容器，只不过容器恰好是在不同集群节点上运行应用的最佳方式。k8s可以被看作集群的一个操作系统，提供服务发现、扩容、负载均衡、自恢复、leader选举等功能。</p>
<h1 id="1-Kubernetes-介绍-1"><a href="#1-Kubernetes-介绍-1" class="headerlink" title="1 Kubernetes 介绍 1"></a>1 Kubernetes 介绍 1</h1><p>微服务架构是替代以单个进程或几个进程运行在服务器上为部署方式的单体应用的一种方式，它将单体应用分解成若干个可独立运行组件。微服务的解耦性，确保它们可以被独立开发、部署、升级、伸缩。<br>如何部署、管理这些微服务，并充分利用宿主机的硬件资源，诞生了k8s。k8s可以理解为是一个数据中心操作系统(DCOS)，他将人员分为开发人员和系统管理员，系统管理员负责处理和硬件、集群相关的事务，开发人员只需要提交自己的应用和描述。k8s会「自动」按照开发人员的描述，把应用启动起来，并暴露定义的端口。</p>
<blockquote>
<p>在computer science领域，有一句话”All problems in computer science can be solved by another level of indirection”。k8s抽象了数据中心的硬件基础设置，对外暴露资源池API，开发人员不用关心底层的硬件设施。这种抽象和操作系统也有相似之处。</p>
</blockquote>
<h2 id="1-1-Kubernetes-系统的需求-2"><a href="#1-1-Kubernetes-系统的需求-2" class="headerlink" title="1.1 Kubernetes 系统的需求 2"></a>1.1 Kubernetes 系统的需求 2</h2><h3 id="1-1-1-从单体应用到微服务-2"><a href="#1-1-1-从单体应用到微服务-2" class="headerlink" title="1.1.1 从单体应用到微服务 2"></a>1.1.1 从单体应用到微服务 2</h3><p>对于单体应用，为了提升系统负载能力，有两种扩展方式。<br>垂直扩展：增加CPU、内存或其它系统资源。应用程序无需变化，但成本越来越高，无法无限扩展。<br>水平扩展：经常需要应用程序进行改动才可执行，可能会被某个模块无法水平扩展限制。</p>
<p>单体应用可被拆分成多个可独立部署、以独立进程运行的微服务，微服务之间以约定的API通信。</p>
<p>对于微服务架构，可以只扩容某些服务，因为扩容粒度细化，可以根据具体情况分配扩容资源。</p>
<blockquote>
<p>如果有历史项目是单体应用，不得不水平扩容，而水平扩容受到某些模块的限制。可以把应用拆分成多个微服务，对能扩容的组件水平扩展，对不能扩容的组件垂直扩展。</p>
</blockquote>
<p>看似一切很美好，微服务带来的弊端不容忽视。<br>当服务数量激增，如何处理服务间错综复杂的依赖关系，如何把正确的配置应用到每个服务，如何调试代码和定位异常调用，如何解决不同服务对于环境需求的差异，都是需要面对的。</p>
<h3 id="1-1-2-为应用程序提供一个一致的环境-5"><a href="#1-1-2-为应用程序提供一个一致的环境-5" class="headerlink" title="1.1.2 为应用程序提供一个一致的环境 5"></a>1.1.2 为应用程序提供一个一致的环境 5</h3><p>目标是让服务在开发和生产阶段可以运行在完全一样的环境下，有完全一样的操作系统、库、系统配置、网络环境等。各个服务之间独立互不影响。</p>
<h3 id="1-1-3-迈向持续交付-：DevOps-和无运维-6"><a href="#1-1-3-迈向持续交付-：DevOps-和无运维-6" class="headerlink" title="1.1.3 迈向持续交付 ：DevOps 和无运维 6"></a>1.1.3 迈向持续交付 ：DevOps 和无运维 6</h3><p>让应用开发者和系统管理员解耦，开发者可以自己参与配置和部署程序，但又无需关注硬件基础设施。而实际上系统管理员在幕后保证底层基础设施正常运转，但他们也无需关注运行的程序本身。<br>这正是k8s实现的功能。它对硬件资源进行抽象，对外暴露成一个平台，用于部署和运行应用程序。</p>
<h2 id="1-2-介绍容器技术-7"><a href="#1-2-介绍容器技术-7" class="headerlink" title="1.2 介绍容器技术 7"></a>1.2 介绍容器技术 7</h2><p>k8s使用Linux容器技术来实现对应用的隔离。</p>
<h3 id="1-2-1-什么是容器-7"><a href="#1-2-1-什么是容器-7" class="headerlink" title="1.2.1 什么是容器 7"></a>1.2.1 什么是容器 7</h3><p>虚拟机可以隔离不同的微服务环境是显然的，Linux容器技术也可以。容器和虚拟机相比开销小很多，容器里运行的进程实际上运行在宿主机上，但是和其它进程隔离，开销仅是容器消耗的资源。</p>
<p>虚拟机和容器中的应用进程对CPU的使用方式不同。每个虚拟机对应的Linux内核不一样，而不同容器对应的Linux内核一样（存在安全隐患）。如图所示。</p>
<img width="400" src="/images/Kubernetes In Action阅读笔记/1.png">

<p>如果多个进程运行在同一个操作系统上，是怎么利用容器是隔离它们的？有两个机制可用。</p>
<ol>
<li>Linux命名空间。可以在某个命名空间运行一个进程，进程只能看到这个命名空间下的资源。当然，会存在多种类型的命名空间，所以一个进程不单单只属于某一个命名空间，而属于每个类型的一个命名空间。</li>
</ol>
<p>存在以下类型的命名空间：</p>
<ul>
<li>Mount（mnt）</li>
<li>Process ID（pid）</li>
<li>Network（net）</li>
<li>Inter-process communicaion（ipd）</li>
<li>UTS</li>
<li>User ID（user）</li>
</ul>
<ol start="2">
<li>内核的cgroups。限制进程能使用的资源量（CPU、内存、网络带宽等）不能超过被分配的量。</li>
</ol>
<h3 id="1-2-2-Docker-容器平台介绍-11"><a href="#1-2-2-Docker-容器平台介绍-11" class="headerlink" title="1.2.2 Docker 容器平台介绍 11"></a>1.2.2 Docker 容器平台介绍 11</h3><p>Docker是第一个使容器成为主流的容器平台。Docker本身不提供进程隔离，而是由Linux命名空间和cgroups之类的内核特性完成。</p>
<p>镜像层是只读的。容器运行时，一个新的可写层在镜像层之上被创建。 容器中进程写入位于底层的一个文件时，此文件的一个拷贝在顶层被创建，进程写的是此拷贝。</p>
<p>Docker可以借助于镜像在不同操作系统之间移植，但是内核由运行容器的宿主机决定。如果一个容器化的应用需要一个特定的内核版本，那它可能不能在每台机器上都工作。 如果一台机器上运行了一个不匹配的 Linux 内核版本，或者没有相同内核模块可用，那么此应用就不能在其上运行。所以容器镜像存在移植性的限制，在不同CPU架构上构建的镜像不能通用。例如在x86平台构建的镜像，不能在arm平台使用。</p>
<h3 id="1-2-3-rkt——一个-Docker-的替代方案-14"><a href="#1-2-3-rkt——一个-Docker-的替代方案-14" class="headerlink" title="1.2.3 rkt——一个 Docker 的替代方案 14"></a>1.2.3 rkt——一个 Docker 的替代方案 14</h3><p>开放容器计划OCI是围绕容器格式和运行时创建的开放工业标准。kubelet以CRI标准接口与OCI进行通信。rkt是另一个Linux容器引擎。</p>
<p>本书集中使用Docker作为k8s的容器，它是k8s最初唯一支持的容器类型，但k8s目前也支持rkt等其它容器类型。</p>
<h2 id="1-3-Kubernetes-介绍-15"><a href="#1-3-Kubernetes-介绍-15" class="headerlink" title="1.3 Kubernetes 介绍 15"></a>1.3 Kubernetes 介绍 15</h2><h3 id="1-3-1-初衷-15"><a href="#1-3-1-初衷-15" class="headerlink" title="1.3.1 初衷 15"></a>1.3.1 初衷 15</h3><p>在海量服务器规模下，有效处理部署管理，并提高基础设施利用率。</p>
<h3 id="1-3-2-深入浅出地了解-Kubernetes-15"><a href="#1-3-2-深入浅出地了解-Kubernetes-15" class="headerlink" title="1.3.2 深入浅出地了解 Kubernetes 15"></a>1.3.2 深入浅出地了解 Kubernetes 15</h3><p>k8s整个系统由一个主节点和若干个工作节点组成。开发者把一个应用列表提交到主节点，k8s会将它们部署到集群的工作节点。组件被部署在哪个节点对于开发者和系统管理员来说都不用关心 。开发者能指定一些应用必须一起运行，k8s将会在一个工作节点上部署它们。其他的将被分散部署到集群中，但是不管部署在哪儿，它们都能以相同的方式互相通信。</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/2.png">

<h3 id="1-3-3-Kubernetes-集群架构-17"><a href="#1-3-3-Kubernetes-集群架构-17" class="headerlink" title="1.3.3 Kubernetes 集群架构 17"></a>1.3.3 Kubernetes 集群架构 17</h3><p>一个k8s集群由很多节点组成，分为两种类型：</p>
<ol>
<li>主节点：它承载着k8s控制和管理整个集群系统的控制面板。控制面板的组件持有井控制集群状态，但是它们不运行应用，运行应用是由工作节点完成的。</li>
</ol>
<ul>
<li>API服务器：应用和其它控制面板组件都要和它通信。</li>
<li>Scheculer：调度应用(为应用的每个可部署组件分配一个工作节点)。</li>
<li>Controller Manager：执行集群级别的功能，如复制组件、持续跟踪工作节点、处理节点失败等。</li>
<li>etcd：一个可靠的分布式数据存储，它能持久化存储集群配置。</li>
</ul>
<ol start="2">
<li>工作节点：它们运行用户实际部署的应用。</li>
</ol>
<ul>
<li>Docker、rkt或其它容器类型。</li>
<li>Kubelet：与API服务器通信，并管理它所在节点的容器。</li>
<li>kube-proxy：负责组件之间的负载均衡网络流量。</li>
</ul>
<img width="500" src="/images/Kubernetes In Action阅读笔记/3.png">

<h3 id="1-3-4-在-Kubernetes-中运行应用-18"><a href="#1-3-4-在-Kubernetes-中运行应用-18" class="headerlink" title="1.3.4 在 Kubernetes 中运行应用 18"></a>1.3.4 在 Kubernetes 中运行应用 18</h3><p>在向k8提交描述符之后，它将把每个pod的指定副本数量调度到可用的工作节点上。 节点上的 Kubelets将告知Docker从镜像仓库中拉取 容器镜像井运行容器。 </p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/4.png">

<p>一旦应用程序运行起来，k8s就会不断地确认应用程序的部署状态始终与你提供的描述相匹配。</p>
<p>k8s采用声明式的控制流，所有的资源声明都保存在etcd，所有的组件都通过API Server来声明或监听资源。只要资源被声明，那么监听资源的控制器就会开始工作，确保让各个资源实例达到声明的状态。</p>
<h3 id="1-3-5-使用-Kubernetes-的好处-20"><a href="#1-3-5-使用-Kubernetes-的好处-20" class="headerlink" title="1.3.5 使用 Kubernetes 的好处 20"></a>1.3.5 使用 Kubernetes 的好处 20</h3><ul>
<li>简化应用程序部署</li>
<li>更好地利用硬件</li>
<li>健康检查和自修复</li>
<li>自动扩容</li>
<li>敏捷交付</li>
</ul>
<h1 id="2-开始使用-Kubernetes-和-Docker-23"><a href="#2-开始使用-Kubernetes-和-Docker-23" class="headerlink" title="2 开始使用 Kubernetes 和 Docker 23"></a>2 开始使用 Kubernetes 和 Docker 23</h1><h2 id="2-1-创建、运行及共享容器镜像-23"><a href="#2-1-创建、运行及共享容器镜像-23" class="headerlink" title="2.1 创建、运行及共享容器镜像 23"></a>2.1 创建、运行及共享容器镜像 23</h2><p>容器中的进程是运行在主机操作系统上的，但是该进程的ID在主机上和容器中不同。容器使用独立的PID Linux命令空间并且有着独立的系列号，完全独立于进程树。</p>
<p>正如拥有独立的进程树一 样，每个容器也拥有独立的文件系统。在容器内列出 根目录的内容，只会展示容器内的文件，包括镜像内的所有文件，再加上容器运行时创建的任何文件(类似日志文件)。</p>
<p>使用是比较简单的，本文不赘述了。</p>
<h2 id="2-2-配置-Kubernetes-集群-34"><a href="#2-2-配置-Kubernetes-集群-34" class="headerlink" title="2.2 配置 Kubernetes 集群 34"></a>2.2 配置 Kubernetes 集群 34</h2><p>主要讲如何创建k8s集群，讲了两个方法：用 Minikube 运行一个本地单节点 Kubernetes 集群；用 Google Kubernetes Engine 托管 Kubernetes 集群。以及为kubectl 配置别名和命令行补齐，方便命令输入。</p>
<p>使用是比较简单的，本文不赘述了。</p>
<h2 id="2-3-在-Kubernetes-上运行第一个应用-40"><a href="#2-3-在-Kubernetes-上运行第一个应用-40" class="headerlink" title="2.3 在 Kubernetes 上运行第一个应用 40"></a>2.3 在 Kubernetes 上运行第一个应用 40</h2><h3 id="2-3-1-部署-Node-js-应用-40"><a href="#2-3-1-部署-Node-js-应用-40" class="headerlink" title="2.3.1 部署 Node.js 应用 40"></a>2.3.1 部署 Node.js 应用 40</h3><p>一个pod是一组紧密相关的容器，它们总是一起运行在同一个工作节点上，以及同一个Linux命名空间中。每个pod就像一个独立的逻辑机器，拥有自己的IP、主机名、进程等，运行一个独立的应用程序。应用程序可以是单个进程，运行在单个容器中，也可以是一个主应用进程或者其他支持进程，每个进程都在自己的容器中运行。一个pod的所有容器都运行在同一个逻辑机器上，而其它pod中的容器，即使运行在同 一个工作节点上，也会出现在不同的节点上 。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/5.png">

<p>当运行kubectl命令时，它通过向API服务器发送一个REST HTTP请求，在集群中创建一个新的ReplicationController对象。然后，ReplicationController创建了一个新的pod，调度器将其调度到 一个工作节点上。Kubelet看到pod被调度到节点上，就告知Docker从镜像中心中拉取指定的镜像，因为本地没有该镜像。下载镜像后，Docker创建并运行容器。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/6.png">

<h3 id="2-3-2-访问-Web-应用-43"><a href="#2-3-2-访问-Web-应用-43" class="headerlink" title="2.3.2 访问 Web 应用 43"></a>2.3.2 访问 Web 应用 43</h3><p>每个pod有自己的IP地址，但是这个地址是集群内部的，不能从集群外部访问。要让pod能够从外部访问，需要通过服务对象公开它，要创建一个LoadBalancer类型的服务。它将创建一个外部的负载均衡，外部可以通过负载均衡的公共IP访问pod。</p>
<h3 id="2-3-3-系统的逻辑部分-45"><a href="#2-3-3-系统的逻辑部分-45" class="headerlink" title="2.3.3 系统的逻辑部分 45"></a>2.3.3 系统的逻辑部分 45</h3><p>k8s的基本构件是pod，但是没有直接创建和使用pod。通过运行<code>kubectl run</code>命令，创建了一个ReplicationController，它用于创建pod实例 。为了使该pod能够从集群外部访问，需要让 k8s将 该ReplicationController管理的所有pod由一个服务对外暴露。服务表示一组或多组提供相同服务的pod的静态地址。到达服务IP和端口的请求将被转发到属于该服务的一个容器的IP和端口。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/7.png">

<h3 id="2-3-4-水平伸缩应用-46"><a href="#2-3-4-水平伸缩应用-46" class="headerlink" title="2.3.4 水平伸缩应用 46"></a>2.3.4 水平伸缩应用 46</h3><p>为了增加pod的副本数，需要改变ReplicationController期望的副本数。告诉k8s需要确保pod始终有三个实例在运行。成功后，请求会随机地切到不同的pod。</p>
<blockquote>
<p>应用本身需要支持水平伸缩。</p>
</blockquote>
<p>没有告诉k8s需要采取什么行动，也没有告诉k8s增加两个pod，只设置新的期望的实例数量并让 k8s决定需要采取哪些操作来实现期望的状态。这是k8s最基本的原则之一。不是告诉 k8s 应该执行什么操作，而是声明性地改变系统的期望状态，并让k8s检查当前的状态是否与期望的状态一致。在整个 k8s 世界中都是这样的——声明式设计。</p>
<h3 id="2-3-5-查看应用运行在哪个节点上-49"><a href="#2-3-5-查看应用运行在哪个节点上-49" class="headerlink" title="2.3.5 查看应用运行在哪个节点上 49"></a>2.3.5 查看应用运行在哪个节点上 49</h3><p>不管调度到哪个节点，容器中运行的所有应用都具有相同类型的操作系统。每个pod都有自己的IP，并且可以与任何其他pod通信，不论其他pod是运行在同一 个节点上，还是运行在另一个节点上。每个pod都被分配到所需的计算资源，因此这些资源是由一个节点提供还是由另一个节点提供，并没有任何区别。</p>
<h3 id="2-3-6-介绍-Kubernetes-dashboard-50"><a href="#2-3-6-介绍-Kubernetes-dashboard-50" class="headerlink" title="2.3.6 介绍 Kubernetes dashboard 50"></a>2.3.6 介绍 Kubernetes dashboard 50</h3><p>k8s的图形化用户界面。列出部署在集群中的所有pod、ReplicationController、服务和其他部署在集群中的对象， 以及创建、修改和删除它们。</p>
<h2 id="2-4-本章的k8s命令"><a href="#2-4-本章的k8s命令" class="headerlink" title="2.4 本章的k8s命令"></a>2.4 本章的k8s命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">########## 集群 ##########  </span><br><span class="line"></span><br><span class="line"># 展示集群信息</span><br><span class="line">$ kubectl cluster-info</span><br><span class="line"></span><br><span class="line"># 获取dashboard的URL</span><br><span class="line">$ kubectl cluster-info | grep dashboard</span><br><span class="line"></span><br><span class="line">########## node ##########  </span><br><span class="line"></span><br><span class="line"># 列出集群节点</span><br><span class="line">$ kubectl get nodes</span><br><span class="line"></span><br><span class="line">########## pod ##########  </span><br><span class="line"></span><br><span class="line"># 列出所有pod</span><br><span class="line">$ kubectl get pods</span><br><span class="line">可以加上 -o wide 选项请求其它列</span><br><span class="line"></span><br><span class="line"># 描述一个pod</span><br><span class="line">$ kubectl describe pod kubia-hczji</span><br><span class="line"></span><br><span class="line">########## service ##########  </span><br><span class="line"></span><br><span class="line"># 列出所有服务</span><br><span class="line">$ kubectl get services(缩写svc)</span><br><span class="line"></span><br><span class="line">########## ReplicationController ##########  </span><br><span class="line"></span><br><span class="line"># 创建一个ReplicationController</span><br><span class="line">$ kubectl run kubia --image&#x3D;luksa&#x2F;kubia --port&#x3D;8080 --generator&#x3D;run&#x2F;v1</span><br><span class="line"></span><br><span class="line"># 改变ReplicationController期望的副本数</span><br><span class="line">$ kubectl scale re kubia --replicas&#x3D;3</span><br><span class="line"></span><br><span class="line"># 列出ReplicationController</span><br><span class="line">$ kubectl get replicationcontroller(缩写rc)</span><br><span class="line"></span><br><span class="line">########## LoadBalancer ##########  </span><br><span class="line"></span><br><span class="line"># 创建LoadBalancer服务对象</span><br><span class="line">$ kubectl expose rc kubia --type&#x3D;LoadBalancer --name kubia-http</span><br></pre></td></tr></table></figure>

<h1 id="3-pod-：运行于-Kubernetes-中的容器-53"><a href="#3-pod-：运行于-Kubernetes-中的容器-53" class="headerlink" title="3 pod ：运行于 Kubernetes 中的容器 53"></a>3 pod ：运行于 Kubernetes 中的容器 53</h1><p>pod是k8s中最重要的核心概念，而其他对象仅仅是在管理、 暴露pod或被pod使用。</p>
<h2 id="3-1-介绍-pod-53"><a href="#3-1-介绍-pod-53" class="headerlink" title="3.1 介绍 pod 53"></a>3.1 介绍 pod 53</h2><p>当一个 pod包含多个容器时，这些容器总是运行于同一个工作节点上。一个pod绝不会跨越多个工作节点。</p>
<h3 id="3-1-1-为何需要-pod-54"><a href="#3-1-1-为何需要-pod-54" class="headerlink" title="3.1.1 为何需要 pod 54"></a>3.1.1 为何需要 pod 54</h3><p>容器被设计为每个容器只运行一个进程(除非进程本身产生子进程)。如果在单个容器中运行多个不相关的进程，那么保持所有进程运行、管理它们的日志等将会是我们的责任。例如，我们需要包含一种在进程崩溃时能够自动重启的机制。同时这些进程都将记录到相同的标准输出中， 而此时我们将很难确定每个进程分别记录了什么。<br>我们需要让每个进程运行于自己的容器中，而这就是Docker和k8s期望使用的方式。<br>pod是k8s调度的最小单位，一个 pod可以包含一个或多个容器。</p>
<h3 id="3-1-2-了解-pod-55"><a href="#3-1-2-了解-pod-55" class="headerlink" title="3.1.2 了解 pod 55"></a>3.1.2 了解 pod 55</h3><p>由于不能将多个进程聚集在一个单独的容器中，我们需要另一种更高级的结构来将容器绑定在一 起，并将它们作为一个单元进行管理，这就是pod背后的根本原理。</p>
<p>k8s通过配置Docker来让一个pod内的所有容器共享相同的Linux命名空间，而不是每个容器都有自己的一组命名空间。</p>
<p>由于一个pod中的所有容器都在相同的network和UTS命名空间下运行，所以它们都共享相同的主机名和网络接口。 同一个pod中的容器共享相同的IP地址和端口空间。同样地，这些容器也都在相同的IPC命名空间下运行，因此能够通过IPC进行通信。在最新的k8s和Docker版本中，它们也能够共享相同的PID命名空间（但是该特征默认是未激活的）。</p>
<p>k8s集群的pod之间没有NAT网关，两个pod彼此之间发送网络数据包时，它们都会将对方的实际IP地址看作数据包中的源IP。</p>
<h3 id="3-1-3-通过-pod-合理管理容器-56"><a href="#3-1-3-通过-pod-合理管理容器-56" class="headerlink" title="3.1.3 通过 pod 合理管理容器 56"></a>3.1.3 通过 pod 合理管理容器 56</h3><p>当决定是将两个容器放入一个pod还是 两个单独的pod时，我们需要问自己以下问题:</p>
<ul>
<li>它们需要 一起运行还是可以在不同的主机上运行?</li>
<li>它们代表的是一个整体还是相互独立的组件?</li>
<li>它们必须一起进行扩缩容还是可以分别进行? </li>
</ul>
<p>我们总是应该倾向于在单独的pod中运行容器，除非有特定的原因要求它们是同一pod的一部分。<br>比如常见的是sidecar容器，用于日志轮转器和收集器、数据处理器、通信适配器等。</p>
<blockquote>
<p>在实际业务场景中，在pod中使用多个容器，sidecar是最常见的方式。其它情况，需要三思。</p>
</blockquote>
<img width="600" src="/images/Kubernetes In Action阅读笔记/8.png">

<h2 id="3-2-以-YAML-或-JSON-描述文件创建-pod-58"><a href="#3-2-以-YAML-或-JSON-描述文件创建-pod-58" class="headerlink" title="3.2 以 YAML 或 JSON 描述文件创建 pod 58"></a>3.2 以 YAML 或 JSON 描述文件创建 pod 58</h2><p>pod和其它k8s资源通常是通过向k8s REST API提供JSON或YAML描述文件来创建的。<br>全面的文档在<a href="https://kubernetes.io/docs/reference/kubernetes-api/" target="_blank" rel="noopener">Kubernetes API参考文档</a>。</p>
<h3 id="3-2-1-检查现有-pod-的-YAML-描述文件-59"><a href="#3-2-1-检查现有-pod-的-YAML-描述文件-59" class="headerlink" title="3.2.1 检查现有 pod 的 YAML 描述文件 59"></a>3.2.1 检查现有 pod 的 YAML 描述文件 59</h3><p>pod定义由这几个部分组成：首先是YAML中使用的k8s API版本和YAML描述的资源类型；其次是几乎在所有k8s资源中都可以找到的三大重要部分：</p>
<ul>
<li>metadata：包括名称、命名空间、标签和关于该容器的其他信息。</li>
<li>spec：包含pod内容的实际说明，例如pod的容器、卷和其他数据。</li>
<li>status：包含运行中的pod的当前信息，例如pod所处的条件、 每个容器的描述和状态，以及内部IP和其他基本信息。status只包含只读的运行时数据，在创建新的pod时，不需要提供status部分。</li>
</ul>
<h3 id="3-2-2-为-pod-创建一个简单的-YAML-描述文件-61"><a href="#3-2-2-为-pod-创建一个简单的-YAML-描述文件-61" class="headerlink" title="3.2.2 为 pod 创建一个简单的 YAML 描述文件 61"></a>3.2.2 为 pod 创建一个简单的 YAML 描述文件 61</h3><p>一个基本的pod描述文件非常简单。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia-manual</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa&#x2F;kubia</span><br><span class="line">    name: kubia</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 8080</span><br><span class="line">      protocol: TCP</span><br></pre></td></tr></table></figure>

<h3 id="3-2-3-使用-kubectl-create-来创建-pod-63"><a href="#3-2-3-使用-kubectl-create-来创建-pod-63" class="headerlink" title="3.2.3 使用 kubectl create 来创建 pod 63"></a>3.2.3 使用 kubectl create 来创建 pod 63</h3><p><code>kubectl create -f</code>命令用于从YAML或JSON文件创建任何资源。创建后可以请求k8s获得完整的YAML和JSON格式的描述文件。</p>
<h3 id="3-2-4-查看应用程序日志-64"><a href="#3-2-4-查看应用程序日志-64" class="headerlink" title="3.2.4 查看应用程序日志 64"></a>3.2.4 查看应用程序日志 64</h3><p>当日志文件达到一定大小时，容器日志会自动轮替。<code>kubectl logs</code>命令仅显示最后一次轮替后的日志条目。</p>
<p>当一个pod被删除时，它的日志也会被删除。如果希望在pod删除之后仍然可以获取其日志，我们需要设置中心化的、集群范围的日志系统，将所有日志存储到中心存储中。 </p>
<h3 id="3-2-5-向-pod-发送请求-65"><a href="#3-2-5-向-pod-发送请求-65" class="headerlink" title="3.2.5 向 pod 发送请求 65"></a>3.2.5 向 pod 发送请求 65</h3><p>如果要在外部访问pod，除了前面提到的lb service，还可以借助端口转发（常用于开发中测试pod）。端口转发通过<code>kubectl port-forward</code>命令完成。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/9.png">

<h2 id="3-3-使用标签组织-pod-66"><a href="#3-3-使用标签组织-pod-66" class="headerlink" title="3.3 使用标签组织 pod 66"></a>3.3 使用标签组织 pod 66</h2><p>通过一次操作对属于某个组的所有pod进行操作，而不必单独为每个pod执行操作。<br>标签可以做到这一点。通过标签来组织pod和所有其他k8s对象。</p>
<h3 id="3-3-1-介绍标签-66"><a href="#3-3-1-介绍标签-66" class="headerlink" title="3.3.1 介绍标签 66"></a>3.3.1 介绍标签 66</h3><p>标签是可以附加到资源的任意键值对。通过标签选择器可以选择具有确切标签的资源。<br>标签和资源是多对多关系。</p>
<p>比如常用的场景有，给每个pod标有两个标签。</p>
<ul>
<li>app：它指定pod属于哪个应用、 组件或微服务。</li>
<li>rel：它显示在pod中运行的应用程序版本是stable、beta还是canary（用于金丝雀发布）。</li>
</ul>
<img width="600" src="/images/Kubernetes In Action阅读笔记/10.png">

<h3 id="3-3-2-创建-pod-时指定标签-67"><a href="#3-3-2-创建-pod-时指定标签-67" class="headerlink" title="3.3.2 创建 pod 时指定标签 67"></a>3.3.2 创建 pod 时指定标签 67</h3><p>包含creation_method=manual，env=prod两个标签。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia-manual-v2</span><br><span class="line">  labels:</span><br><span class="line">    creation_method: manual</span><br><span class="line">    env: prod</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="3-3-3-修改现有-pod-的标签-68"><a href="#3-3-3-修改现有-pod-的标签-68" class="headerlink" title="3.3.3 修改现有 pod 的标签 68"></a>3.3.3 修改现有 pod 的标签 68</h3><p>标签可以在现有pod上进行添加和修改。</p>
<h2 id="3-4-通过标签选择器列出-pod-子集-69"><a href="#3-4-通过标签选择器列出-pod-子集-69" class="headerlink" title="3.4 通过标签选择器列出 pod 子集 69"></a>3.4 通过标签选择器列出 pod 子集 69</h2><p>标签要与标签选择器结合，否则标签没有作用。</p>
<h3 id="3-4-1-使用标签选择器列出-pod-69"><a href="#3-4-1-使用标签选择器列出-pod-69" class="headerlink" title="3.4.1 使用标签选择器列出 pod 69"></a>3.4.1 使用标签选择器列出 pod 69</h3><p>标签选择器根据资源的以下条件来选择资源：</p>
<ul>
<li>包含(或不包含)使用特定键的标签。</li>
<li>包含具有特定键和值的标签。</li>
<li>包含具有特定键的标签，但其值与我们指定的不同。</li>
</ul>
<h3 id="3-4-2-在标签选择器中使用多个条件-71"><a href="#3-4-2-在标签选择器中使用多个条件-71" class="headerlink" title="3.4.2 在标签选择器中使用多个条件 71"></a>3.4.2 在标签选择器中使用多个条件 71</h3><p>在包含多个逗号分隔的清况下，可以在标签选择器中同时使用多个条件。 此时，资源需要全部匹配才算成功匹配了选择器。</p>
<h2 id="3-5-使用标签和选择器来约束-pod-调度-71"><a href="#3-5-使用标签和选择器来约束-pod-调度-71" class="headerlink" title="3.5 使用标签和选择器来约束 pod 调度 71"></a>3.5 使用标签和选择器来约束 pod 调度 71</h2><p>在硬件基础设施不是同质的情况下，比如想将执行GPU密集型运算的pod调度到提供GPU加速的节点上，需要约束pod的调度。这可以通过节点标签和节点标签选择器完成。</p>
<h3 id="3-5-1-使用标签分类工作节点-72"><a href="#3-5-1-使用标签分类工作节点-72" class="headerlink" title="3.5.1 使用标签分类工作节点 72"></a>3.5.1 使用标签分类工作节点 72</h3><p>pod并不是唯一可以附加标签的k8s资源。标签可以附加到任何k8s对象上，包括节点。 </p>
<h3 id="3-5-2-将-pod-调度到特定节点-72"><a href="#3-5-2-将-pod-调度到特定节点-72" class="headerlink" title="3.5.2 将 pod 调度到特定节点 72"></a>3.5.2 将 pod 调度到特定节点 72</h3><p>在spec部分添加了一个<code>nodeSelector</code>字段。当创建该pod时，调度器将只在包含标签gpu=true的节点中选择。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">spec:</span><br><span class="line">  nodeSelector:</span><br><span class="line">    gpu: &quot;true&quot;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="3-5-3-调度到一个特定节点-73"><a href="#3-5-3-调度到一个特定节点-73" class="headerlink" title="3.5.3 调度到一个特定节点 73"></a>3.5.3 调度到一个特定节点 73</h3><p>也可以将pod调度到某个确定的节点，由于每个节点都有一个唯一标签，其中键为<code>kubernetes.io/hostname</code>， 值为该节点的实际主机名， 因此也可以将pod调度到某个确定的节点。但如果节点处于离线状态，通过hostname标签将nodeSelector设置为特定节点可能会导致pod不可调度。所以绝不应该考虑单个节点，而是应该通过标签选择器考虑符合特定标准的逻辑节点组。</p>
<h2 id="3-6-注解-pod-73"><a href="#3-6-注解-pod-73" class="headerlink" title="3.6 注解 pod 73"></a>3.6 注解 pod 73</h2><p>pod和其它对象还可以包含注解。注解也是键值对。但是注解不能像标签一样用于对对象分组。不存在注解选择器这样的东西。</p>
<h3 id="3-6-1-查找对象的注解-74"><a href="#3-6-1-查找对象的注解-74" class="headerlink" title="3.6.1 查找对象的注解 74"></a>3.6.1 查找对象的注解 74</h3><p>注解可以包含相对更多的数据，标签则是应该比较简短的。</p>
<h3 id="3-6-2-添加和修改注解-74"><a href="#3-6-2-添加和修改注解-74" class="headerlink" title="3.6.2 添加和修改注解 74"></a>3.6.2 添加和修改注解 74</h3><p>通过<code>kubectl annotate</code>命令添加和修改注解。</p>
<h2 id="3-7-使用命名空间对资源进行分组-75"><a href="#3-7-使用命名空间对资源进行分组-75" class="headerlink" title="3.7 使用命名空间对资源进行分组 75"></a>3.7 使用命名空间对资源进行分组 75</h2><p>k8s中可供声明的类称为资源（Resource），包括 pod、rs、deployment 等。声明一个资源构成的实例都有名字，这些名字都归属于一个个的命名空间之中（namespace），互不影响。</p>
<h3 id="3-7-1-了解对命名空间的需求-75"><a href="#3-7-1-了解对命名空间的需求-75" class="headerlink" title="3.7.1 了解对命名空间的需求 75"></a>3.7.1 了解对命名空间的需求 75</h3><p>在使用多个namespace的前提下，可以将包含大量组件的复杂系统拆分为更小的不同组，这些不同组也可以用于在多租户环境中分配资源，将资源分配为生产、开发和QA环境。两个不同命名空间可以包含同名资源。</p>
<blockquote>
<p>我们在业务上也这样使用过，为了减小硬件开销，开发和QA环境使用同一套k8s集群，使用不同的namespace区分。</p>
</blockquote>
<h3 id="3-7-2-发现其他命名空间及其-pod-75"><a href="#3-7-2-发现其他命名空间及其-pod-75" class="headerlink" title="3.7.2 发现其他命名空间及其 pod 75"></a>3.7.2 发现其他命名空间及其 pod 75</h3><p>命名空间除了为资源名称提供了一个作用域，也可用于仅允许某些用户访问某些特定资源，甚至限制单个用户可用的计算资源数量。</p>
<h3 id="3-7-3-创建一个命名空间-76"><a href="#3-7-3-创建一个命名空间-76" class="headerlink" title="3.7.3 创建一个命名空间 76"></a>3.7.3 创建一个命名空间 76</h3><p>k8s中的所有资源都是一个API对象。命名空间同理，所以创建namespace也可以用YAML文件描述，使用<code>kubectl create -f xxx.yaml</code>创建。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: custom-namespace</span><br></pre></td></tr></table></figure>

<p>也可以通过<code>kubectl create namespace</code>命令创建。</p>
<h3 id="3-7-4-管理其他命名空间中的对象-77"><a href="#3-7-4-管理其他命名空间中的对象-77" class="headerlink" title="3.7.4 管理其他命名空间中的对象 77"></a>3.7.4 管理其他命名空间中的对象 77</h3><p>在列出、描述、创建、修改、删除等操作中，需要给<code>kubectl</code>命令传递<code>--namespace</code>。否则<code>kubectl</code>在当前上下文中配置的默认命名空间执行操作。</p>
<p>当前上下文的命名空间可以通过<code>kubectl config</code>修改。要想快速切换到不同的命名空间，可以设置以下别名：<code>alias kcd=&#39;kubectl config set-context $(kubectl config current-context) --namespace&#39;</code>。然后使用<code>kcd some-namespace</code>在命名空间之间进行切换。</p>
<h3 id="3-7-5-命名空间提供的隔离-78"><a href="#3-7-5-命名空间提供的隔离-78" class="headerlink" title="3.7.5 命名空间提供的隔离 78"></a>3.7.5 命名空间提供的隔离 78</h3><p>你需要首先创建命名空间，然后再创建资源。</p>
<p>k8s 包含三个预设的命名空间：</p>
<ul>
<li>default</li>
<li>kube-public</li>
<li>kube-system</li>
</ul>
<p>命名空间之间是否网络隔离依赖于k8s使用的NetworkPolicy的配置。</p>
<h2 id="3-8-停止和移除-pod-78"><a href="#3-8-停止和移除-pod-78" class="headerlink" title="3.8 停止和移除 pod 78"></a>3.8 停止和移除 pod 78</h2><h3 id="3-8-1-按名称删除-pod-78"><a href="#3-8-1-按名称删除-pod-78" class="headerlink" title="3.8.1 按名称删除 pod 78"></a>3.8.1 按名称删除 pod 78</h3><p>在删除pod的过程中，实际上我们指示k8s终止该pod中的所有容器。k8s会向进程发送SIGTERM信号并等待一定时间，使其正常关闭（所以为了确保进程能正常关闭，业务代码中需要处理SIGTERM信号）。如果没有及时关闭，k8s则通过发送SIGKILL终止该进程。</p>
<h3 id="3-8-2-使用标签选择器删除-pod-79"><a href="#3-8-2-使用标签选择器删除-pod-79" class="headerlink" title="3.8.2 使用标签选择器删除 pod 79"></a>3.8.2 使用标签选择器删除 pod 79</h3><p>可以使用标签一次删除所有指定标签的pod。</p>
<h3 id="3-8-3-通过删除整个命名空间来删除-pod-80"><a href="#3-8-3-通过删除整个命名空间来删除-pod-80" class="headerlink" title="3.8.3 通过删除整个命名空间来删除 pod 80"></a>3.8.3 通过删除整个命名空间来删除 pod 80</h3><p>删除整个命名空间，pod将也会自动删除。</p>
<h3 id="3-8-4-删除命名空间中的所有-pod，但保留命名空间-80"><a href="#3-8-4-删除命名空间中的所有-pod，但保留命名空间-80" class="headerlink" title="3.8.4 删除命名空间中的所有 pod，但保留命名空间 80"></a>3.8.4 删除命名空间中的所有 pod，但保留命名空间 80</h3><p>要删除pod，还需要删除ReplicationController，否则会根据YAML描述文件自动创建新的pod。因为k8s是声明式设计。</p>
<h3 id="3-8-5-删除命名空间中的（几乎）所有资源-80"><a href="#3-8-5-删除命名空间中的（几乎）所有资源-80" class="headerlink" title="3.8.5 删除命名空间中的（几乎）所有资源 80"></a>3.8.5 删除命名空间中的（几乎）所有资源 80</h3><p><code>--all</code>删除所有内容并不是真的删除所有内容，一些资源例如secret会被保留下来，除非明确指定删除。</p>
<h2 id="3-9-本章的k8s命令"><a href="#3-9-本章的k8s命令" class="headerlink" title="3.9 本章的k8s命令"></a>3.9 本章的k8s命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">########## 查看pod ########## </span><br><span class="line"></span><br><span class="line"># 查看已部署的pod的完整YAML</span><br><span class="line">$ kubectl get pod kubia-zxzij -o yaml</span><br><span class="line"></span><br><span class="line"># 查看API对象支持的属性和解释</span><br><span class="line">$ kubectl explain pods</span><br><span class="line">$ kubectl explain pods.spec</span><br><span class="line"></span><br><span class="line"># 得到运行中的pod的完整定义</span><br><span class="line">$ kubectl get pod kubia-manual -o yaml</span><br><span class="line">$ kubectl get pod kubia-manual -o json</span><br><span class="line"></span><br><span class="line">########## 创建资源 ##########  </span><br><span class="line"></span><br><span class="line"># 从文件(YAML或JSON)创建资源</span><br><span class="line">$ kubectl create -f kubia-manual.yaml</span><br><span class="line"></span><br><span class="line">########## 查看日志 ##########  </span><br><span class="line"></span><br><span class="line"># 查看pod日志(准确地说是容器的日志)</span><br><span class="line">$ kubectl logs kubia-manual -c kubia</span><br><span class="line"></span><br><span class="line">########## 端口转发 ##########  </span><br><span class="line"></span><br><span class="line"># 将本地端口8888转发到pod端口8080</span><br><span class="line">$ kubectl port-forward kubia-manual 8888:8080</span><br><span class="line"></span><br><span class="line">########## label ##########  </span><br><span class="line"></span><br><span class="line"># 列出pod，带上标签</span><br><span class="line">$ kubectl get pod --show-labels</span><br><span class="line"></span><br><span class="line"># 列出pod，仅展示指定标签</span><br><span class="line">$ kubectl get pod -L creation_method,env</span><br><span class="line"></span><br><span class="line"># 为pod添加标签</span><br><span class="line">$ kubectl label pod kubia-manual creation_method&#x3D;manual</span><br><span class="line"></span><br><span class="line"># 为pod修改标签</span><br><span class="line">$ kubectl label pod kubia-manual-v2 env&#x3D;debug --overwrite</span><br><span class="line"></span><br><span class="line"># 列出包含creation_method标签，值等于manual的pod</span><br><span class="line">$ kubectl get pod -l creation_method&#x3D;manual</span><br><span class="line"></span><br><span class="line"># 列出包含env标签的pod</span><br><span class="line">$ kubectl get pod -l env</span><br><span class="line"></span><br><span class="line"># 列出没有env标签的pod</span><br><span class="line">$ kubectl get pod -l &#39;!env&#39;</span><br><span class="line"></span><br><span class="line"># 其它标签筛选条件</span><br><span class="line">creation_method!&#x3D;manual：选择带有creation_method标签，并且值不等于manual的pod。</span><br><span class="line">env in (prod, devel)：选择带有env标签且值为prod或devel的pod。</span><br><span class="line">env notin (prod, devel)：选择带有env标签，但其值不是prod或devel的pod。</span><br><span class="line"></span><br><span class="line"># 给节点添加标签gpu&#x3D;true</span><br><span class="line">$ kubectl label node gke-kubia-85f6-node-orrx gpu&#x3D;true</span><br><span class="line"></span><br><span class="line"># 列出只包含标签gpu&#x3D;true的节点</span><br><span class="line">$ kubectl get nodes -l gpu&#x3D;true</span><br><span class="line"></span><br><span class="line"># 列出所有节点，展示gpu标签值附加列</span><br><span class="line">$ kubectl get nodes -L gpu</span><br><span class="line"></span><br><span class="line">########## annotations ##########  </span><br><span class="line"></span><br><span class="line"># 给pod添加注解，将注解mycompany.com&#x2F;someannotation添加为值foo bar</span><br><span class="line">$ kubectl annotate pod kubia-manual mycompany.com&#x2F;someannotation&#x3D;&quot;foo bar&quot;</span><br><span class="line"></span><br><span class="line"># 查看pod的注解</span><br><span class="line">$ kubectl describe pod kubia-manual | grep annotations</span><br><span class="line"></span><br><span class="line">########## namespace ##########</span><br><span class="line"></span><br><span class="line"># 列出所有命名空间</span><br><span class="line">$ kubectl get ns</span><br><span class="line"></span><br><span class="line"># 列出属于命名空间kube-system的pod</span><br><span class="line">$ kubectl get pod --namespace kube-system（--namespace的缩写是-n）</span><br><span class="line"></span><br><span class="line"># 创建命名空间</span><br><span class="line">$ kubectl create namespace custom-namespace</span><br><span class="line"></span><br><span class="line">########## 删除资源 ##########</span><br><span class="line"></span><br><span class="line"># 删除pod</span><br><span class="line">$ kubectl delete pod kubia-gpu</span><br><span class="line"></span><br><span class="line"># 删除指定标签的pod</span><br><span class="line">$ kubectl delete pod -l create_method&#x3D;manual</span><br><span class="line"></span><br><span class="line"># 删除指定命名空间</span><br><span class="line">$ kubectl delete ns custom-namespace</span><br><span class="line"></span><br><span class="line"># 删除当前命名空间中的所有pod</span><br><span class="line">$ kubectl delete pod --all</span><br><span class="line"></span><br><span class="line"># 删除当前命名空间的所有资源(并不是真的删除所有内容)</span><br><span class="line">$ kubectl delete all --all</span><br></pre></td></tr></table></figure>

<h1 id="4-副本机制和其他控制器-：部署托管的-pod-83"><a href="#4-副本机制和其他控制器-：部署托管的-pod-83" class="headerlink" title="4 副本机制和其他控制器 ：部署托管的 pod 83"></a>4 副本机制和其他控制器 ：部署托管的 pod 83</h1><p>前三章比较基础，从这一章开始，事情变得有趣起来。</p>
<p>通过创建ReplicationControlle或Deployment这样的资源，由它们来创建并管理实际的pod。kubelet会保持该节点上的pod健康。</p>
<h2 id="4-1-保持-pod-健康-84"><a href="#4-1-保持-pod-健康-84" class="headerlink" title="4.1 保持 pod 健康 84"></a>4.1 保持 pod 健康 84</h2><h3 id="4-1-1-介绍存活探针-84"><a href="#4-1-1-介绍存活探针-84" class="headerlink" title="4.1.1 介绍存活探针 84"></a>4.1.1 介绍存活探针 84</h3><p>k8s可以通过存活探针(liveness probe)检查容器是否还在与进行。可以为pod中的每个容器单独指定存活探针，如果探测失败，k8s将定期执行探针并重新启动容器。</p>
<p>k8s有三种探测容器的机制（在spec内定义livenessProbe）：</p>
<ul>
<li>HTTP GET 探针：是否能正确响应GET请求。</li>
<li>TCP 探针：是否能建立TCP连接。</li>
<li>exec 探针：在容器内执行指定命令并检查退出状态码。</li>
</ul>
<h3 id="4-1-2-创建基于-HTTP-的存活探针-85"><a href="#4-1-2-创建基于-HTTP-的存活探针-85" class="headerlink" title="4.1.2 创建基于 HTTP 的存活探针 85"></a>4.1.2 创建基于 HTTP 的存活探针 85</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa&#x2F;kubia-unhealthy</span><br><span class="line">    name: kubia</span><br><span class="line">    livenessProbe:</span><br><span class="line">      httpGet:</span><br><span class="line">        path: &#x2F;</span><br><span class="line">        port: 8080</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3-使用存活探针-86"><a href="#4-1-3-使用存活探针-86" class="headerlink" title="4.1.3 使用存活探针 86"></a>4.1.3 使用存活探针 86</h3><p>通过<code>kubectl describe</code>查看为什么必须「重启」容器。不是真的重启，是创建一个新的容器。</p>
<p><code>Exit Code</code>的值减去128是终止进程的信号编号。比如<code>Exit Code</code>是137，表示因为SIGKILL(9)信号被终止。</p>
<h3 id="4-1-4-配置存活探针的附加属性-87"><a href="#4-1-4-配置存活探针的附加属性-87" class="headerlink" title="4.1.4 配置存活探针的附加属性 87"></a>4.1.4 配置存活探针的附加属性 87</h3><p>其它属性，包括delay、timeout、period等。</p>
<p>例如可用<code>initialDelaySeconds</code>自定义初始延迟。务必记得设置一个初始延迟来说明应用程序的启动时间。否则容器可能不断被重启。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">    livenessProbe:</span><br><span class="line">      httpGet:</span><br><span class="line">        path: &#x2F;</span><br><span class="line">        port: 8080</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="4-1-5-创建有效的存活探针-88"><a href="#4-1-5-创建有效的存活探针-88" class="headerlink" title="4.1.5 创建有效的存活探针 88"></a>4.1.5 创建有效的存活探针 88</h3><p>一定要检查应用程序的内部，而没有外部因素的影响，比如不能调用在其它pod的数据库容器。并且保证存活探针轻量，也无需在探针中实现重式循环。</p>
<h2 id="4-2-了解-ReplicationController-89"><a href="#4-2-了解-ReplicationController-89" class="headerlink" title="4.2 了解 ReplicationController 89"></a>4.2 了解 ReplicationController 89</h2><p>ReplicationController已经完全被ReplicaSet替代，阅读了一下但不再赘述。</p>
<h2 id="4-3-使用-ReplicaSet-而不是-ReplicationController-104"><a href="#4-3-使用-ReplicaSet-而不是-ReplicationController-104" class="headerlink" title="4.3 使用 ReplicaSet 而不是 ReplicationController 104"></a>4.3 使用 ReplicaSet 而不是 ReplicationController 104</h2><p>通常不会直接创建ReplicaSet，而是通过在创建Deployment资源（在后面章节讲）时创建。</p>
<p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/" target="_blank" rel="noopener">replicaset的官方文档</a></p>
<h3 id="4-3-1-比较-ReplicaSet-和-ReplicationController-104"><a href="#4-3-1-比较-ReplicaSet-和-ReplicationController-104" class="headerlink" title="4.3.1 比较 ReplicaSet 和 ReplicationController 104"></a>4.3.1 比较 ReplicaSet 和 ReplicationController 104</h3><p>ReplicaSet的标签选择器的表达能力比ReplicationController更强。</p>
<h3 id="4-3-2-定义-ReplicaSet-105"><a href="#4-3-2-定义-ReplicaSet-105" class="headerlink" title="4.3.2 定义 ReplicaSet 105"></a>4.3.2 定义 ReplicaSet 105</h3><p>ReplicaSet不是v1 API的一部分，但属于apps API组的v1beta2版本。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1beta2</span><br><span class="line">kind: ReplicaSet</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: kubia</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: kubia</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: kubia</span><br><span class="line">        image: luksa&#x2F;kubia</span><br></pre></td></tr></table></figure>

<h3 id="4-3-3-创建和检查-ReplicaSet-106"><a href="#4-3-3-创建和检查-ReplicaSet-106" class="headerlink" title="4.3.3 创建和检查 ReplicaSet 106"></a>4.3.3 创建和检查 ReplicaSet 106</h3><p>使用<code>kubectl create</code>命令根据YAML文件创建ReplicaSet。</p>
<h3 id="4-3-4-使用-ReplicaSet-的更富表达力的标签选择器-106"><a href="#4-3-4-使用-ReplicaSet-的更富表达力的标签选择器-106" class="headerlink" title="4.3.4 使用 ReplicaSet 的更富表达力的标签选择器 106"></a>4.3.4 使用 ReplicaSet 的更富表达力的标签选择器 106</h3><p>rs和rc相比最大的改动就是支持更为强大复杂的标签选择器。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">selector:</span><br><span class="line">  matchExpressions:</span><br><span class="line">    - key: app</span><br><span class="line">    - operator: In</span><br><span class="line">      values:</span><br><span class="line">        - kubia</span><br></pre></td></tr></table></figure>

<p>可以在<code>selector</code>中使用<code>matchExpressions</code>，支持的<code>operator</code>有：</p>
<ul>
<li>In：pod的label在指定labels之中。</li>
<li>NotIn：不在指定labels中。</li>
<li>Exists：指定的label key存在。</li>
<li>DoesNotExist：指定的label key不存在。</li>
</ul>
<p>如果你指定了多个表达式，则所有这些表达式都必须为true才能使选择器与pod匹配。如果同时指定matchLabels和matchExpressions，则所有标签都必须匹配，并且所有表达式必须计算为true以使该pod与选择器匹配。</p>
<h3 id="4-3-5-ReplicaSet-小结-107"><a href="#4-3-5-ReplicaSet-小结-107" class="headerlink" title="4.3.5 ReplicaSet 小结 107"></a>4.3.5 ReplicaSet 小结 107</h3><p>删除ReplicaSet会删除所有的pod。</p>
<h2 id="4-4-使用-DaemonSet-在每个节点上运行一个-pod-107"><a href="#4-4-使用-DaemonSet-在每个节点上运行一个-pod-107" class="headerlink" title="4.4 使用 DaemonSet 在每个节点上运行一个 pod 107"></a>4.4 使用 DaemonSet 在每个节点上运行一个 pod 107</h2><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/" target="_blank" rel="noopener">daemonset的官方文档</a></p>
<h3 id="4-4-1-使用-DaemonSet-在每个节点上运行一个-pod-108"><a href="#4-4-1-使用-DaemonSet-在每个节点上运行一个-pod-108" class="headerlink" title="4.4.1 使用 DaemonSet 在每个节点上运行一个 pod 108"></a>4.4.1 使用 DaemonSet 在每个节点上运行一个 pod 108</h3><p>使用DaemonSet在每个节点上运行一个pod。一般用于运行一些基础组件，如kube-proxy、日志组件等。</p>
<p>DaemonSet没有期望的副本数的概念，它的工作是确保一个pod匹配它的选择器并在每个节点上运行。如果节点下线，DaemonSet不会在其它地方重新创建pod。但是当一个新节点加入到集群中，DaemonSet会立即部署一个新的pod实例。</p>
<h3 id="4-4-2-使用-DaemonSet-只在特定的节点上运行-pod-109"><a href="#4-4-2-使用-DaemonSet-只在特定的节点上运行-pod-109" class="headerlink" title="4.4.2 使用 DaemonSet 只在特定的节点上运行 pod 109"></a>4.4.2 使用 DaemonSet 只在特定的节点上运行 pod 109</h3><p>通过pod模板中的nodeSelector属性指定。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1beta2</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: ssd-monitor</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: ssd-monitor</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: ssd-monitor</span><br><span class="line">    spec:</span><br><span class="line">      nodeSelector:</span><br><span class="line">        disk: ssd</span><br><span class="line">      containers:</span><br><span class="line">      - name: main</span><br><span class="line">        image: luksa&#x2F;ssd-monitor</span><br></pre></td></tr></table></figure>

<h2 id="4-5-运行执行单个任务的-pod-112"><a href="#4-5-运行执行单个任务的-pod-112" class="headerlink" title="4.5 运行执行单个任务的 pod 112"></a>4.5 运行执行单个任务的 pod 112</h2><p>前面提到的ReplicationController、ReplicaSet、DaemonSet都会持续运行任务，永远达不到完成态。k8s通过Job资源提供了可完成任务的支持，其进程正常终止后，不重新启动。</p>
<p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/" target="_blank" rel="noopener">Job的官方文档</a></p>
<h3 id="4-5-1-介绍-Job-资源-112"><a href="#4-5-1-介绍-Job-资源-112" class="headerlink" title="4.5.1 介绍 Job 资源 112"></a>4.5.1 介绍 Job 资源 112</h3><p>Job可以调度pod来运行一次性的任务，程序运行成功退出后，不重启容器。一旦任务完成，pod就被认为处于完成状态。</p>
<p>如果pod在被调度的节点上异常退出后，由Job管理的pod会一直被重新安排，直到成功完成任务。</p>
<h3 id="4-5-2-定义-Job-资源-113"><a href="#4-5-2-定义-Job-资源-113" class="headerlink" title="4.5.2 定义 Job 资源 113"></a>4.5.2 定义 Job 资源 113</h3><p>重启策略<code>restartPolicy</code>默认为Always。Job pod不能使用默认策略。需要明确将其设置为<code>OnFailure</code>或<code>Never</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: batch&#x2F;v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: batch-job</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: batch-job</span><br><span class="line">    spec:</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      containers:</span><br><span class="line">      - name: main</span><br><span class="line">        image: luksa&#x2F;batch-job</span><br></pre></td></tr></table></figure>

<h3 id="4-5-3-看-Job-运行一个-pod-114"><a href="#4-5-3-看-Job-运行一个-pod-114" class="headerlink" title="4.5.3 看 Job 运行一个 pod 114"></a>4.5.3 看 Job 运行一个 pod 114</h3><p>完成后的pod STATUS是Completed，并且不被删除。除非手动删除pod，或者删除创建它的Job。</p>
<h3 id="4-5-4-在-Job-中运行多个-pod-实例-114"><a href="#4-5-4-在-Job-中运行多个-pod-实例-114" class="headerlink" title="4.5.4 在 Job 中运行多个 pod 实例 114"></a>4.5.4 在 Job 中运行多个 pod 实例 114</h3><p>通过在Job配置中设置<code>completions</code>和<code>parallelism</code>属性，可以以并行或串行方式运行多个pod。</p>
<ul>
<li>顺序运行Job pod</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: batch&#x2F;v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: multi-completion-batch-job</span><br><span class="line">spec:</span><br><span class="line">  completions: 5</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: batch-job</span><br><span class="line">    spec:</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      containers:</span><br><span class="line">      - name: main</span><br><span class="line">        image: luksa&#x2F;batch-job</span><br></pre></td></tr></table></figure>

<ul>
<li>并行运行Job pod</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: batch&#x2F;v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: multi-completion-batch-job</span><br><span class="line">spec:</span><br><span class="line">  completions: 5</span><br><span class="line">  parallelism: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: batch-job</span><br><span class="line">    spec:</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      containers:</span><br><span class="line">      - name: main</span><br><span class="line">        image: luksa&#x2F;batch-job</span><br></pre></td></tr></table></figure>

<p>通过<code>kubectl scale</code>命令更改<code>parallelism</code>属性，Job可以在运行过程中被缩放。</p>
<h3 id="4-5-5-限制-Job-pod-完成任务的时间-116"><a href="#4-5-5-限制-Job-pod-完成任务的时间-116" class="headerlink" title="4.5.5 限制 Job pod 完成任务的时间 116"></a>4.5.5 限制 Job pod 完成任务的时间 116</h3><p>通过<code>activeDeadlineSeconds</code>属性，限制pod运行的时间。<br>通过<code>spec.backoffLimit</code>属性，配置Job在被标记为失败之前可以重试的次数。默认为6。</p>
<h2 id="4-6-安排-Job-定期运行或在将来运行一次-116"><a href="#4-6-安排-Job-定期运行或在将来运行一次-116" class="headerlink" title="4.6 安排 Job 定期运行或在将来运行一次 116"></a>4.6 安排 Job 定期运行或在将来运行一次 116</h2><p>k8s用CronJob资源设置cron任务。</p>
<p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/" target="_blank" rel="noopener">CronJob的官方文档</a></p>
<h3 id="4-6-1-创建一个-CronJob-116"><a href="#4-6-1-创建一个-CronJob-116" class="headerlink" title="4.6.1 创建一个 CronJob 116"></a>4.6.1 创建一个 CronJob 116</h3><p>CronJob通过<code>jobTemplate</code>模板创建资源。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: batch&#x2F;v1beta1</span><br><span class="line">kind: CronJob</span><br><span class="line">metadata:</span><br><span class="line">  name: batch-job-every-fifteen-minutes</span><br><span class="line">spec:</span><br><span class="line">  schedule: &quot;0,15,30,45 * * * *&quot;</span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        metadata:</span><br><span class="line">          labels:</span><br><span class="line">            app: periodic-batch-job</span><br><span class="line">        spec:</span><br><span class="line">          restartPolicy: OnFailure</span><br><span class="line">          containers:</span><br><span class="line">          - name: main</span><br><span class="line">            image: luksa&#x2F;batch-job</span><br></pre></td></tr></table></figure>

<h3 id="4-6-2-了解计划任务的运行方式-118"><a href="#4-6-2-了解计划任务的运行方式-118" class="headerlink" title="4.6.2 了解计划任务的运行方式 118"></a>4.6.2 了解计划任务的运行方式 118</h3><p>在计划的时间内，CronJob资源会创建Job资源，然后Job创建pod。</p>
<p>可以通过指定CronJob规范中的<code>startingDeadlineSeconds</code>字段来指定截止时间。</p>
<p>CronJob总是为计划中配置的每个执行创建一个Job，但可能会同时创建两个Job，或者根本没有创建。为了解决第一个问题，你的任务应该是幂等的（多次而不是一次运行不会得到不希望的结果）。对于第二个问题，请确保下一个任务运行完成本应该由上一次的（错过的）运行完成的任何工作。</p>
<h2 id="4-7-本章的k8s命令-118"><a href="#4-7-本章的k8s命令-118" class="headerlink" title="4.7 本章的k8s命令 118"></a>4.7 本章的k8s命令 118</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">########## 日志 ##########</span><br><span class="line"></span><br><span class="line"># 获取前一个容器的日志</span><br><span class="line">$ kubectl logs mypod --previous</span><br><span class="line"></span><br><span class="line">########## ReplicationController ##########</span><br><span class="line"></span><br><span class="line"># 编辑模板</span><br><span class="line">$ kubectl edit rc kubia</span><br><span class="line"></span><br><span class="line"># 对管理的pod数量伸缩，等于修改spec.replicas&#x3D;3</span><br><span class="line">$ kubectl scale rc kubia --replicas&#x3D;3</span><br><span class="line"></span><br><span class="line"># 删除rc使pod不受管理但保持运行</span><br><span class="line">$ kubectl delete rc kubia --cascade&#x3D;false</span><br><span class="line"></span><br><span class="line">########## ReplicaSet ##########</span><br><span class="line"></span><br><span class="line"># 查看ReplicaSet</span><br><span class="line">$ kubectl get rs</span><br><span class="line"></span><br><span class="line"># 描述ReplicaSet</span><br><span class="line">$ kubectl describe rs</span><br><span class="line"></span><br><span class="line"># 删除ReplicaSet</span><br><span class="line">$ kubectl delete rs kubia</span><br><span class="line"></span><br><span class="line">########## DaemonSet ##########</span><br><span class="line"></span><br><span class="line"># 查看DaemonSet</span><br><span class="line">$ kubectl get ds</span><br><span class="line"></span><br><span class="line">########## node ##########</span><br><span class="line"></span><br><span class="line"># 给节点添加标签</span><br><span class="line">$ kubectl label node minikube disk&#x3D;ssd</span><br><span class="line"></span><br><span class="line"># 从节点删除标签</span><br><span class="line">$ kubectl label node minikube disk&#x3D;hdd --overwrite</span><br><span class="line"></span><br><span class="line">########## Job ##########</span><br><span class="line"></span><br><span class="line"># 查看Job</span><br><span class="line">$ kubectl get jobs</span><br><span class="line"></span><br><span class="line"># 查看所有pod包括已经完成的</span><br><span class="line">$ kubectl get pod --show-all(缩写-a)</span><br><span class="line"></span><br><span class="line"># 将Job并行度改成3</span><br><span class="line">$ kubectl scale job multi-completion-batch-job --replicas 3</span><br></pre></td></tr></table></figure>

<h1 id="5-服务-：让客户端发现-pod-并与之通信-121"><a href="#5-服务-：让客户端发现-pod-并与之通信-121" class="headerlink" title="5 服务 ：让客户端发现 pod 并与之通信 121"></a>5 服务 ：让客户端发现 pod 并与之通信 121</h1><p>pod会在node间被调度，一组功能相同的pod需要对外提供一个稳定地址，而service就是pod对外的门户。</p>
<p><a href="https://kubernetes.io/docs/concepts/services-networking/service/" target="_blank" rel="noopener">service的官方文档</a></p>
<h2 id="5-1-介绍服务-122"><a href="#5-1-介绍服务-122" class="headerlink" title="5.1 介绍服务 122"></a>5.1 介绍服务 122</h2><p>service会通过selector绑定多个pod，service通过clusterIP对外接收请求，然后分配给绑定的pod。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/11.png">

<h3 id="5-1-1-创建服务-123"><a href="#5-1-1-创建服务-123" class="headerlink" title="5.1.1 创建服务 123"></a>5.1.1 创建服务 123</h3><p>通过<code>kubectl expose</code>命令或者YAML文件描述创建service均可。</p>
<p>例如创建一个名叫kubia的service。它将在端口80接收请求并将连接路由到具有标签选择器<code>app=kubia</code>的pod的8080端口上。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80 # 该服务的可用端口</span><br><span class="line">    targetPort: 8080 # 服务将连接转发到的容器端口</span><br><span class="line">  selector:</span><br><span class="line">    app: kubia # 具有app&#x3D;kubia标签的pod都属于该服务</span><br></pre></td></tr></table></figure>

<p><code>kubectl exec</code>命令可以在一个存在的pod中运行命令。</p>
<p>如果希望特定客户端产生的所有请求每次都指向同一个 pod，可以设置服务的<code>sessionAffinity</code>属性为<code>ClientIP</code>。<br>k8s仅仅支持两种形式的会话亲和性服务： None 和 ClientIP。默认值None。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">spec:</span><br><span class="line">  sessionAffinity: ClientIP</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<blockquote>
<p>k8s服务不是在HTTP层工作，服务处理TCP/UDP包，并不关心包的内容，所以k8s不支持基于cookie(HTTP协议的一部分)的会话亲和性选项。</p>
</blockquote>
<p>同一个服务可以暴露多个端口，但必须给每个端口指定名字。标签选择器应用于整个服务，不能对每个端口做单独的配置。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  - name: https</span><br><span class="line">    port: 443</span><br><span class="line">    targetPort: 8443</span><br><span class="line">  selector:</span><br><span class="line">    app: kubia</span><br></pre></td></tr></table></figure>

<p>可以在pod中定义port的名称，这样可以在service中按名称引用这些端口。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">kind: pod</span><br><span class="line">spec:</span><br><span class="line">  container:</span><br><span class="line">  - name: kubia</span><br><span class="line">    ports:</span><br><span class="line">    - name: http</span><br><span class="line">      containerPort: 8080</span><br><span class="line">    - name: https</span><br><span class="line">      containerPort: 8443</span><br><span class="line">---</span><br><span class="line">kind: Service</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: http</span><br><span class="line">  - name: https</span><br><span class="line">    port: 443</span><br><span class="line">    targetPort: https</span><br></pre></td></tr></table></figure>

<h3 id="5-1-2-服务发现-129"><a href="#5-1-2-服务发现-129" class="headerlink" title="5.1.2 服务发现 129"></a>5.1.2 服务发现 129</h3><p>在服务后面的pod可能删除重建，它们的IP地址可能改变，数量也会增减，但是始终可以通过服务的单一不变的IP地址访问到这些pod。</p>
<ul>
<li>可以通过环境变量获取服务IP地址和端口号。</li>
<li>可以通过DNS发现服务（推荐）。但是客户端必须知道服务的端口号。</li>
</ul>
<p>service的DNS地址为<code>&lt;service_name&gt;.&lt;namespace&gt;.svc.cluster.local</code>。<code>svc.cluster.local</code>是在所有集群本地服务名称中使用的可配置集群域后缀，可以省略。</p>
<p>k8s有一个kube-dns的pod，作为集群的DNS服务。集群中的其它pod都被配置成使用其作为DNS服务器(通过修改每个容器的<code>/etc/resolv.conf</code>文件实现)。pod是否使用内部的DNS服务器根据<code>spec.dnsPolicy</code>决定。</p>
<blockquote>
<p>创建service时会自动地创建DNS记录，DNS里会记录和service关联的所有pods的IP。这一特性非常的有用，比如如果你想要在prometheus里监听某个daemonset，那么就可以为这些daemonset配置一个svc，然后让prometheus通过dns_sd_configs（基于DNS的服务发现）去自动发现所有的daemonset pods。</p>
</blockquote>
<h2 id="5-2-连接集群外部的服务-132"><a href="#5-2-连接集群外部的服务-132" class="headerlink" title="5.2 连接集群外部的服务 132"></a>5.2 连接集群外部的服务 132</h2><h3 id="5-2-1-介绍服务-endpoint-133"><a href="#5-2-1-介绍服务-endpoint-133" class="headerlink" title="5.2.1 介绍服务 endpoint 133"></a>5.2.1 介绍服务 endpoint 133</h3><p>服务并不是和 pod 直接相连的。有一种资源介于两者之间——它就是Endpoint资源。<br>service创建endpoint，并且将流量导向 endpoint。</p>
<blockquote>
<p>Pods expose themselves through endpoints to a service. </p>
</blockquote>
<h3 id="5-2-2-手动配置服务的-endpoint-133"><a href="#5-2-2-手动配置服务的-endpoint-133" class="headerlink" title="5.2.2 手动配置服务的 endpoint 133"></a>5.2.2 手动配置服务的 endpoint 133</h3><p>尽管在spec服务中定义了pod选择器，但在重定向传入连接时不会直接使用它。相反，选择器用于构建IP和端口列表，然后存储在Endpoint资源中。当客户端连接到服务时，服务代理选择这些IP和端口对中的一个。</p>
<p>selector用于构建endpoint，svc直接从endpoint中选择一个地址来使用。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: external-service # service的名称必须和endpoint的名字匹配</span><br><span class="line">spec: # 因为不需要匹配到pods，所以无需定义selector</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Endpoints</span><br><span class="line">metadata:</span><br><span class="line">  name: external-service # endpoint的名称必须和service的名称匹配</span><br><span class="line">subsets:</span><br><span class="line">  - addresses:</span><br><span class="line">    - ip: 11.11.11.11 # service将会将请求重定向的地址</span><br><span class="line">    - ip: 22.22.22.22</span><br><span class="line">    ports:</span><br><span class="line">    - port: 80 # endpoint的目标端口</span><br></pre></td></tr></table></figure>

<img width="600" src="/images/Kubernetes In Action阅读笔记/12.png">

<h3 id="5-2-3-为外部服务创建别名-135"><a href="#5-2-3-为外部服务创建别名-135" class="headerlink" title="5.2.3 为外部服务创建别名 135"></a>5.2.3 为外部服务创建别名 135</h3><p>要创建一个具有别名的外部服务的服务时，将创建service资源的<code>type</code>字段设置为<code>ExternalName</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: external-service</span><br><span class="line">spec:</span><br><span class="line">  type: ExternalName</span><br><span class="line">  externalName: api.somecompany.com # 实际服务的完全限定域名</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br></pre></td></tr></table></figure>

<h2 id="5-3-将服务暴露给外部客户端-136"><a href="#5-3-将服务暴露给外部客户端-136" class="headerlink" title="5.3 将服务暴露给外部客户端 136"></a>5.3 将服务暴露给外部客户端 136</h2><h3 id="5-3-1-使用-NodePort-类型的服务-137"><a href="#5-3-1-使用-NodePort-类型的服务-137" class="headerlink" title="5.3.1 使用 NodePort 类型的服务 137"></a>5.3.1 使用 NodePort 类型的服务 137</h3><p>通过创建<code>NodePort</code>类型的服务，可以让k8s在其所有节点上保留一个端口（所有节点上都使用相同的端口号），并将传入的连接转发给作为服务部分的pod。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/13.png">

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia-nodeport</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">    nodePort: 30123</span><br><span class="line">  selector:</span><br><span class="line">    app: kubia</span><br></pre></td></tr></table></figure>

<p>EXTERNAL-IP列显示nodes，表明服务可通过任何集群节点的IP地址访问。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/14.png">

<h3 id="5-3-2-通过负载均衡器将服务暴露出来-140"><a href="#5-3-2-通过负载均衡器将服务暴露出来-140" class="headerlink" title="5.3.2 通过负载均衡器将服务暴露出来 140"></a>5.3.2 通过负载均衡器将服务暴露出来 140</h3><p>在EKS或GKE等云端使用k8s服务时，可以将服务的类型设置成<code>LoadBalance</code>，直接将服务绑定到云上的lb上。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/15.png">

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia-loadbalancer</span><br><span class="line">spec:</span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app: kubia</span><br></pre></td></tr></table></figure>

<p>EXTERNAL-IP列显示的是lb的IP，可以通过该IP访问服务。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/16.png">

<h3 id="5-3-3-了解外部连接的特性-142"><a href="#5-3-3-了解外部连接的特性-142" class="headerlink" title="5.3.3 了解外部连接的特性 142"></a>5.3.3 了解外部连接的特性 142</h3><p>可以通过将服务配置为仅将外部通信重定向到接收连接的节点上运行的pod来阻止此额外跳数。这是通过在服务的spec部分中设置<code>externalTrafficPolicy</code>字段。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  externalTrafficPolicy: Local</span><br></pre></td></tr></table></figure>

<h2 id="5-4-通过-Ingress-暴露服务-143"><a href="#5-4-通过-Ingress-暴露服务-143" class="headerlink" title="5.4 通过 Ingress 暴露服务 143"></a>5.4 通过 Ingress 暴露服务 143</h2><p>除了NodePort和LoadBalance这两种向集群外部的客户端公开服务的方法，还有一种方法，创建Ingress资源。</p>
<p>每个LoadBalancer服务都需要自己的负载均衡器，以及独有的公有 IP 地址，而 Ingress 只需要一个公网IP就能为许多服务提供访问。</p>
<p>Ingress在HTTP层工作，可以提供服务不能实现的功能(service在TCP/UDP层工作)。比如基于cookie的会话亲和性(session affinity)等功能。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/17.png">

<p>Ingress其实就是集群的网关，一般都会使用Nginx或HAProxy，通过绑定虚拟主机的形式暴露集群内的服务。</p>
<h3 id="5-4-1-创建-Ingress-资源-145"><a href="#5-4-1-创建-Ingress-资源-145" class="headerlink" title="5.4.1 创建 Ingress 资源 145"></a>5.4.1 创建 Ingress 资源 145</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: kubia.example.com # Ingress将域名kubia.example.com映射到你的服务</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F; # 将所有的请求发送到kubia-nodeport服务的80端口</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: kubia-nodeport</span><br><span class="line">          servicePort: 80</span><br></pre></td></tr></table></figure>

<p>定义了一个单一规则的Ingress，确保Ingress控制器收到的所有请求主机<code>kubia.example.com</code>的HTTP请求，将被发送到端口80上的kubia-nodeport服务。</p>
<h3 id="5-4-2-通过-Ingress-访问服务-146"><a href="#5-4-2-通过-Ingress-访问服务-146" class="headerlink" title="5.4.2 通过 Ingress 访问服务 146"></a>5.4.2 通过 Ingress 访问服务 146</h3><img width="600" src="/images/Kubernetes In Action阅读笔记/18.png">

<p>客户端通过Ingress控制器连接到其中一个pod的流程：</p>
<ul>
<li>客户端首先对<code>kubia.example.com</code>执行DNS查询，得到Ingress控制器的IP。</li>
<li>客户端然后向Ingress控制器发送HTTP请求，并在HTTP header指定host(<code>-H &quot;Host: kubia.example.com&quot;</code>)。</li>
<li>Ingress控制器从该头部确定客户端目标访问哪个service。</li>
<li>通过与该service关联的endpoint对象查看pod IP。</li>
<li>将客户端的请求转发给其中一个pod IP。</li>
</ul>
<blockquote>
<p><code>curl http://kubia.example.com</code>（需要在/etc/hosts添加192.168.99.100 kubia.example.com）和<code>curl http://192.168.99.100 -H &quot;Host: kubia.example.com&quot;</code>均可用来通过Ingress访问服务。</p>
</blockquote>
<h3 id="5-4-3-通过相同的-Ingress-暴露多个服务-147"><a href="#5-4-3-通过相同的-Ingress-暴露多个服务-147" class="headerlink" title="5.4.3 通过相同的 Ingress 暴露多个服务 147"></a>5.4.3 通过相同的 Ingress 暴露多个服务 147</h3><p>一个Ingress可以将多个主机和路径映射到多个服务。</p>
<ul>
<li>将不同的服务映射到相同虚拟主机的不同路径</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">- host: kubia.example.com</span><br><span class="line">  http:</span><br><span class="line">    paths:</span><br><span class="line">    - path: &#x2F;kubia</span><br><span class="line">      backend:</span><br><span class="line">        serviceName: kubia # 对kubia.example.com&#x2F;kubia的请求将会转发至kubia服务</span><br><span class="line">        servicePort: 80</span><br><span class="line">    - path: &#x2F;bar</span><br><span class="line">      backend:</span><br><span class="line">        serviceName: bar # 对kubia.example.com&#x2F;bar的请求将会转发至bar服务</span><br><span class="line">        servicePort: 80</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<ul>
<li>将不同的服务映射到不同的虚拟主机上</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">- host: foo.example.com</span><br><span class="line">  http:</span><br><span class="line">    paths:</span><br><span class="line">    - path: &#x2F;</span><br><span class="line">      backend:</span><br><span class="line">        serviceName: foo # 对foo.example.com的请求将会转发至foo服务</span><br><span class="line">        servicePort: 80</span><br><span class="line">- host: bar.example.com</span><br><span class="line">  http:</span><br><span class="line">    paths:</span><br><span class="line">    - path: &#x2F;</span><br><span class="line">      backend:</span><br><span class="line">        serviceName: bar # 对bar.example.com的请求将会转发至bar服务</span><br><span class="line">        servicePort: 80</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="5-4-4-配置-Ingress-处理-TLS-传输-149"><a href="#5-4-4-配置-Ingress-处理-TLS-传输-149" class="headerlink" title="5.4.4 配置 Ingress 处理 TLS 传输 149"></a>5.4.4 配置 Ingress 处理 TLS 传输 149</h3><p>将证书可私钥附加到Ingress控制器。<br>当客户端创建到Ingress控制器的TLS连接时，控制器将终止TLS连接。客户端和控制器之间的通信是加密的，而控制器和后端pod之间的通信则不是。运行在pod上的应用程序不需要支持TLS。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  tls: # 在这个属性下包含了所有的TLS的配置</span><br><span class="line">  - hosts: </span><br><span class="line">    - kubia.example.com # 将接收来自kubia.example.com主机的TLS连接</span><br><span class="line">    secretName: tls-secret # 从tls-secret中获得之前创建的私钥和证书</span><br><span class="line">  rules:</span><br><span class="line">  - host: kubia.example.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: kubia-nodeport</span><br><span class="line">          servicePort: 80</span><br></pre></td></tr></table></figure>

<h2 id="5-5-pod-就绪后发出信号-150"><a href="#5-5-pod-就绪后发出信号-150" class="headerlink" title="5.5 pod 就绪后发出信号 150"></a>5.5 pod 就绪后发出信号 150</h2><h3 id="5-5-1-介绍就绪探针-151"><a href="#5-5-1-介绍就绪探针-151" class="headerlink" title="5.5.1 介绍就绪探针 151"></a>5.5.1 介绍就绪探针 151</h3><p>就绪探针（readinessProbe）会定期调用，并确定特定的 pod 是否接收客户端请求。当容器的准备就绪探测返回成功时，表示容器已准备好接收请求。</p>
<p>和存活探针一样，就绪探针也有三种类型：</p>
<ul>
<li>Exec</li>
<li>HTTP GET</li>
<li>TCP</li>
</ul>
<p>就绪探针与存活探针最重要的区别是，如果容器未通过准备检查，则不会被终止或重新启动，只是从服务中删除该pod，如果pod再次准备就绪，则重新添加pod到服务。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/19.png">

<p>如果一个pod的就绪探测失败，则将该容器从端点对象中移除。连接到该服务的客户端不会被重定向到pod。这和pod与服务的标签选择器完全不匹配的效果相同。</p>
<h3 id="5-5-2-向-pod-添加就绪探针-152"><a href="#5-5-2-向-pod-添加就绪探针-152" class="headerlink" title="5.5.2 向 pod 添加就绪探针 152"></a>5.5.2 向 pod 添加就绪探针 152</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ReplicationController</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    app: kubia</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: kubia</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: kubia</span><br><span class="line">        image: luksa&#x2F;kubia</span><br><span class="line">        ports:</span><br><span class="line">        - name: http</span><br><span class="line">          containerPort: 8080</span><br><span class="line">        readinessProbe: # pod中的每个容器都会有一个就绪探针</span><br><span class="line">          exec:</span><br><span class="line">            command:</span><br><span class="line">            - ls</span><br><span class="line">            - &#x2F;var&#x2F;ready</span><br></pre></td></tr></table></figure>

<h3 id="5-5-3-了解就绪探针的实际作用-154"><a href="#5-5-3-了解就绪探针的实际作用-154" class="headerlink" title="5.5.3 了解就绪探针的实际作用 154"></a>5.5.3 了解就绪探针的实际作用 154</h3><p>应该通过删除pod或更改pod标签而不是手动更改探针来从服务中手动移除 pod。<br>应该始终定义一个就绪探针，即使它只是向基准URL发送HTTP请求一样简单。</p>
<h2 id="5-6-使用-headless-服务来发现独立的-pod-155"><a href="#5-6-使用-headless-服务来发现独立的-pod-155" class="headerlink" title="5.6 使用 headless 服务来发现独立的 pod 155"></a>5.6 使用 headless 服务来发现独立的 pod 155</h2><p><a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services" target="_blank" rel="noopener">headless service的官方文档</a></p>
<p>如果告诉k8s，不需要为服务提供集群IP，则DNS服务器将返回pod IP而不是单个服务IP。<br>将服务spec中的clusterIP字段设置为None会使服务成为headless服务，因为k8s不会为其分配集群IP，客户端可通过该IP将其连接到支持它的pod。<br>通常情况下，DNS查询svc会返回svc的clusterIP。而对于headless服务，DNS查询会返回一系列A记录，分别对应相应的pod的地址。</p>
<h3 id="5-6-1-创建-headless-服务-156"><a href="#5-6-1-创建-headless-服务-156" class="headerlink" title="5.6.1 创建 headless 服务 156"></a>5.6.1 创建 headless 服务 156</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia-headless</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None # 这使得服务成为headless的</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app: kubia</span><br></pre></td></tr></table></figure>

<h3 id="5-6-2-通过-DNS-发现-pod-156"><a href="#5-6-2-通过-DNS-发现-pod-156" class="headerlink" title="5.6.2 通过 DNS 发现 pod 156"></a>5.6.2 通过 DNS 发现 pod 156</h3><p>非headless服务返回的DNS是服务的集群IP。<br>headless服务返回的DNS是所有就绪的pod的IP。headless服务依然提供跨pod的负载均衡。</p>
<h3 id="5-6-3-发现所有的-pod——包括未就绪的-pod-157"><a href="#5-6-3-发现所有的-pod——包括未就绪的-pod-157" class="headerlink" title="5.6.3 发现所有的 pod——包括未就绪的 pod 157"></a>5.6.3 发现所有的 pod——包括未就绪的 pod 157</h3><p>通过添加annotations，可以将所有匹配标签选择器的pod添加到服务中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    service.alpha.kubernetes.io&#x2F;tolerate-unready-endpoints: &quot;true&quot;</span><br></pre></td></tr></table></figure>

<h2 id="5-7-排除服务故障-158"><a href="#5-7-排除服务故障-158" class="headerlink" title="5.7 排除服务故障 158"></a>5.7 排除服务故障 158</h2><ul>
<li>确保从集群内连接到服务的集群IP，而不是从外部。</li>
<li>不要通过ping服务IP来判断服务是否可访问(服务的集群IP是虚拟IP，是无法ping通的)。</li>
<li>如果已经定义了就绪探针，请确保它返回成功；否则该pod不会成为服务的一部分。</li>
<li>要确认某个容器是服务的一部分，请使用<code>kubectl get endpoint</code>来检查相应的端点对象。</li>
<li>如果尝试通过FQDN或其中一部分来访问服务(例如<code>myservice.mynamespace.svc.cluster.local</code>或<code>myservice.mynamespace</code>)，但不起作用，请查看是否可以使用其集群IP而不是FQDN来访问服务。</li>
<li>检查是否连接到服务公开的端口，而不是目标端口。</li>
<li>尝试直接连接到pod IP以确认pod正在接收正确端口上的连接。</li>
<li>如果甚至无法通过pod的IP访问应用，请确保应用不是仅绑定到本地主机。 </li>
</ul>
<h2 id="5-8-本章的k8s命令-159"><a href="#5-8-本章的k8s命令-159" class="headerlink" title="5.8 本章的k8s命令 159"></a>5.8 本章的k8s命令 159</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">########## Service ##########</span><br><span class="line"></span><br><span class="line"># 在一个运行的pod容器上执行curl，--代表kubectl命令的结束，之后是在pod内部需要执行的命令</span><br><span class="line">$ kubectl exec kubia-7nog1 -- curl -s http:&#x2F;&#x2F;10.111.249.153</span><br><span class="line"></span><br><span class="line"># 展示服务细节</span><br><span class="line">$ kubectl describe svc kubia</span><br><span class="line"></span><br><span class="line">########## Pod ##########</span><br><span class="line"></span><br><span class="line"># 删除所有pod</span><br><span class="line">$ kubectl delete pod --all</span><br><span class="line"></span><br><span class="line"># 在pod容器上运行bash</span><br><span class="line">$ kubectl exec -it kubia-3inly bash</span><br><span class="line"></span><br><span class="line"># 查看Ingress控制器的pod</span><br><span class="line">$ kubectl get pod --all-namespaces|grep ingress</span><br><span class="line"></span><br><span class="line"># 不通过YAML文件进行pod，直接创建pod，不需要通过rc等资源来创建</span><br><span class="line">$ kubectl run dnsutils --image&#x3D;tutum&#x2F;dnsutils --generator&#x3D;run-pod&#x2F;v1 --command -- sleep infinity</span><br><span class="line"></span><br><span class="line"># 使用pod dnsutils执行DNS查找</span><br><span class="line">$ kubectl exec dnsutils nslookup kubia-headless</span><br><span class="line"></span><br><span class="line">########## Endpoint ##########</span><br><span class="line"></span><br><span class="line"># 查看endpoint</span><br><span class="line">$ kubectl get endpoint kubia</span><br><span class="line"></span><br><span class="line">########## Node ##########</span><br><span class="line"></span><br><span class="line"># 使用JSONPath获取所有节点的IP</span><br><span class="line">$ kubectl get nodes -o jsonpath&#x3D;&#39;&#123;.items[*].status.addresses[?(@.type&#x3D;&#x3D;&quot;ExternalIP&quot;)].address&#125;&#39;</span><br><span class="line"></span><br><span class="line">########## Ingress ##########</span><br><span class="line"></span><br><span class="line"># 列出Ingress</span><br><span class="line">$ kubectl get Ingress</span><br><span class="line"></span><br><span class="line"># 更新Ingress资源</span><br><span class="line">$ kubectl apply -f kubia-ingress-tls.yaml</span><br><span class="line"></span><br><span class="line">########## Secret ##########</span><br><span class="line"></span><br><span class="line"># 创建Secret</span><br><span class="line">$ kubectl create secret tls tls-secret --cert&#x3D;tls.cert --key&#x3D;tls.key</span><br></pre></td></tr></table></figure>

<h1 id="6-卷-：将磁盘挂载到容器-161"><a href="#6-卷-：将磁盘挂载到容器-161" class="headerlink" title="6 卷 ：将磁盘挂载到容器 161"></a>6 卷 ：将磁盘挂载到容器 161</h1><p><a href="https://kubernetes.io/docs/concepts/storage/volumes/" target="_blank" rel="noopener">volume的官方文档</a></p>
<p>pod中的每个容器都有自己的独立文件系统，因为文件系统来自容器镜像。<br>k8s通过在pod中定义卷，使得存储持久化，和pod共享生命周期，而不会随着容器的重启消失。</p>
<h2 id="6-1-介绍卷-162"><a href="#6-1-介绍卷-162" class="headerlink" title="6.1 介绍卷 162"></a>6.1 介绍卷 162</h2><h3 id="6-1-1-卷的应用示例-162"><a href="#6-1-1-卷的应用示例-162" class="headerlink" title="6.1.1 卷的应用示例 162"></a>6.1.1 卷的应用示例 162</h3><p>卷被绑定到pod的lifecycle中，只有在pod存在时才会存在，但取决于卷的类型，即使在pod和卷消失之后，卷的文件也可能保待原样，并可以挂载到新的卷中。</p>
<img width="400" src="/images/Kubernetes In Action阅读笔记/20.png">

<h3 id="6-1-2-介绍可用的卷类型-164"><a href="#6-1-2-介绍可用的卷类型-164" class="headerlink" title="6.1.2 介绍可用的卷类型 164"></a>6.1.2 介绍可用的卷类型 164</h3><ul>
<li>emptyDir：用于存储临时数据的简单空目录。</li>
<li>hostPath：用于将目录从工作节点的文件系统挂载到 pod 中。</li>
<li>gitRepo：通过检出 Git 仓库的内容来初始化的卷。</li>
<li>nfs：挂载到 pod 中的 NFS 共享卷。</li>
<li>云磁盘<ul>
<li>gcePersistentDisk</li>
<li>awsElasticBlockStore</li>
<li>azureDisk</li>
</ul>
</li>
<li>网络存储<ul>
<li>cinder</li>
<li>cephfs</li>
<li>iscsi</li>
<li>flocker</li>
<li>glusterfs</li>
<li>…</li>
</ul>
</li>
<li>k8s 内部资源卷<ul>
<li>configMap</li>
<li>secret</li>
<li>downwardAPI</li>
</ul>
</li>
<li>persistentVolumeClaim：动态配置的持久存储</li>
</ul>
<h2 id="6-2-通过卷在容器之间共享数据-165"><a href="#6-2-通过卷在容器之间共享数据-165" class="headerlink" title="6.2 通过卷在容器之间共享数据 165"></a>6.2 通过卷在容器之间共享数据 165</h2><h3 id="6-2-1-使用-emptyDir-卷-165"><a href="#6-2-1-使用-emptyDir-卷-165" class="headerlink" title="6.2.1 使用 emptyDir 卷 165"></a>6.2.1 使用 emptyDir 卷 165</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: fortune</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: luksa&#x2F;fortune</span><br><span class="line">    name: html-generator</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: html # 名为html的卷挂载在html-generator容器的&#x2F;var&#x2F;htdocs中</span><br><span class="line">      mountPath: &#x2F;var&#x2F;htdocs</span><br><span class="line">  - image: nginx:alpine</span><br><span class="line">    name: web-server</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: html # 名为html的卷挂载在web-server容器的&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html中</span><br><span class="line">      mountPath: &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html</span><br><span class="line">      readOnly: true # 设为只读</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">  volumes:</span><br><span class="line">  - name: html # 一个名为html的单独emptyDir卷，挂载在上面的两个容器中</span><br><span class="line">    emptyDir: &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>可以指定用于emptyDir的介质。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">volumes:</span><br><span class="line">  - name: html</span><br><span class="line">    emptyDir:</span><br><span class="line">      medium: Memory # emptyDir的文件将会存储在内存中</span><br></pre></td></tr></table></figure>

<h3 id="6-2-2-使用-Git-仓库作为存储卷-168"><a href="#6-2-2-使用-Git-仓库作为存储卷-168" class="headerlink" title="6.2.2 使用 Git 仓库作为存储卷 168"></a>6.2.2 使用 Git 仓库作为存储卷 168</h3><p>将拉取的git repo作为文件系统，可以方便的读取到git的内容。<br>缺点是，在创建gitRepo卷后，它并不能和对应repo保持同步。<br>可以使用sider容器进行「git sync」。</p>
<p>如果想要将私有的Git repo克隆到容器中，则应该使用gitsync sidecar或类似的方法，而不是使用 gitRepo卷。</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/21.png">

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: gitrepo-volume-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx:alpine</span><br><span class="line">    name: web-server</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: html</span><br><span class="line">      mountPath: &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html</span><br><span class="line">      readOnly: true</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">  volumes:</span><br><span class="line">  - name: html</span><br><span class="line">    gitRepo: # gitRepo卷</span><br><span class="line">      repository: https:&#x2F;&#x2F;github.com&#x2F;luksa&#x2F;kubia-website-example.git</span><br><span class="line">      revision: master</span><br><span class="line">      directory: . # 将repo克隆到卷的根目录</span><br></pre></td></tr></table></figure>

<h2 id="6-3-访问工作节点文件系统上的文件-171"><a href="#6-3-访问工作节点文件系统上的文件-171" class="headerlink" title="6.3 访问工作节点文件系统上的文件 171"></a>6.3 访问工作节点文件系统上的文件 171</h2><h3 id="6-3-1-介绍-hostPath-卷-171"><a href="#6-3-1-介绍-hostPath-卷-171" class="headerlink" title="6.3.1 介绍 hostPath 卷 171"></a>6.3.1 介绍 hostPath 卷 171</h3><p>hostPath卷指向节点文件系统上的特定文件或目录。</p>
<img width="500" src="/images/Kubernetes In Action阅读笔记/22.png">

<h3 id="6-3-2-检查使用-hostPath-卷的系统-pod-172"><a href="#6-3-2-检查使用-hostPath-卷的系统-pod-172" class="headerlink" title="6.3.2 检查使用 hostPath 卷的系统 pod 172"></a>6.3.2 检查使用 hostPath 卷的系统 pod 172</h3><p>仅当需要在节点上读取或写入系统文件时才使用hostPath，不能用来持久化跨pod的数据。</p>
<h2 id="6-4-使用持久化存储-173"><a href="#6-4-使用持久化存储-173" class="headerlink" title="6.4 使用持久化存储 173"></a>6.4 使用持久化存储 173</h2><h3 id="6-4-1-使用-GCE-持久磁盘作为-pod-存储卷-174"><a href="#6-4-1-使用-GCE-持久磁盘作为-pod-存储卷-174" class="headerlink" title="6.4.1 使用 GCE 持久磁盘作为 pod 存储卷 174"></a>6.4.1 使用 GCE 持久磁盘作为 pod 存储卷 174</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: mongodb </span><br><span class="line">spec:</span><br><span class="line">  volumes:</span><br><span class="line">  - name: mongodb-data</span><br><span class="line">    gcePersistentDisk: # 卷类型是GCE持久磁盘</span><br><span class="line">      pdName: mongodb</span><br><span class="line">      fsType: ext4 # 文件系统类型是EXT4</span><br><span class="line">  containers:</span><br><span class="line">  - image: mongo</span><br><span class="line">    name: mongodb</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: mongodb-data</span><br><span class="line">      mountPath: &#x2F;data&#x2F;db # MongoDB数据存放的路径</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 27017</span><br><span class="line">      protocol: TCP</span><br></pre></td></tr></table></figure>

<img width="600" src="/images/Kubernetes In Action阅读笔记/23.png">

<h3 id="6-4-2-通过底层持久化存储使用其他类型的卷-177"><a href="#6-4-2-通过底层持久化存储使用其他类型的卷-177" class="headerlink" title="6.4.2 通过底层持久化存储使用其他类型的卷 177"></a>6.4.2 通过底层持久化存储使用其他类型的卷 177</h3><ul>
<li>使用AWS弹性块存储卷</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">spec:</span><br><span class="line">  volumes:</span><br><span class="line">  - name: mongodb-data</span><br><span class="line">    awsElasticBlockStore:</span><br><span class="line">      volumeID: my-volume</span><br><span class="line">      fsType: ext4</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<ul>
<li>使用NFS卷</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">spec:</span><br><span class="line">  volumes:</span><br><span class="line">  - name: mongodb-data</span><br><span class="line">    nfs:</span><br><span class="line">      server: 1.2.3.4</span><br><span class="line">      path: &#x2F;some&#x2F;path</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h2 id="6-5-从底层存储技术解耦-pod-179"><a href="#6-5-从底层存储技术解耦-pod-179" class="headerlink" title="6.5 从底层存储技术解耦 pod 179"></a>6.5 从底层存储技术解耦 pod 179</h2><p><a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/" target="_blank" rel="noopener">persistent-volume的官方文档</a></p>
<p>将这种涉及基础设施类型的信息塞到一个pod设置中，意味着pod设置与特定的k8s集群有很大耦合度。这就不能在另一个pod中使用相同的设置了。所以使用这样的卷并不是在pod中附加持久化存储的最佳实践。</p>
<p>理想的情况是，在k8s上部署应用程序的开发人员不需要知道底层使用的是哪种存储技术，同理他们也不需要了解应该使用哪些类型的物理服务器来运行pod，与基础设施相关的交互是集群管理员独有的控制领域。</p>
<h3 id="6-5-1-介绍持久卷和持久卷声明-179"><a href="#6-5-1-介绍持久卷和持久卷声明-179" class="headerlink" title="6.5.1 介绍持久卷和持久卷声明 179"></a>6.5.1 介绍持久卷和持久卷声明 179</h3><p>系统管理员首先准备好磁盘资源，然后创建全局的持久卷(Persistent Volume)。</p>
<p>然后用户通过创建持久卷声明(PersistentVolumeClaim，简称PVC)清单，指定所需要的最低容量要求和访问模式，然后用户将持久卷声明清单提交给k8s的API服务器，k8s将找到可匹配的持久卷并将其绑定到持久卷声明。</p>
<p>持久卷声明可以当作pod中的一个卷来使用，其他用户不能使用相同的持久卷，除非先通过删除持久卷声明绑定来释放。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/24.png">

<h3 id="6-5-2-创建持久卷-180"><a href="#6-5-2-创建持久卷-180" class="headerlink" title="6.5.2 创建持久卷 180"></a>6.5.2 创建持久卷 180</h3><p>创建持久卷</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: mongodb-pv</span><br><span class="line">spec:</span><br><span class="line">  capacity: # 定义PersistentVolume的大小</span><br><span class="line">    storage: 1Gi</span><br><span class="line">  accessModes: # 可以被单个客户端挂载为读写模式或被多个客户端挂载为只读模式</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">    - ReadOnlyMany</span><br><span class="line">  persistentVolumeReclaimPolicy: Retain # 当声明被释放后，PersistentVolume将会被保留</span><br><span class="line">  gcePersistentDisk: # PersistentVolume指定支持之前创建的GCE持久磁盘</span><br><span class="line">    pdName: mongodb</span><br><span class="line">    fsType: ext4</span><br></pre></td></tr></table></figure>

<p>在pod卷中引用GCE PD</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  volumes:</span><br><span class="line">  - name: mongodb-data</span><br><span class="line">    gcePersistentDisk:</span><br><span class="line">      pdName: mongodb</span><br><span class="line">      fsType: ext4</span><br></pre></td></tr></table></figure>

<p>在创建持久卷时，管理员需要告诉k8s其对应的容量需求，以及它是否可以由单个节点或多个节点同时读取或写入。管理员还需要告诉k8s如何处理PersistentVolume（当持久卷声明的绑定被删除时）。最后，无疑也很重要的事情是，管理员需要指定持久卷支持的实际存储类型、位置和其他属性。</p>
<p>持久卷不属于任何命名空间，它跟节点一样是集群层面的资源。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/25.png">

<h3 id="6-5-3-通过创建持久卷声明来获取持久卷-182"><a href="#6-5-3-通过创建持久卷声明来获取持久卷-182" class="headerlink" title="6.5.3 通过创建持久卷声明来获取持久卷 182"></a>6.5.3 通过创建持久卷声明来获取持久卷 182</h3><p>创建持久卷声明</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: mongodb-pvc # 声明的名称，将声明当做pod的卷使用时需要用到</span><br><span class="line">spec:</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi # 申请1GiB的存储空间</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce # 允许单个客户端访问(同时支持读取和写入操作)</span><br><span class="line">  storageClassName: &quot;&quot; # 将空字符串指定为存储类名可确保PVC绑定到预先配置的PV，而不是动态配置新的PV</span><br></pre></td></tr></table></figure>

<p>当创建好持久卷声明，k8s就会找到适当的持久卷并将其绑定到声明，持久卷的容量必须足够大以满足声明的需求，并且卷的访问模式必须包含声明中指定的访问模式。</p>
<p>访问模式：</p>
<ul>
<li>PWO： ReadWriteOnce，仅允许单个节点挂载读写；</li>
<li>ROX： ReadOnlyMany，允许多个节点挂载读；</li>
<li>RWX： ReadWriteMany，允许多个节点挂载读写。</li>
</ul>
<blockquote>
<p>accessModes设置的是同时使用卷的工作节点的数量，而非pod的数量。</p>
</blockquote>
<h3 id="6-5-4-在-pod-中使用持久卷声明-184"><a href="#6-5-4-在-pod-中使用持久卷声明-184" class="headerlink" title="6.5.4 在 pod 中使用持久卷声明 184"></a>6.5.4 在 pod 中使用持久卷声明 184</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: mongodb </span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: mongo</span><br><span class="line">    name: mongodb</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: mongodb-data</span><br><span class="line">      mountPath: &#x2F;data&#x2F;db</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 27017</span><br><span class="line">      protocol: TCP</span><br><span class="line">  volumes:</span><br><span class="line">  - name: mongodb-data</span><br><span class="line">    persistentVolumeClaim: # 在pod卷中通过名称引用持久卷声明</span><br><span class="line">      claimName: mongodb-pvc</span><br></pre></td></tr></table></figure>

<h3 id="6-5-5-了解使用持久卷和持久卷声明的好处-185"><a href="#6-5-5-了解使用持久卷和持久卷声明的好处-185" class="headerlink" title="6.5.5 了解使用持久卷和持久卷声明的好处 185"></a>6.5.5 了解使用持久卷和持久卷声明的好处 185</h3><img width="600" src="/images/Kubernetes In Action阅读笔记/26.png">

<h3 id="6-5-6-回收持久卷-186"><a href="#6-5-6-回收持久卷-186" class="headerlink" title="6.5.6 回收持久卷 186"></a>6.5.6 回收持久卷 186</h3><p>通过将persistentVolumeReclaimPolicy设置为Retain从而通知到k8s，希望在创建持久卷后将其持久化，让k8s可以在持久卷从持久卷声明中释放后仍然能保留它的卷和数据内容。手动回收持久卷并使其恢复可用的唯一方法是删除和重新创建持久卷资源。</p>
<p>存在两种其他可行的回收策略：Recycle和Delete。第一种删除卷的内容并使卷可用于再次声明，通过这种方式，持久卷可以被不同的持久卷声明和pod反复使用。</p>
<img width="600" src="/images/Kubernetes In Action阅读笔记/27.png">

<h2 id="6-6-持久卷的动态卷配置-187"><a href="#6-6-持久卷的动态卷配置-187" class="headerlink" title="6.6 持久卷的动态卷配置 187"></a>6.6 持久卷的动态卷配置 187</h2><p><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank" rel="noopener">storage-class的官方文档</a></p>
<h3 id="6-6-1-通过-StorageClass-资源定义可用存储类型-188"><a href="#6-6-1-通过-StorageClass-资源定义可用存储类型-188" class="headerlink" title="6.6.1 通过 StorageClass 资源定义可用存储类型 188"></a>6.6.1 通过 StorageClass 资源定义可用存储类型 188</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: storage.k8s.io&#x2F;v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: fast</span><br><span class="line">provisioner: kubernetes.io&#x2F;gce-pd # 用于配置持久卷的卷插件</span><br><span class="line">parameters:</span><br><span class="line">  type: pd-ssd</span><br><span class="line">  zone: europe-westl-b</span><br></pre></td></tr></table></figure>

<h3 id="6-6-2-请求持久卷声明中的存储类-188"><a href="#6-6-2-请求持久卷声明中的存储类-188" class="headerlink" title="6.6.2 请求持久卷声明中的存储类 188"></a>6.6.2 请求持久卷声明中的存储类 188</h3><p>StorageClass资源指定当久卷声明请求此StorageClass时应使用哪个置备程序来提供持久卷。StorageClass定义中定义的参数将传递给置备程序，并具体到每个供应器插件。</p>
<p>简单地说，管理员可以手动通过置备程序创建PV，或者直接创建对应的StorageClass，然后用户创建PVC时，会自动根据StorageClass的设置调用置备程序创建出可供使用的PV。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: mongodb-pvc </span><br><span class="line">spec:</span><br><span class="line">  storageClassName: fast # 该PVC请求自定义存储类</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 100Mi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br></pre></td></tr></table></figure>

<p>StorageClasses的好处在于，声明是通过名称引用它们的。因此，只要StorageClass名称在所有这些名称中相同，PVC定义便可跨不同集群移植。</p>
<h3 id="6-6-3-不指定存储类的动态配置-190"><a href="#6-6-3-不指定存储类的动态配置-190" class="headerlink" title="6.6.3 不指定存储类的动态配置 190"></a>6.6.3 不指定存储类的动态配置 190</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: mongodb-pvc2 </span><br><span class="line">spec:</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 100Mi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br></pre></td></tr></table></figure>

<img width="700" src="/images/Kubernetes In Action阅读笔记/28.png">

<h2 id="6-7-本章的k8s命令-193"><a href="#6-7-本章的k8s命令-193" class="headerlink" title="6.7 本章的k8s命令 193"></a>6.7 本章的k8s命令 193</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">########## PersistentVolume ##########  </span><br><span class="line"></span><br><span class="line"># 列出所有的PersistentVolume</span><br><span class="line">$ kubectl get pv</span><br><span class="line"></span><br><span class="line">########## PersistentVolumeClaim ##########  </span><br><span class="line"></span><br><span class="line"># 列出所有的PersistentVolumeClaim</span><br><span class="line">$ kubectl get pvc</span><br><span class="line"></span><br><span class="line">########## StorageClass ##########  </span><br><span class="line"></span><br><span class="line"># 列出所有的StorageClass</span><br><span class="line">$ kubectl get sc</span><br><span class="line"></span><br><span class="line"># 查看默认存储类</span><br><span class="line">$ kubectl get sc standard -o yaml</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://pearlzju.github.io/2021/06/12/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%20IO%E6%A8%A1%E5%9E%8B(%E4%B8%80)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pearl">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/face.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pearl 的个人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/12/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%20IO%E6%A8%A1%E5%9E%8B(%E4%B8%80)/" itemprop="url">深入理解Linux IO模型(一)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-06-12T10:43:55+08:00">
                2021-06-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" itemprop="url" rel="index">
                    <span itemprop="name">计算机</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/06/12/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%20IO%E6%A8%A1%E5%9E%8B(%E4%B8%80)/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2021/06/12/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%20IO%E6%A8%A1%E5%9E%8B(%E4%B8%80)/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2021/06/12/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%20IO%E6%A8%A1%E5%9E%8B(%E4%B8%80)/" class="leancloud_visitors" data-flag-title="深入理解Linux IO模型(一)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<p>Linux IO模型是后端工程师的必备技能。从以往的面试中看，部分后端开发人员对它的理解停留在调API的层面，我自己也理解欠缺。最近系统学习了一下，整理了此文。本文参考了一些文章，放在本文最后，大家可以直接去看这些文章，值得阅读。</p>
<blockquote>
<ol>
<li>本文为了描述方便，统一用读操作讲述，写操作同理。</li>
<li>本文为了撰写方便，统一将I/O写成了IO。</li>
<li>欢迎指正文中的错误。</li>
</ol>
</blockquote>
<h3 id="操作系统预备知识"><a href="#操作系统预备知识" class="headerlink" title="操作系统预备知识"></a>操作系统预备知识</h3><h4 id="UNIX体系结构"><a href="#UNIX体系结构" class="headerlink" title="UNIX体系结构"></a>UNIX体系结构</h4><p>UNIX操作系统的体系结构如图所示。</p>
<img width="250" src="/images/深入理解Linux IO模型/1.png">

<p>内核(kernel)：控制计算机硬件资源，提供程序运行环境。<br>系统调用(system call)：内核的函数接口。<br>公共函数库：构建在系统调用之上的函数接口。<br>shell：特殊的应用程序，为运行其他应用程序提供了一个接口。<br>应用程序：用户编写的程序。可使用公共函数库，也可直接调用系统调用。</p>
<h4 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h4><p>进一步介绍下系统调用(syscall)。<br>内核用于控制硬件资源，例如从磁盘上读写文件，需要控制硬盘这个硬件设备做IO操作。应用代码通过调用内核暴露出来的系统调用接口来使内核进行IO操作。<br>如图所示，库函数调用系统调用接口，应用程序可以调用系统调用和库函数。</p>
<img width="250" src="/images/深入理解Linux IO模型/2.png">

<p>例如用户常用的<code>printf</code>函数，可以调用它输出内容到显示器上，但是控制显示器的输出是内核。系统调用提供的是<code>write</code>函数，<code>printf</code>是库函数，它封装了<code>write</code> 这个系统调用接口。</p>
<h4 id="用户空间和内核空间"><a href="#用户空间和内核空间" class="headerlink" title="用户空间和内核空间"></a>用户空间和内核空间</h4><p>对于32位CPU（表示CPU的寄存器长度为32位），指令集长度32位，数据总线宽度32位，地址总线宽度32位（因为受到寄存器长度的限制，再大也是浪费，无法把指令或数据从内存装载到寄存器或把寄存器的值写入内存）。因为地址总线宽度32位，所以最大寻址范围2^32，即对应 2^32*8bit=4GB 内存寻址空间。虽然内存的最大寻址容量只有4GB，但是每个进程的虚拟存储空间却都为4GB。</p>
<blockquote>
<p>虚拟存储空间是什么？</p>
<ol>
<li>MMU(内存管理单元)通过段页式存储管理，负责物理地址和逻辑地址(虚拟地址)的转化。逻辑空间可以理解为内存空间和磁盘空间之间的抽象，为了解决容量问题。</li>
<li>程序的局部性原理。CPU访问内存时，无论是存取指令还是数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。程序运行时，无需全部装入内存，如果访问页不在内存，发出缺页中断，发起页面置换（页面置换有常用的几种算法，FIFO、LFU、LRU）。</li>
</ol>
</blockquote>
<blockquote>
<p>操作系统怎么划分的虚拟存储空间？</p>
<ol>
<li>程序在磁盘中，加载进内存后，才能变成进程运行起来。内存的第一个进程是kernel。</li>
<li>kernel会注册一个GDT(Global Descriptor Table)，把4GB虚拟内存划分成用户空间和内核空间。最高的1GB，从虚拟地址 0xC0000000 到 0xFFFFFFFF），供内核使用，作为内核空间；较低的3GB，从虚拟地址0x00000000到0xBFFFFFFF），供各个应用进程使用，作为用户空间。</li>
</ol>
</blockquote>
<p>内核独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证内核的安全，用户进程不能直接操作内核。操作系统将4GB的虚拟存储空间划分为两部分，用户空间和内核空间。</p>
<blockquote>
<p>CPU如何区分指令来自内核空间还是用户空间的？<br>指令存储在内存中，通过数据总线加载到CPU的指令寄存器，CPU解码执行。实际上CPU本身并不能区分是谁发出的指令，而是通过特权等级来区分。以X86架构来说，CPU指令集的特权等级分为Ring0~3，内核空间对应指令集Ring0，具有最高权限，可以访问所有资源；用户空间对应指令集Ring3，不能直接访问硬件设备。</p>
</blockquote>
<blockquote>
<p>如果用户空间存在特权指令，CPU如何区分这个指令来自用户进程从而禁止执行？<br>CPU有两种执行模式，用户模式和内核模式。用户模式受到限制，某些指令不能被执行，某些寄存器不能被访问，IO设备也不能被访问。内核模式则没有这些限制，可以执行所有的机器指令，可以读写所有的内存位置。<br>这个问题我理解可能不到位，抛砖引玉。</p>
</blockquote>
<h4 id="用户态和内核态"><a href="#用户态和内核态" class="headerlink" title="用户态和内核态"></a>用户态和内核态</h4><p>进程运行时会有用户态和内核态的区别。<br>如图所示，程序执行时，如果执行的是用户空间的应用代码，这些代码运行在用户态；当调用了系统调用后，内核空间的内核代码就会执行，内核中的这些代码运行在内核态。</p>
<img width="250" src="/images/深入理解Linux IO模型/3.png">

<h4 id="进程阻塞"><a href="#进程阻塞" class="headerlink" title="进程阻塞"></a>进程阻塞</h4><p>进程有五个状态，创建、就绪、执行、阻塞和终止。<br>就绪状态：当进程被分配到除CPU以外所有必要的资源（包括PCB、栈空间、堆空间等）后。只要获得CPU的使用权，就可以立即执行。<br>执行状态：进程获得CPU，在执行的状态。单CPU同一时刻只能有一个进程在执行状态。<br>阻塞状态：因为某种原因如IO未就绪，进程放弃CPU的使用权，进入阻塞状态。</p>
<p>进程模型之间的切换关系如图所示。</p>
<img width="500" src="/images/深入理解Linux IO模型/4.png">

<p>进程切换(进程调度)是指操作系统通过某种进程调度算法决定哪个就绪进程可以获得CPU的使用权。进一步说，内核以一定策略挂起当前正在利用CPU运行的进程，并保存进程的上下文运行信息，然后分配CPU给某个就绪状态的另一个进程执行。</p>
<p>可以看出，进程阻塞是进程的主动行为，只有处于获得CPU在执行状态的进程，才可能转变成阻塞状态。当进程进入阻塞状态，不占用CPU资源。所以，在执行IO请求后进入阻塞状态的进程，是不占用CPU资源的。</p>
<blockquote>
<p>PCB(进程控制块)指的是什么？<br>PCB是进程常驻在内存中的通用数据结构，记录进程运行的全部信息，被用于操作系统调用时读取。记录包括进程的标识符、状态、优先级、程序计数器、内存指针、CPU的上下文数据、被进程占用的IO的状态信息、记账信息等。</p>
</blockquote>
<h4 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h4><p>理解中断，对理解IO模型很重要。</p>
<h5 id="任务事件"><a href="#任务事件" class="headerlink" title="任务事件"></a>任务事件</h5><p>操作系统是事件驱动的，只有在有中断、陷阱或系统调用时才执行。如图所示。</p>
<img width="500" src="/images/深入理解Linux IO模型/9.png">

<blockquote>
<p>为什么操作系统要采用事件驱动设计呢？</p>
<ol>
<li>操作系统不能信任用户进程</li>
</ol>
<ul>
<li>用户进程可能是错误的或恶意的</li>
<li>用户进程崩溃不应影响操作系统</li>
</ul>
<ol start="2">
<li>操作系统需要保证对所有用户进程公平性</li>
</ol>
<ul>
<li>一个进程不能霸占CPU时间</li>
<li>采用定时中断的方式</li>
</ul>
</blockquote>
<p>事件触发简化流程如图所示。</p>
<img width="400" src="/images/深入理解Linux IO模型/10.png">

<p>事件有中断和异常两类。中断由硬件或者程序触发，以引起操作系统的注意。异常由于非法操作而导致的。本文不讲异常，只讲中断。<br>中断又有硬件中断和软件中断之分：硬件中断由外部硬件设备触发；软件中断由应用进程触发。</p>
<p>每个中断都有一个编号，称为中断向量(interrupt vector)，用于在中断描述符表IDT(也称为中断向量表)中进行索引，从而获得中断服务程序的指针，即中断处理程序的入口点。</p>
<blockquote>
<p>为什么「中断向量」不叫「中断指针」？我猜可能是历史原因，知道的读者可以留言告诉我。</p>
</blockquote>
<h5 id="硬件中断"><a href="#硬件中断" class="headerlink" title="硬件中断"></a>硬件中断</h5><p>与CPU相连接的外部设备，如键盘、鼠标、网卡等，偶尔需要CPU提供服务，但是CPU无法预测它们何时发生。<br>如果在数据采集系统中，可以采用CPU定期轮询设备的方式，以确定它们是否需要提供服务。否则，轮询会浪费CPU资源。<br>所以引入了硬件中断的方式，每个连接的外部设备都可以向CPU发出信号，表示它们需要CPU提供服务。一般来说，CPU有2个引脚，INT用于中断，NMI用于不可屏蔽的关键的信号。</p>
<p>如图所示，是8259可编程中断控制器。可支持转发8个中断。当设备通过中断请求(IRQ)引发中断，CPU确认并查询8259以确定哪个设备产生中断。8259可以为每个IRQ线分配优先权，可以级联以支持更多的中断。</p>
<img width="300" src="/images/深入理解Linux IO模型/11.png">

<p>当硬件中断发生的时候，发生了什么？流程如图所示。</p>
<img width="500" src="/images/深入理解Linux IO模型/12.png">

<img width="500" src="/images/深入理解Linux IO模型/13.png">

<p>第1步，CPU完成当前指令后，立即响应硬件中断，先获取到中断向量。<br>第2步，切换到内核堆栈不是必须的，因为只有从用户模式转到内核模式，才需要进行堆栈切换。有可能中断来临时，CPU正在内核模式执行内核的指令。<br>第3步，保存程序状态，是为了保证当前正常执行的程序在中断服务完成后能恢复。<br>第4步到第7步，是中断处理程序执行流程。</p>
<blockquote>
<p>典型的中断处理程序过程是:</p>
<ol>
<li>保存CPU上下文</li>
<li>处理中断(如与IO设备通信)</li>
<li>调用内核调度程序</li>
<li>恢复CPU上下文并返回</li>
</ol>
</blockquote>
<p>如图所示，中断处理是有延时的，最小值受限于中断控制器，它的最大值受到操作系统的限制，如当内核和中断处理程序需要操作同一个全局变量，需要保证内核执行的是原子操作，中断处理程序需要等待原子操作完成，才能得到处理。</p>
<img width="500" src="/images/深入理解Linux IO模型/14.png">

<h5 id="软件中断"><a href="#软件中断" class="headerlink" title="软件中断"></a>软件中断</h5><p>下面讲软件中断，它是为何产生？<br>为了让CPU能尽快响应其它硬件中断，中断处理程序需要小型化，可以只是设置flag或放入工作队列，让非关键性的代码推迟执行。于是提出了Top and Bottom Half Technique。<br>Top half：做最小的工作并从中断处理程序中返回。如保存寄存器、取消对其他中断的屏蔽、恢复寄存器并返回到以前的上下文。<br>Bottom half ：对Top half剩下的工作延迟处理。</p>
<p>硬件中断和软件中断的直观对比如图所示。硬件中断由一个设备（如PIC）向CPU的一个引脚发出信号产生；软件中断由正在执行的某条指令产生。</p>
<img width="400" src="/images/深入理解Linux IO模型/15.png">

<p>软件中断通过请求系统调用产生，如图所示。</p>
<img width="200" src="/images/深入理解Linux IO模型/16.png">

<p>一个write system call的例子，如图所示。</p>
<img width="250" src="/images/深入理解Linux IO模型/17.png">

<p>软件中断产生、处理和返回的流程，如图所示。</p>
<img width="500" src="/images/深入理解Linux IO模型/18.png">

<p>操作系统是如何区分系统调用的？答案是利用 System call number。直观上看，如图所示。</p>
<img width="400" src="/images/深入理解Linux IO模型/19.png">

<h3 id="数据包的接收过程"><a href="#数据包的接收过程" class="headerlink" title="数据包的接收过程"></a>数据包的接收过程</h3><h4 id="网卡-gt-内存"><a href="#网卡-gt-内存" class="headerlink" title="网卡-&gt;内存"></a>网卡-&gt;内存</h4><p>数据包如何进入内存，并被内核的网络模块开始处理的？流程如图所示。</p>
<img width="400" src="/images/深入理解Linux IO模型/20.png">

<ol>
<li>数据包进入网卡（如果目的地址不是该网卡，且该网卡没有开启混杂模式，该包会被网卡丢弃）。</li>
<li>网卡将数据包通过DMA方式写入指定的内存地址（该地址由网卡驱动分配并初始化）。</li>
<li>网卡raise硬件中断IRQ，通知CPU，告诉有数据包到来。</li>
<li>CPU查询中断向量表，得到中断服务程序的指针，这个中断服务程序会调用网卡驱动程序中的相应函数。</li>
<li>网卡驱动先禁用网卡的硬件中断，表示驱动程序已经知道内存中有网络数据，如果网卡下次再接收到数据包，直接DMA方式写内存就可以，不需要raise硬件中断通知CPU（这样避免CPU不停地被中断）。</li>
<li>网卡驱动程序raise软件中断，内核启动软件中断服务。目的是将硬件中断服务程序中耗时久的部分放到软中断函数慢慢处理。</li>
</ol>
<h4 id="内存-gt-内核网络模块-gt-内核网络协议栈"><a href="#内存-gt-内核网络模块-gt-内核网络协议栈" class="headerlink" title="内存-&gt;内核网络模块-&gt;内核网络协议栈"></a>内存-&gt;内核网络模块-&gt;内核网络协议栈</h4><p>内核在软件中断服务中接收链路层帧，并逐层递交上层协议栈处理，处理流程如下。</p>
<ol>
<li>内核中有专门的进程负责接收网卡驱动raise的软中断，然后该进程调用对应的软中断处理函数，读取之前网卡写到内存中的数据包。</li>
<li>网卡驱动程序知道如何处理内存中的数据包格式，它将数据包转换成内核网络模块能识别的格式。</li>
<li>内核网络模块将数据包合并(这样可以减小调用协议栈的次数)，并将数据包放入CPU对应的接收队列(softnet_data.input_pkt_queue)中等待处理。</li>
<li>CPU在软中断上下文中处理队列中的网络数据。</li>
<li>调用协议栈相应的函数，把数据包交给协议栈处理。</li>
<li>协议栈的处理过程（IP层-&gt;TCP/UDP层）不展开描述了。</li>
<li>用户空间的应用层通过调用socket接口接收数据。比如调用recvfrom函数阻塞等待数据到来，当socket fd收到通知后，recvfrom函数被唤醒，然后读取数据；或通过select/epoll等IO多路复用方式监听多个socket fd，只要其中有fd收到通知，进程主动调用recvfrom函数去读取数据。本文后面会展开描述。</li>
</ol>
<blockquote>
<p>CPU的接收队列input_pkt_queue是什么？<br>网络设备模块在初始化时，为每个CPU初始化结构体softnet_data，用于处理网络数据。input_pkt_queue是该结构体的一个成员变量，作为接收队列，在对其操作的时候，关闭当前CPU的中断。<br>如果接收队列input_pkt_queue不为空，将接收队列拼接到处理队列process_queue上。接收队列input_pkt_queue清空，继续处理添加到处理队列process_queue的数据包，并且在处理前就打开当前的CPU中断。</p>
</blockquote>
<h3 id="关于IO的认知"><a href="#关于IO的认知" class="headerlink" title="关于IO的认知"></a>关于IO的认知</h3><h4 id="IO是什么"><a href="#IO是什么" class="headerlink" title="IO是什么"></a>IO是什么</h4><p>IO是指Input/Output，即输入和输出。<br>IO从广义上说，是数据流动的过程。<br>IO有内存IO、网络IO和磁盘IO等。</p>
<p>从计算机架构上讲，CPU和内存与其他外部设备之间的数据转移过程就是IO。<br>本文从用户进程的角度理解IO。用户进程要完成IO读写，需要对内核发起IO调用，内核执行IO任务，返回IO结果，即完成一次IO。内核为每个IO设备维护一个内核缓冲区。</p>
<h4 id="不带缓冲的IO和带缓冲的IO"><a href="#不带缓冲的IO和带缓冲的IO" class="headerlink" title="不带缓冲的IO和带缓冲的IO"></a>不带缓冲的IO和带缓冲的IO</h4><p>IO分为不带缓冲的IO和带缓冲的IO（标准IO）。</p>
<p>不带缓冲的IO：读和写都调用内核中的系统调用read和write，写入内核缓冲区。</p>
<p>带缓冲的IO：目的是减少调用系统调用read和write的次数。方法是在用户空间建立流缓冲区。例如用户多次调用fwrite将数据写入流缓冲区，等流缓冲区满的时候只调用一次系统调用write，写入内核缓冲区。标准IO库实现的就是对IO流的缓存管理。</p>
<p>需要注意，不管是哪种IO，内存和磁盘之间，总是会有内核缓冲区的，这是IO设备的缓冲区。</p>
<p>总结一下数据流向路径:<br>不带缓冲的IO: 数据—内核缓存区—磁盘<br>带缓冲的IO: 数据—流缓存区—内核缓存区—磁盘</p>
<p>不管是哪种IO，因为用户进程是运行在用户空间的，不能直接操作内核缓冲区的数据。所以数据在传输过程中，总是需要从内核缓冲区复制到用户进程空间（对于带缓冲的IO，就是需要在内核缓冲区到用户缓冲区之间复制）。这个复制的过程对CPU和内存的开销是比较大的。</p>
<h4 id="文件描述符"><a href="#文件描述符" class="headerlink" title="文件描述符"></a>文件描述符</h4><p>文件描述符(fd)在形式上是一个非负整数。<br>内核用以标记一个特定进程正在访问的文件。<br>当内核打开一个现有的文件或创建一个新的文件时，内核返回一个文件描述符，用于后续的IO操作。</p>
<h4 id="流"><a href="#流" class="headerlink" title="流"></a>流</h4><p>流是可以进行读写操作的内核对象。<br>比如文件、管道、套接字。<br>Linux一切皆文件，一切都是流。用户进程都是对这些流进行读写操作，实现数据交换。<br>用户进程用文件描述符fd实现对流的操作。<br>准确地说，流是带缓冲的IO（标准IO）才有的概念。<br>流有方向。对流的读写操作，可以理解为IO操作。如图所示。</p>
<img width="250" src="/images/深入理解Linux IO模型/6.png">

<p>如果流中没有数据，读取，就阻塞。进一步说，是用户缓冲区没有数据，无法读取数据。</p>
<img width="250" src="/images/深入理解Linux IO模型/7.png">

<p>如果流中数据已满，写入，就阻塞。进一步说，是用户缓冲区数据已满，无法写入数据。</p>
<img width="250" src="/images/深入理解Linux IO模型/8.png">

<h4 id="IO操作"><a href="#IO操作" class="headerlink" title="IO操作"></a>IO操作</h4><p>对于用户进程的一个读IO操作，包括以下阶段：<br>1.用户进程调用IO系统调用读数据。<br>2.内核先看下内核缓冲区是否有数据，如果没有数据，则从设备读取，先加载到内核缓冲区，再复制到用户进程缓冲区；如果有数据，直接复制到用户进程缓冲区（对于标准IO）。</p>
<p>直观的流程如图所示。</p>
<img width="500" src="/images/深入理解Linux IO模型/5.png">

<p>具体地说，对于一个网络IO输入操作，如果内核缓冲区无数据，包括以下阶段：</p>
<ol>
<li>用户进程调用Socket API</li>
<li>等待网络数据到达网卡这个硬件设备</li>
<li>通过DMA，直接从网卡读取到内核缓冲区</li>
<li>内核把内核缓冲区的数据复制到用户空间</li>
</ol>
<p>总结一下，一次完整的网络IO输入操作，是应用进程进行系统调用，内核从网卡读取数据写入内存，接着内核把数据从内存中复制到到用户空间的过程。<br>这个过程，有很多种IO模型可以处理，就引发了下文要讲的同步IO（包括阻塞IO、非阻塞IO、IO多路复用）和异步IO模型。</p>
<h4 id="IO就绪"><a href="#IO就绪" class="headerlink" title="IO就绪"></a>IO就绪</h4><p>我们常说的fd就绪，也就是IO就绪，是IO可读或可写了，即应用程序调用的内核系统调用返回结果了，可以从内核缓冲区读取数据或者写入数据到内核缓冲区。</p>
<h3 id="同步IO和异步IO"><a href="#同步IO和异步IO" class="headerlink" title="同步IO和异步IO"></a>同步IO和异步IO</h3><p>IO模型从大类上分，分为同步IO和异步IO。</p>
<h4 id="同步IO-synchronous-IO"><a href="#同步IO-synchronous-IO" class="headerlink" title="同步IO(synchronous IO)"></a>同步IO(synchronous IO)</h4><p>应用程序通过系统调用发送IO请求给内核后，必须等待IO返回后才继续执行后续代码。<br>同步IO有以下几种模型。</p>
<h5 id="阻塞式IO-blocking-IO"><a href="#阻塞式IO-blocking-IO" class="headerlink" title="阻塞式IO(blocking IO)"></a>阻塞式IO(blocking IO)</h5><img width="400" src="/images/深入理解Linux IO模型/21.png">

<ol>
<li>应用进程调用系统调用recvfrom，应用进程进入阻塞状态。</li>
<li>内核准备好数据，写入内核缓冲区。</li>
<li>内核将数据从内核缓冲区复制到用户空间。</li>
<li>应用进程被唤醒，进入执行状态，处理拿到的数据。</li>
</ol>
<blockquote>
<p>R1和R2阶段的应用进程都是阻塞的。</p>
</blockquote>
<h5 id="非阻塞式IO-nonblocking-IO"><a href="#非阻塞式IO-nonblocking-IO" class="headerlink" title="非阻塞式IO(nonblocking IO)"></a>非阻塞式IO(nonblocking IO)</h5><img width="400" src="/images/深入理解Linux IO模型/22.png">

<ol>
<li>应用进程轮询调用系统调用recvfrom（非阻塞方式），如果内核未准备好数据，返回错误EWOULDBLOCK。</li>
<li>内核准备好数据，写入内核缓冲区。</li>
<li>这次应用进程调用系统调用recvfrom，内核会返回非错误码数据，并将数据从内核缓冲区复制到用户空间。</li>
<li>应用进程被唤醒，进入执行状态，处理拿到的数据。</li>
</ol>
<blockquote>
<p>R1阶段的应用进程是非阻塞的，R2阶段的应用进程是阻塞的。</p>
</blockquote>
<h5 id="IO多路复用-IO-multiplexing"><a href="#IO多路复用-IO-multiplexing" class="headerlink" title="IO多路复用(IO multiplexing)"></a>IO多路复用(IO multiplexing)</h5><img width="400" src="/images/深入理解Linux IO模型/23.png">

<ol>
<li>应用进程调用系统调用select（这里以select为例，还有poll、epoll等IO多路复用器），进程进入阻塞状态。（这里的阻塞不同于阻塞式IO只等待一个socket fd，而是同时等待多个socket fd）</li>
<li>内核将可读的socket fd数据准备好，写入内核缓冲区。</li>
<li>应用进程收到select的返回结果，知道存在任意数量可读的socket fd。对于这些socket fd，应用进程遍历socket fd（select和poll是遍历所有fd，epoll是只遍历可读的fd），分别调用系统调用recvfrom，内核将数据从内核缓冲区复制到用户空间。</li>
<li>应用进程被唤醒，进入执行状态，处理拿到的数据（多个socket fd的返回结果）。</li>
</ol>
<blockquote>
<p>R1和R2阶段的应用进程都是阻塞的。</p>
</blockquote>
<h5 id="信号驱动IO-signal-driven-IO"><a href="#信号驱动IO-signal-driven-IO" class="headerlink" title="信号驱动IO(signal-driven IO)"></a>信号驱动IO(signal-driven IO)</h5><img width="400" src="/images/深入理解Linux IO模型/24.png">

<ol start="0">
<li>应用进程内建立信号捕获函数，和socket fd关联。</li>
<li>应用进程调用系统调用sigaction，收到调用返回后，接着应用进程去执行其它代码。</li>
<li>当内核准备好数据，发送SIGIO信号给应用进程。</li>
<li>应用进程回调信号捕获函数，调用系统调用recvfrom。</li>
<li>应用进程被唤醒，进入执行状态，处理拿到的数据。</li>
</ol>
<blockquote>
<p>R1阶段的应用进程是非阻塞的，R2阶段的应用进程是阻塞的。</p>
</blockquote>
<h4 id="异步IO-asynchronous-IO"><a href="#异步IO-asynchronous-IO" class="headerlink" title="异步IO(asynchronous IO)"></a>异步IO(asynchronous IO)</h4><p>相对于同步IO，异步IO在用户进程调用系统调用aio_read以后，无论内核缓冲区数据是否准备好，都立即返回，不会阻塞当前进程，转而处理其它代码。</p>
<img width="400" src="/images/深入理解Linux IO模型/25.png">

<ol>
<li>应用进程调用系统调用aio_read，收到调用返回后，接着应用进程去执行其它代码。</li>
<li>内核准备好数据，并且将数据从内核缓冲区复制到用户空间。</li>
<li>内核发送aio_read中指定的信号给应用进程。</li>
<li>应用进程转而处理拿到的数据。</li>
</ol>
<blockquote>
<p>R1和R2阶段的应用进程都是非阻塞的。</p>
</blockquote>
<h3 id="为什么提出IO多路复用"><a href="#为什么提出IO多路复用" class="headerlink" title="为什么提出IO多路复用"></a>为什么提出IO多路复用</h3><p>以上在同步IO模型中已经介绍了IO多路复用。IO多路复用也是目前主流软件，如nginx、redis、kafka等使用的模型。它可以让一个线程在同一时刻监听多个socket fd。<br>技术的发展都是有迹可循，为了解决某种问题提出，那么IO多路复用是怎么产生的？</p>
<p>先介绍下阻塞等待和非阻塞忙轮询两种模型，分别对应上面同步IO中的阻塞式IO和非阻塞式IO。</p>
<h4 id="阻塞等待"><a href="#阻塞等待" class="headerlink" title="阻塞等待"></a>阻塞等待</h4><p>阻塞等待指的是被动地等待IO状态到来，即阻塞等待IO可读或可写。<br>阻塞等待的时候，CPU是空闲的，即不占用CPU的时间片（在上文已经说明原因）。<br>虽然不占用CPU时间片，但无法处理其它IO状态的到来（因为进程在阻塞状态等待IO可操作，无法进入就绪状态），即单个CPU无法并发处理多个IO请求。</p>
<p>优点：处理接收数据的时候，不浪费性能资源。<br>缺点：同一时刻，只能处理一个流的阻塞监听，即单个CPU不能并发处理多个IO请求。</p>
<p>虽然可以用阻塞+多线程/多进程的模型，实现多个CPU可以同一时刻监听多个IO状态。<br>但是开辟线程/进程浪费内存资源，而且切换线程/进程也浪费CPU。</p>
<h4 id="非阻塞忙轮询"><a href="#非阻塞忙轮询" class="headerlink" title="非阻塞忙轮询"></a>非阻塞忙轮询</h4><p>非阻塞忙轮询指的是主动地轮询IO状态，判断可读或可写。<br>非阻塞忙轮询判断IO状态的时候，CPU是忙碌的，即CPU时间片被占用。<br>注意：所以非阻塞忙轮询和异步是两个概念。</p>
<p>缺点：浪费CPU。</p>
<p>伪代码如下。CPU 大部分时间在做 while 和 for 判断处理，CPU 的利用率不高。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">true</span> &#123;</span><br><span class="line">  <span class="keyword">for</span> i in 流[] &#123;</span><br><span class="line">    <span class="keyword">if</span> i has 数据 &#123;</span><br><span class="line">      读 或者 其他处理</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="IO多路复用解决的问题"><a href="#IO多路复用解决的问题" class="headerlink" title="IO多路复用解决的问题"></a>IO多路复用解决的问题</h4><p>最基础的网络编程伪代码如下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">创建socketint s &#x3D; socket(AF_INET, SOCK_STREAM, 0); &#x2F;&#x2F; 得到socket fd</span><br><span class="line">绑定bind(s, ...)</span><br><span class="line">监听listen(s, ...)</span><br><span class="line">接受客户端连接int c &#x3D; accept(s, ...)</span><br><span class="line">接收客户端数据recv(c, ...);</span><br><span class="line">将数据打印出来printf(...)</span><br></pre></td></tr></table></figure>

<p>先创建socket fd，依次调用bind、listen、accept，最后调用recv接收数据。recv是个阻塞方法，当程序运行到recv时，进程进入阻塞状态（不占用CPU资源），直到接收到数据，进程转到执行状态处理数据。进程阻塞在accept和recv。</p>
<p>但是有没有一种方式，既有阻塞等待不浪费CPU资源的优点，也能避免阻塞等待同一时刻只能处理一个流的问题，而是可以在同一时刻监听多个socket fd？即同时accept和recv多个socket fd。答案就是IO多路复用。</p>
<p>所以产生了select、poll、epoll等IO多路复用技术，目的是解决单线程同一时刻处理大量IO读写请求，并且不浪费CPU。</p>
<h4 id="什么是-IO-多路复用"><a href="#什么是-IO-多路复用" class="headerlink" title="什么是 IO 多路复用"></a>什么是 IO 多路复用</h4><p>阻塞等待只能同一时刻只能监听一个IO状态。<br>为了解决大量 IO 请求读写的问题，提出了 IO 多路复用。<br>如果同一流程想同一时刻监听多个IO状态。要么非阻塞忙轮询；要么用 select/epoll等IO多路复用器，告诉用户态有哪些 IO 可读可写，一起处理。即 IO 多路复用可以实现单线程在同一时刻可以监听多个IO状态。IO多路复用在非忙轮询状态，不浪费CPU。</p>
<h4 id="select-简介"><a href="#select-简介" class="headerlink" title="select 简介"></a>select 简介</h4><p>先上伪代码。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">true</span> &#123;</span><br><span class="line">  select(流[]); <span class="comment">// 阻塞。CPU 可以去做其他事。如果有流可读了，返回。</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 有消息抵达</span></span><br><span class="line">  <span class="keyword">for</span> i in 流 [] &#123; <span class="comment">// 需要依次判断所有的流哪个可读</span></span><br><span class="line">    <span class="keyword">if</span> i has 数据 &#123; <span class="comment">// 如果可读的流数量少，浪费性能</span></span><br><span class="line">        读 或者 其他处理</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>进一步的代码。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> s = socket(AF_INET, SOCK_STREAM, <span class="number">0</span>); </span><br><span class="line">bind(s, ...);</span><br><span class="line">listen(s, ...)</span><br><span class="line"><span class="keyword">int</span> fds[] = 存放需要监听的socket</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">  <span class="keyword">int</span> n = select(..., fds, ...)</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; fds.count; i++)&#123;</span><br><span class="line">    <span class="keyword">if</span>(FD_ISSET(fds[i], ...))&#123;</span><br><span class="line">      <span class="comment">// fds[i]的数据处理</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>select的流程是：</p>
<ol>
<li>应用进程调用系统调用select(fds)。</li>
<li>select阻塞直到有任意数量fd可读。</li>
<li>应用进程遍历fds，通过FD_ISSET判断哪些socket fd可读。</li>
<li>应用进程处理返回的数据。</li>
</ol>
<p>select的缺点是：</p>
<ol>
<li>应用进程每次select系统调用都需要应用空间复制整个fds列表到内核空间。</li>
<li>内核需要主动遍历n次，才能返回哪些fd可读可写，CPU浪费在了内核空间。</li>
<li>规定select的最多同时监听1024个socket fd。</li>
<li>应用进程被唤醒后，不知道那些socket fd可读，需要遍历所有fd。</li>
</ol>
<h4 id="epoll-简介"><a href="#epoll-简介" class="headerlink" title="epoll 简介"></a>epoll 简介</h4><p>先上伪代码。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">true</span> &#123;</span><br><span class="line">  可处理的流[] = epoll_wait(epoll_fd); <span class="comment">// 阻塞</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 有消息抵达</span></span><br><span class="line">  <span class="keyword">for</span> i in 可处理的流[] &#123;</span><br><span class="line">    读 或者 其他处理</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>进一步的代码。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> s = socket(AF_INET, SOCK_STREAM, <span class="number">0</span>);</span><br><span class="line">bind(s, ...);</span><br><span class="line">listen(s, ...)</span><br><span class="line"><span class="keyword">int</span> epfd = epoll_create(...);</span><br><span class="line">epoll_ctl(epfd, ...); <span class="comment">// 将所有需要监听的socket添加到epfd中</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">  <span class="keyword">int</span> n = epoll_wait(...)</span><br><span class="line">  <span class="keyword">for</span>(接收到数据的socket fds)&#123;</span><br><span class="line">    <span class="comment">// fds[i]的数据处理</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>epoll的流程是：</p>
<ol>
<li>应用进程调用系统调用epoll_create，创建eventpoll对象，用于维护等待列表和就绪列表。</li>
<li>应用进程调用系统调用epoll_ctl，添加要监听的fd。</li>
<li>应用进程调用系统调用epoll_wait。</li>
<li>epoll_wait阻塞直到有任意数量fd可读。</li>
<li>应用进程遍历就绪列表，得到数据。</li>
<li>应用进程处理返回的数据。</li>
</ol>
<p>epoll的优点是：</p>
<ol>
<li>可以同时监听大量的socket fd。能够处理大量的链接请求(系统可以打开的文件数目) 。</li>
<li>应用进程被唤醒后，只需要遍历可读的fd。</li>
</ol>
<blockquote>
<p><code>cat /proc/sys/fs/file-max</code> 得到当前操作系统可以打开的最大文件描述符个数。</p>
</blockquote>
<h3 id="epoll详解"><a href="#epoll详解" class="headerlink" title="epoll详解"></a>epoll详解</h3><p>关于epoll更多细节，在《深入理解Linux IO模型(二)》讲述。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>UNIX环境高级编程（第3版）<a href="https://book.douban.com/subject/25900403/" target="_blank" rel="noopener">https://book.douban.com/subject/25900403/</a><br><a href="http://www.cse.iitm.ac.in/~chester/courses/15o_os/slides/5_Interrupts.pdf" target="_blank" rel="noopener">http://www.cse.iitm.ac.in/~chester/courses/15o_os/slides/5_Interrupts.pdf</a><br><a href="https://blog.packagecloud.io/eng/2016/10/11/monitoring-tuning-linux-networking-stack-receiving-data-illustrated/" target="_blank" rel="noopener">https://blog.packagecloud.io/eng/2016/10/11/monitoring-tuning-linux-networking-stack-receiving-data-illustrated/</a><br><a href="https://blog.packagecloud.io/eng/2016/06/22/monitoring-tuning-linux-networking-stack-receiving-data/" target="_blank" rel="noopener">https://blog.packagecloud.io/eng/2016/06/22/monitoring-tuning-linux-networking-stack-receiving-data/</a><br><a href="https://mp.weixin.qq.com/s/kWDKpgmcOQFjoBAK3LyPTg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/kWDKpgmcOQFjoBAK3LyPTg</a><br><a href="https://juejin.cn/post/6892687008552976398#heading-26" target="_blank" rel="noopener">https://juejin.cn/post/6892687008552976398#heading-26</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://pearlzju.github.io/2021/06/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%20IO%E6%A8%A1%E5%9E%8B(%E4%BA%8C)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pearl">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/face.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pearl 的个人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%20IO%E6%A8%A1%E5%9E%8B(%E4%BA%8C)/" itemprop="url">深入理解Linux IO模型(二)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-06-05T23:57:11+08:00">
                2021-06-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" itemprop="url" rel="index">
                    <span itemprop="name">计算机</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/06/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%20IO%E6%A8%A1%E5%9E%8B(%E4%BA%8C)/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2021/06/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%20IO%E6%A8%A1%E5%9E%8B(%E4%BA%8C)/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2021/06/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%20IO%E6%A8%A1%E5%9E%8B(%E4%BA%8C)/" class="leancloud_visitors" data-flag-title="深入理解Linux IO模型(二)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<p>接着前文《深入理解Linux IO模型(一)》，本文深入分析IO多路复用模型中的epoll。</p>
<blockquote>
<ol>
<li>本文为了描述方便，统一用读操作讲述，写操作同理。</li>
<li>本文为了撰写方便，统一将I/O写成了IO。</li>
<li>欢迎指正文中的错误。</li>
</ol>
</blockquote>
<h3 id="为何使用epoll"><a href="#为何使用epoll" class="headerlink" title="为何使用epoll"></a>为何使用epoll</h3><p>Nginx在几十万并发连接下，是如何做到高效利用服务器资源的？答案是epoll。</p>
<p>设想一个场景：有100万用户同时与一个网络应用进程保持着TCP连接，而每一时刻只有几十或几百个TCP连接是活跃的（网络应用进程接收到TCP报文），那么在这个时刻，进程只需要处理这100万个连接中的这些活跃的连接即可。那么，内核和应用进程如何协同，才能高效地处理这种情况呢？</p>
<h4 id="select的缺陷"><a href="#select的缺陷" class="headerlink" title="select的缺陷"></a>select的缺陷</h4><p>应用进程是否在每次调用系统调用，询问内核有事件发生的TCP连接时，把这100万个连接告诉内核，由内核找出其中有事件发生的TCP连接呢？<br>这正是select的做法。</p>
<p>select有明显的缺陷，因为这100万个TCP连接中，大部分是没有事件发生的。如果应用程序每次收集事件时，都把这100万个socket fd传给内核。有以下问题：</p>
<ol>
<li>导致用户空间到内核空间的大量复制。</li>
<li>内核需要遍历所有的socket fd，判断哪些有事件到来。</li>
<li>应用进程仍需要遍历所有的socket fd，来判断哪些socket fd可读。</li>
</ol>
<p>所以select限制了同时监听的socket fd数量，最多只能同时处理1024个并发连接。</p>
<h4 id="epoll的提出"><a href="#epoll的提出" class="headerlink" title="epoll的提出"></a>epoll的提出</h4><p>epoll在内核中申请了一片内存空间。</p>
<p>epoll的做法是，把应用程序的一个select调用分成三部分：</p>
<ol>
<li>调用epoll_create创建一个epoll对象</li>
<li>调用epoll_ctl向epoll对象添加这100万个socket fd</li>
<li>调用epoll_wait等待收集发生事件的连接</li>
</ol>
<p>这样，只要在应用进程启动时，建立1个epoll对象(下文用epfd表示)，并在TCP连接到来和断开的时候，对epfd添加和删除事件就可以了（也可以修改）。<br>应用进程调用epoll_wait时，不需要向内核空间传递这100万个连接，内核也不需要遍历全部的连接。所以epoll_wait很高效。</p>
<h3 id="epoll的原理"><a href="#epoll的原理" class="headerlink" title="epoll的原理"></a>epoll的原理</h3><p>当应用进程调用epoll_create时，内核会在内核空间创建一个独立的eventpoll结构体对象，用于维护使用epoll_ctl向其添加的事件。</p>
<h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h4><p>epoll的数据结构如图所示。eventpoll有两个核心的数据结构：</p>
<ol>
<li>红黑树(rbr)：维护通过epoll_ctl添加的事件。</li>
<li>就绪链表(rdllist)：保存就绪的事件，当事件发生时，由内核的中断处理程序插入该就绪链表。</li>
</ol>
<img width="500" src="/images/深入理解Linux IO模型/29.png">

<blockquote>
<p>说明: 这张图来自于《深入理解Nginx》，网上很多博客用了这张图，但是这张图关于就绪链表的描述有个小错误。”红黑树中每个节点都是基于epitem结构中的rdllink成员”应该改成”就绪链表中每个节点都是基于epitem结构中的rdllink成员”。</p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里只列出了成员rbr、rdllist，它们和epoll的使用密切相关</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">eventpoll</span> &#123;</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 红黑树的根节点，这棵树中存储着所有添加到epoll中的事件，即这个epoll监控的事件</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">rb_root</span> <span class="title">rbr</span>;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 双向链表rdllist保存着要通过epoll_wait返回给应用程序的满足条件的事件</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">rdllist</span>;</span></span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epitem</span> &#123;</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 红黑树节点</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> <span class="title">rbn</span>;</span></span><br><span class="line">  <span class="comment">// 双向链表节点</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">rdllink</span>;</span></span><br><span class="line">  <span class="comment">// 事件句柄等信息</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">epoll_filefd</span> <span class="title">ffd</span>;</span></span><br><span class="line">  <span class="comment">// 指向其所属的eventpoll对象</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">eventpoll</span> *<span class="title">ep</span>;</span></span><br><span class="line">  <span class="comment">// 期待的事件类型</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> <span class="title">event</span>;</span></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><p>在epoll中，为每个事件都建立一个epitem结构体对象。<br>这些事件都会添加到rbr红黑树中（重复添加的事件可以通过红黑树高效地识别出来）。从红黑树中查找事件非常快。</p>
<p>所有添加到epoll对象中的事件都会与设备驱动程序（如网卡驱动程序）建立回调关系，当相应的事件发生时，会调用回调函数（中断处理程序）。这个回调函数在内核叫<code>ep_poll_callback</code>，回调函数会把就绪的事件写入rdllist双向链表中。</p>
<p>当应用程序调用epoll_wait检查是否有事件发生的连接时，内核只是检查eventpoll对象的rdllist双向链表是否有epitem元素而已。如果rdllist链表不为空，内核把这里的事件复制到用户空间，同时返回对应的事件数量。</p>
<h4 id="高效原因"><a href="#高效原因" class="headerlink" title="高效原因"></a>高效原因</h4><p>最后总结分析下epoll之所以可以处理百万级别的并发连接，而且效率很高的原因。</p>
<ol>
<li>应用程序在调用系统调用epoll_create创建epoll时，内核为它开辟了一片内存空间。把listen fd存在里面，以及当每次来客户端请求，三次握手后建立的client fd都会存在内核态的这个内存空间。这样不同于select，避免了用户空间和内核空间之间重复传递fd的过程。</li>
<li>应用程序要知道哪些事件可读了，不同于在select中应用程序需要主动遍历所有fd，内核只是将就绪列表中的事件复制到用户空间的event数组中（应用程序提前申请好的内存），这样应用程序只需要遍历这些就绪的事件。</li>
<li>就绪事件是怎么放入就绪列表的？答案是epoll利用了事件驱动。当数据包进入网卡，网卡将数据包通过DMA方式写入内存。网卡raise硬件中断IRQ，通知CPU有数据包到来了。CPU查询中断向量表，得到中断服务程序的指针，这个中断服务程序会调用网卡驱动程序。这里的中断服务程序是事先注册的，所以也可以理解CPU根据中断号回调中断处理程序，从内存读取数据，得到事件的fd，写入就绪列表rdllist中。</li>
</ol>
<blockquote>
<p>这里用到了上一篇《深入理解Linux IO模型(一)》写到的硬中断，不熟悉的可以看一下。</p>
</blockquote>
<p>从程序的本质上看，程序是否有更好的并发，是看少浪费了什么。<br>CPU、内存、硬盘、网络带宽的利用率决定程序是不是能应对更复杂的场景。<br>当遇到高并发问题，怀疑程序在服务器上运转不良好时，一定要回过头看硬件有没有被充分利用，有没有浪费硬件资源。<br>CPU在执行什么事情的指令，决定了它的利用率。<br>select需要CPU在内核模式下（CPU的一种执行模式）主动去遍历所有描述符，这样CPU浪费在了遍历上。而epoll靠的是硬件中断，利用中断把就绪fd写入就绪列表。更充分发挥了硬件，不浪费CPU。这是epoll高效的最大原因。</p>
<h3 id="epoll的API"><a href="#epoll的API" class="headerlink" title="epoll的API"></a>epoll的API</h3><p>epoll提供给应用程序的系统调用API有三个。</p>
<ul>
<li>创建epoll：epoll_create系统调用</li>
<li>控制epoll：epoll_ctl系统调用</li>
<li>等待epoll：epoll_wait系统调用</li>
</ul>
<h4 id="创建epoll"><a href="#创建epoll" class="headerlink" title="创建epoll"></a>创建epoll</h4><p>创建epoll，指的是在内核空间创建一颗红黑树（平衡二叉树）的根节点root。它返回一个fd（下文用epfd指代），用来标识这个epoll对象。这个root根节点与epfd相对应。如图所示。</p>
<img width="200" src="/images/深入理解Linux IO模型/26.png">

<p>API如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * @param size 告诉epoll要处理的大致事件数量，而不是能处理的事件最大数量。</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * @returns 返回一个epoll句柄（即一个文件描述符） </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_create</span><span class="params">(<span class="keyword">int</span> size)</span></span>;</span><br></pre></td></tr></table></figure>

<p>调用方法：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> epfd = epoll_create(<span class="number">1000</span>);</span><br></pre></td></tr></table></figure>

<h4 id="控制epoll"><a href="#控制epoll" class="headerlink" title="控制epoll"></a>控制epoll</h4><p>控制epoll，指的是以下三种操作:</p>
<ul>
<li>注册新的事件到epoll</li>
<li>修改已经注册的事件</li>
<li>删除一个注册到epoll的事件</li>
</ul>
<p>添加某事件的时候，事件被插到红黑树的某个节点，并且与相应的设备驱动程序建立回调关系。当事件发生后，内核中断处理程序调用这个回调函数，将事件添加到就绪链表。</p>
<p>API如下:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* @param epfd 用epoll_create所创建的epoll实例</span></span><br><span class="line"><span class="comment">* @param op 表示对epoll监控描述符控制的动作</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* EPOLL_CTL_ADD(添加新的事件到epoll中)</span></span><br><span class="line"><span class="comment">* EPOLL_CTL_MOD(修改已经注册到epoll中的事件)</span></span><br><span class="line"><span class="comment">* EPOLL_CTL_DEL(删除epoll中的事件)</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* @param fd 待监测的连接fd</span></span><br><span class="line"><span class="comment">* @param event 告诉内核需要监听的事件(包括类型)，指向epoll_event的指针</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* @returns 成功返回0，失败返回-1, errno查看错误信息</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_ctl</span><span class="params">(<span class="keyword">int</span> epfd, <span class="keyword">int</span> op, <span class="keyword">int</span> fd,</span></span></span><br><span class="line"><span class="function"><span class="params">struct epoll_event *event)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> &#123;</span></span><br><span class="line">  <span class="keyword">__uint32_t</span> events; <span class="comment">// epoll 事件</span></span><br><span class="line">  <span class="keyword">epoll_data_t</span> data; <span class="comment">// 用户传递的数据</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">union</span> epoll_data &#123;</span><br><span class="line">  <span class="keyword">void</span> *ptr;</span><br><span class="line">  <span class="keyword">int</span> fd; <span class="comment">// 监听的事件fd</span></span><br><span class="line">  <span class="keyword">uint32_t</span> u32;</span><br><span class="line">  <span class="keyword">uint64_t</span> u64;</span><br><span class="line">&#125; <span class="keyword">epoll_data_t</span>;</span><br></pre></td></tr></table></figure>

<p>关于epoll_event，具体介绍下。上文介绍过epoll为每个事件创建epitem对象，在结构体epitem中有一个成员epoll_event。</p>
<p>epoll_event.events的取值包括：<br>EPOLLIN：表示对应的连接上有数据可以读出（TCP连接的远端主动关闭连接，也相当于可读事件，因为要处理发过来的FIN包）<br>EPOLLOUT：表示对应的连接上可以写入数据发送<br>EPOLLRDHUP：表示TCP连接的远端关闭或半关闭连接<br>EPOLLPR：表示对应的链接上有紧急数据需要读<br>EPOLLERR：表示对应的连接发生错误<br>EPOLLHUP：表示对应的连接被挂起<br>EPOLLET：表示将处罚方式设置为边缘触发（ET），系统默认为水平触发（LT）<br>EPOLLONESHOT：表示对这个事件只处理一次，下次需要处理时需要重新加入epoll</p>
<p>调用方法:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> <span class="title">new_event</span>;</span></span><br><span class="line"></span><br><span class="line">new_event.events = EPOLLIN | EPOLLOUT;</span><br><span class="line">new_event.data.fd = <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line">epoll_ctl(epfd, EPOLL_CTL_ADD, <span class="number">5</span>, &amp;new_event);</span><br></pre></td></tr></table></figure>

<p>在用户空间创建一个IO事件，绑定到某个fd上，然后把该事件的fd添加到内核中的epoll红黑树中。当fd可读或可写时，触发的是epoll_event。如图所示。</p>
<img width="500" src="/images/深入理解Linux IO模型/27.png">

<h4 id="等待epoll"><a href="#等待epoll" class="headerlink" title="等待epoll"></a>等待epoll</h4><p>收集在epoll监控的事件中已经发生的事件，内核会检查就绪链表中是否有存在添加过的事件，如果没有任何事件发生，最多等待timeout毫秒后返回（在timeout设置&gt;0的情况下）。返回值表示当前发生的事件个数。</p>
<p>API如下:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* @param epfd 用epoll_create所创建的epoll实例</span></span><br><span class="line"><span class="comment">* @param event 从内核得到的就绪的事件集合</span></span><br><span class="line"><span class="comment">* @param maxevents 本次可以返回的最大事件数目，通常与预分配的event数组大小相等</span></span><br><span class="line"><span class="comment">* 注意: 值不能大于创建epoll_create()时的size</span></span><br><span class="line"><span class="comment">* @param timeout 等待IO事件发生的超时时间</span></span><br><span class="line"><span class="comment">* -1: 永久阻塞</span></span><br><span class="line"><span class="comment">* 0: 如果就绪链表rdllist为空，立即返回，不会等待，即非阻塞</span></span><br><span class="line"><span class="comment">* &gt;0: 指定最多等待的时间，单位毫秒</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* @returns 成功: 有多少文件描述符就绪,时间到时返回0</span></span><br><span class="line"><span class="comment">* 失败: -1, errno 查看错误</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_wait</span><span class="params">(<span class="keyword">int</span> epfd, struct epoll_event *event,</span></span></span><br><span class="line"><span class="function"><span class="params">               <span class="keyword">int</span> maxevents, <span class="keyword">int</span> timeout)</span></span>;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意: epoll_event不能是空指针，内核只是负责把内核空间中就绪链表的数据复制到用户空间的event数组中，不会去帮忙分配内存，所以用户空间需要自己提前分配内存。</p>
</blockquote>
<p>调用方法:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> <span class="title">my_event</span>[1000];</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> event_cnt = epoll_wait(epfd, my_event, <span class="number">1000</span>, <span class="number">-1</span>);</span><br></pre></td></tr></table></figure>

<p>如图所示。应用程序调用epoll_wait后，进入阻塞状态。当内核检测到new_event或event1绑定的fd可读了，内核把就绪的event事件拷贝到用户空间的my_event数组。应用程序只需要遍历my_event，取出对应的事件和fd，知道是可读了，然后堵塞调用recv(fd)读数据。</p>
<img width="500" src="/images/深入理解Linux IO模型/28.png">

<h3 id="使用epoll-API"><a href="#使用epoll-API" class="headerlink" title="使用epoll API"></a>使用epoll API</h3><p>一个简单的使用epoll API的编程架构如下。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建epoll fd，最多可接收1000个事件</span></span><br><span class="line"><span class="keyword">int</span> epfd = epoll_crete(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将listen_fd添加进epoll中</span></span><br><span class="line">epoll_ctl(epfd, EPOLL_CTL_ADD, listen_fd, &amp;listen_event);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">  <span class="comment">// 阻塞等待epoll中的事件fd触发</span></span><br><span class="line">  <span class="keyword">int</span> active_cnt = epoll_wait(epfd, events, <span class="number">1000</span>, <span class="number">-1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (i = <span class="number">0</span> ; i &lt; active_cnt; i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (evnets[i].data.fd == listen_fd) &#123;</span><br><span class="line">      <span class="comment">// 表示新的客户端连接请求到来</span></span><br><span class="line">      <span class="comment">// 调用accept进行三次握手，创建client_fd</span></span><br><span class="line">      <span class="comment">// 并将client_fd加进epoll中</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (events[i].events &amp; EPOLLIN) &#123;</span><br><span class="line">      <span class="comment">// 表示不是新的客户端连接，可读客户端发来的数据</span></span><br><span class="line">      <span class="comment">// client_fd就绪可读，对此fd进行读操作</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (events[i].events &amp; EPOLLOUT) &#123;</span><br><span class="line">      <span class="comment">// 表示不是新的客户端连接，可把数据回写客户端</span></span><br><span class="line">      <span class="comment">// client_fd就绪可写，对此fd进行写操作</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如图所示，是一个服务器使用epoll的常规流程。</p>
<img width="1000" src="/images/深入理解Linux IO模型/30.png">

<h3 id="触发方式"><a href="#触发方式" class="headerlink" title="触发方式"></a>触发方式</h3><p>epoll有两种工作模式：水平触发和边缘触发。默认情况下，epoll采用水平触发模式。</p>
<h4 id="水平触发-Level-Triggered-LT"><a href="#水平触发-Level-Triggered-LT" class="headerlink" title="水平触发(Level Triggered, LT)"></a>水平触发(Level Triggered, LT)</h4><p>如果应用程序阻塞在epoll_wait，当内核有事件发生的时候，内核把已经触发的事件队列复制到用户空间。如果应用程序本次没有完成读操作，下一次epoll_wait会再次返回该事件。<br>即只要一个事件对应的套接字缓冲区还有数据，就总能从epoll_wait中获取这个事件。</p>
<p>优点：事件不会丢掉，除非应用程序处理完毕。保证事件的完整性。<br>缺点：如果应用程序不处理这个事件，就导致内核每次都把该事件从内核空间拷贝到用户空间，系统调用消耗性能。</p>
<h4 id="边缘触发-Edge-Triggered-ET"><a href="#边缘触发-Edge-Triggered-ET" class="headerlink" title="边缘触发(Edge Triggered, ET)"></a>边缘触发(Edge Triggered, ET)</h4><p>如果应用程序阻塞在epoll_wait，当内核有事件发生的时候，内核把已经触发的事件队列复制到用户空间。如果应用程序本次没有完成读操作，下一次epoll_wait不再会返回该事件。<br>即如果这次没有把这个事件对应的套接字缓冲区处理完，在这个套接字没有新的事件再次到来时，无法再次从epoll_wait调用中获取到这个事件。</p>
<p>优点：内核不会重复把该事件从内核空间拷贝到用户空间。保证性能。<br>缺点：如果应用程序没有处理完毕，事件会被丢掉。导致事件不完整。</p>
<h4 id="两者对比"><a href="#两者对比" class="headerlink" title="两者对比"></a>两者对比</h4><p>在水平触发模式下，开发基于epoll的应用要简单一些，不太容易出错。而在边缘触发模式下，当事件发生时，如果没有彻底地将缓冲区数据处理完，则会导致缓冲区中的用户请求得不到响应。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>深入理解Nginx（第2版）<a href="https://book.douban.com/subject/26745255/" target="_blank" rel="noopener">https://book.douban.com/subject/26745255/</a><br><a href="https://mp.weixin.qq.com/s/kWDKpgmcOQFjoBAK3LyPTg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/kWDKpgmcOQFjoBAK3LyPTg</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://pearlzju.github.io/2019/10/21/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pearl">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/face.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pearl 的个人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/21/hello-world/" itemprop="url">Hello World</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-21T20:55:02+08:00">
                2019-10-21
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/21/hello-world/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/10/21/hello-world/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/10/21/hello-world/" class="leancloud_visitors" data-flag-title="Hello World">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/face.jpeg"
                alt="Pearl" />
            
              <p class="site-author-name" itemprop="name">Pearl</p>
              <p class="site-description motion-element" itemprop="description">爱自己是终身浪漫的开始</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Pearlzju" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i></a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:shanglin@zju.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i></a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/LINZJU" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-globe"></i></a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.douban.com/people/104033946" target="_blank" title="豆瓣">
                      
                        <i class="fa fa-fw fa-globe"></i></a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Pearl</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'ECUWkqa8FVLG7NN721RUeTXk-gzGzoHsz',
        appKey: 'BEMbJ6wNDs62iTOP3UAxzVle',
        placeholder: '说点什么呢',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("ECUWkqa8FVLG7NN721RUeTXk-gzGzoHsz", "BEMbJ6wNDs62iTOP3UAxzVle");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  

  

  

</body>
</html>
